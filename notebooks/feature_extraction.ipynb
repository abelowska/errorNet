{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a73099-38c1-4bf0-afd3-5481df7c3d19",
   "metadata": {},
   "source": [
    "# Extraction of features for different models of error-related brain activity and anxiety dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff9f56-5483-44c7-b9cc-486a31838279",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e9e84d26-b32c-41ae-b3f4-81e0ee55156b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "import ast\n",
    "import os.path as op\n",
    "import pickle\n",
    "import mne\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "\n",
    "import pygsp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.utils import resample\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.integrate import simpson\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from autoreject import AutoReject\n",
    "\n",
    "from transformers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c69899-6a32-4418-9079-8bd66aed497f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Load data\n",
    "\n",
    "Loading EEG data and data from rumination questionnaire. By default create_df_data loads all info from given file but one can specify it by passing a list of desired labels from csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "cdc483a7-410f-4b65-9955-9df42c783bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths TODO\n",
    "dir_path = os.path.dirname(os.path.abspath(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "27a25389-d030-415b-982d-b68df981b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = -0.1, 0.6  # Start and end of the segments\n",
    "signal_frequency = 256\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "7c412f36-66a2-4fd8-bfa7-caa98c4a315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_data(\n",
    "    test_participants=False,\n",
    "    test_epochs=False,\n",
    "    info_filename=None,\n",
    "    info=\"all\",\n",
    "    personal=True,\n",
    "):\n",
    "    \"\"\"Loads data for all participants and create DataFrame with optional additional info from given .csv file.\n",
    "\n",
    "    On default, loads a train set: chooses only 80% of participants\n",
    "    and for each of them chooses 80% of epochs.\n",
    "    It will choose them deterministically.\n",
    "\n",
    "    Participants with less than 10 epochs per condition are rejected.\n",
    "\n",
    "    If test_participants is set to True, it will load remaining 20% of participants.\n",
    "    If test_epochs is set to True, it will load remaining 20% of epochs.\n",
    "    Test epochs are chronologically after train epochs,\n",
    "    because it reflects real usage (first callibration and then classification).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_participants: bool\n",
    "        whether load data for training or final testing.\n",
    "        If true load participants data for testing.\n",
    "    test_epochs: bool\n",
    "        whether load data for training or final testing.\n",
    "        If true load epochs of each participants data for testing.\n",
    "    info_filename: String | None\n",
    "        path to .csv file with additional data.\n",
    "    info: array\n",
    "        listed parameters from the info file to be loaded.\n",
    "        if 'all', load all parameters\n",
    "    personal: bool\n",
    "        whether a model will be both trained and tested on epochs from one person\n",
    "        if false, person's epochs aren't split into test and train\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    go_nogo_data_df : pandas.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    print(os.path.abspath(\"\"))\n",
    "    dir_path = os.path.dirname(os.path.abspath(\"\"))\n",
    "    print(dir_path)\n",
    "    header_files_glob = os.path.join(dir_path, \"data/responses_100_600_sonata/*.vhdr\")\n",
    "    header_files = glob.glob(header_files_glob)\n",
    "\n",
    "    header_files = sorted(header_files)\n",
    "    go_nogo_data_df = pd.DataFrame()\n",
    "\n",
    "    # cut 20% of data for testing\n",
    "    h_train, h_test = train_test_split(header_files, test_size=0.3, random_state=0)\n",
    "    \n",
    "    print(f\"train size: {len(h_train)} ; test size: {len(h_test)}\")\n",
    "\n",
    "    if test_participants:\n",
    "        header_files = h_test\n",
    "    else:\n",
    "        header_files = h_train\n",
    "\n",
    "    for file in header_files:\n",
    "        #  load eeg data for given participant\n",
    "        participant_epochs = load_epochs_from_file(file)\n",
    "\n",
    "        # and compute participant's id from file_name\n",
    "        participant_id = re.match(r\".*GNG-(\\d+).*\", file).group(1)\n",
    "\n",
    "        error = participant_epochs[\"error_response\"]._data\n",
    "        correct = participant_epochs[\"correct_response\"]._data\n",
    "\n",
    "        # exclude those participants who have too few samples\n",
    "        if len(error) < 5 or len(correct) < 5:\n",
    "            # not enough data for this participant\n",
    "            continue\n",
    "\n",
    "        # construct dataframe for participant with: id|epoch_data|response_type|additional info...\n",
    "        participant_df = create_df_from_epochs(\n",
    "            participant_id, participant_epochs, info_filename, info\n",
    "        )\n",
    "        print(participant_id)\n",
    "        go_nogo_data_df = go_nogo_data_df.append(participant_df, ignore_index=True)\n",
    "\n",
    "    return go_nogo_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0991419b-7acd-42bc-b048-e5e9fa3cb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_epochs(id, participant_epochs, info_filename, info):\n",
    "    \"\"\"Create df for each participant. DF structure is like: {id: String ; epoch: epoch_data ; marker: 1.0|0.0}\n",
    "    1.0 means correct and 0.0 means error response.\n",
    "    Default info extracted form .csv file is 'Rumination Full Scale' and participants' ids.\n",
    "    With this info df structure is like:\n",
    "    {id: String ; epoch: epoch_data ; marker: 1.0|0.0 ; File: id ; 'Rumination Full Scale': int}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    id: String\n",
    "        participant's id extracted from filename\n",
    "    correct: array\n",
    "        correct responses' data\n",
    "    error: array\n",
    "        error responses' data\n",
    "    info_filename: String\n",
    "        path to .csv file with additional data.\n",
    "    info: array\n",
    "        listed parameters from the info file to be loaded.\n",
    "        if 'all', load all parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    participant_df : pandas.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    participant_df = pd.DataFrame()\n",
    "    info_df = pd.DataFrame()\n",
    "\n",
    "    # get additional info from file\n",
    "    if info_filename is not None:\n",
    "        if info == \"all\":\n",
    "            rumination_df = pd.read_csv(info_filename, dtype={'Demo_kod': object})\n",
    "        else:\n",
    "            rumination_df = pd.read_csv(info_filename, usecols=[\"Demo_kod\"] + info, dtype={'Demo_kod': object})\n",
    "        info_df = (\n",
    "            rumination_df.loc[rumination_df[\"Demo_kod\"] == id]\n",
    "            .reset_index()\n",
    "            .drop(\"index\", axis=1)\n",
    "        )      \n",
    "    epoch_df = pd.DataFrame({\"id\": [id], \"epoch\": [participant_epochs]}).join(\n",
    "            info_df\n",
    "        )\n",
    "    participant_df = participant_df.append(epoch_df, ignore_index=True)\n",
    "\n",
    "    return participant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "aa88517e-884a-4b5b-9652-1bf2e7787aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_epochs_from_file(file, reject_bad_segments=\"auto\", mask=None):\n",
    "    \"\"\"Load epochs from a header file.\n",
    "\n",
    "    Args:\n",
    "        file: path to a header file (.vhdr)\n",
    "        reject_bad_segments: 'auto' means that bad segments are rejected automatically.\n",
    "\n",
    "    Returns:\n",
    "        mne Epochs\n",
    "\n",
    "    \"\"\"\n",
    "    # Import the BrainVision data into an MNE Raw object\n",
    "    raw = mne.io.read_raw_brainvision(file)\n",
    "\n",
    "    # Construct annotation filename\n",
    "    annot_file = file[:-4] + \"vmrk\"\n",
    "\n",
    "    # Read in the event information as MNE annotations\n",
    "    annotations = mne.read_annotations(annot_file)\n",
    "\n",
    "    # Add the annotations to our raw object so we can use them with the data\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    # Map with response markers only\n",
    "    # event_dict = {\n",
    "    #     \"Stimulus/RE*ex*1_n*1_c_1*R*FB\": 10004,\n",
    "    #     \"Stimulus/RE*ex*1_n*1_c_1*R*FG\": 10005,\n",
    "    #     \"Stimulus/RE*ex*1_n*1_c_2*R\": 10006,\n",
    "    #     \"Stimulus/RE*ex*1_n*2_c_1*R\": 10007,\n",
    "    #     \"Stimulus/RE*ex*2_n*1_c_1*R\": 10008,\n",
    "    #     \"Stimulus/RE*ex*2_n*2_c_1*R*FB\": 10009,\n",
    "    #     \"Stimulus/RE*ex*2_n*2_c_1*R*FG\": 10010,\n",
    "    #     \"Stimulus/RE*ex*2_n*2_c_2*R\": 10011,\n",
    "    # }\n",
    "    \n",
    "    event_dict = {\n",
    "        'Stimulus/RE*ex*1_n*1_c_1*R*FB': 10003,\n",
    "        'Stimulus/RE*ex*1_n*1_c_1*R*FG': 10004,\n",
    "        'Stimulus/RE*ex*1_n*1_c_2*R': 10005,\n",
    "        'Stimulus/RE*ex*1_n*2_c_1*R': 10006,\n",
    "        'Stimulus/RE*ex*2_n*1_c_1*R': 10007,\n",
    "        'Stimulus/RE*ex*2_n*2_c_1*R*FB': 10008,\n",
    "        'Stimulus/RE*ex*2_n*2_c_1*R*FG': 10009,\n",
    "        'Stimulus/RE*ex*2_n*2_c_2*R': 10010,\n",
    "    }\n",
    "\n",
    "    # Map for merged correct/error response markers\n",
    "    merged_event_dict = {\"correct_response\": 0, \"error_response\": 1}\n",
    "\n",
    "    # Reconstruct the original events from Raw object\n",
    "    events, event_ids = mne.events_from_annotations(raw, event_id=event_dict)\n",
    "\n",
    "    # Merge correct/error response events\n",
    "    merged_events = mne.merge_events(\n",
    "        events,\n",
    "        [10003, 10004, 10008, 10009],\n",
    "        merged_event_dict[\"correct_response\"],\n",
    "        replace_events=True,\n",
    "    )\n",
    "    merged_events = mne.merge_events(\n",
    "        merged_events,\n",
    "        [10005, 10006, 10007, 10010],\n",
    "        merged_event_dict[\"error_response\"],\n",
    "        replace_events=True,\n",
    "    )\n",
    "\n",
    "    epochs = []\n",
    "    bads = []\n",
    "    this_reject_by_annotation = False\n",
    "    \n",
    "    # Read epochs\n",
    "    epochs = mne.Epochs(\n",
    "        raw=raw,\n",
    "        events=merged_events,\n",
    "        event_id=merged_event_dict,\n",
    "        tmin=tmin,\n",
    "        tmax=tmax,\n",
    "        baseline=None,\n",
    "        reject_by_annotation=this_reject_by_annotation,\n",
    "        preload=True,\n",
    "    )\n",
    "    \n",
    "    ar = AutoReject(random_state=random_state, n_jobs=10, verbose=0)\n",
    "    epochs_ar, reject_log = ar.fit_transform(epochs, return_log=True)\n",
    "    \n",
    "    return epochs_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5e07d-9618-47de-a706-687a529fb2fe",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "264dc68c-de05-4885-b579-2d887884ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_column_names(data_df):\n",
    "    columns_dict = {\n",
    "        \"16-Rumination Full Scale\": \"RRQ\", # mean\n",
    "        \"05-DASS-21 Anxiety scale\": \"DASS-21 Anx\", # mean\n",
    "        ###\n",
    "        \"05-DASS-21 Stress scale\": \"DASS-21 Stress\", # mean\n",
    "        \"05-DASS-21 Depression scale\": \"DASS-21 Dep\", # mean\n",
    "        \"04-STAI Trait MEAN\": \"STAI-T_M\", # mean\n",
    "        \"04-STAI STATE 1-2 DIFFERENCE\": \"STAI-S Diff\", # sum\n",
    "        \"number_error\" : \"uninhibited response\", # sum\n",
    "        \"number_inhibited\" : \"inhibited response\", # sum\n",
    "        ###\n",
    "        \"04-STAI Trait SUM\": \"STAI-T\", # sum\n",
    "        \"07-BIS\": \"BIS\", # mean\n",
    "        \"14-Obsessive-Compulsive WASHING\": \"WASH\", # mean\n",
    "        \"14-Obsessive-Compulsive OBSESSING\": \"OBSESS\", # mean\n",
    "        \"14-Obsessive-Compulsive HOARDING\": \"HOARD\", # mean\n",
    "        \"14-Obsessive-Compulsive ORDERING\": \"ORD\", # mean\n",
    "        \"14-Obsessive-Compulsive CHECKING\": \"CHECK\", # mean\n",
    "        \"14-Obsessive-Compulsive NEUTRALIZING\": \"NEU\", # mean\n",
    "        # \"14-Obsessive-Compulsive FULL\": \"OCI-R\",\n",
    "        \"18-Thought Suppression Inventory\": \"WBSI\", # mean\n",
    "        \"28-Intolerance of Uncertainty - Prospective Anxiety\": \"IUS-P\", # mean\n",
    "        \"28-Intolerance of Uncertainty - Inhibitory Anxiety\": \"IUS-I\", # mean\n",
    "        \"06-Self-Esteem Scale_SES Rosenberga\": \"SES\", # mean\n",
    "        \"07-BAS Dzialanie\": 'BAS_D', # mean\n",
    "        \"07-BAS Poszukiwanie przyjemnosci\": 'BAS_PRZY', # mean\n",
    "        \"07-BAS Wrazliwosc na nagrode\": 'BAS_NAG', # mean\n",
    "        \"22-Nonforgiveness - Full Scale\": 'NONFOR',\n",
    "        \"27-Indecisiveness Scale_Frost\": 'INDEC_F', # mean\n",
    "        \"03-SP (Punishment Sensitivity)\": 'PUN', # sum\n",
    "        \"03-SR (Reward Sensitivity)\": 'REW', # sum\n",
    "        \"15-Obsessional Beliefs - Inflated responsibility for harm\": 'HARM', # mean\n",
    "        \"15-Obsessional Beliefs - Importance/Control of Thoughts\": 'T-CTR', # mean\n",
    "        \"15-Obsessional Beliefs - Overestimation of threat\": \"OT\", # mean\n",
    "        \"15-Obsessional Beliefs - Perfectionism/ Intolerance of uncertainty\": 'OB_PERF', # mean\n",
    "        \"17-Perfectionism CMDA\": 'CMDA', # mean\n",
    "        \"17-Perfect PS-Personal Standards (7 items mean)\" : 'PS', # mean\n",
    "        \"19-Guilt sensitivity\": 'G_SE', # mean\n",
    "        \"31-NFC Nietolerancja wieloznaczności-FULL\": 'AMB', # mean\n",
    "        \"31-NFC Preferowanie przewidywalności-FULL\": 'PRED', # mean\n",
    "        \"32-High standards from Maximization Full Scale\" : 'STAND',   # mean\n",
    "        \"Wiek\": \"Age\",\n",
    "        \"Płeć\": \"Sex\",\n",
    "        \"Ręczność\": \"Handness\",    \n",
    "\n",
    "        #######\n",
    "        \"Rumination Full Scale\": \"RRQ\",\n",
    "        \"DASS-21 Anxiety scale 0-SUM\": \"DASS-21 Anx\", # sum\n",
    "        \"DASS-21 Stress scale 0-SUM\": \"DASS-21 Stress\", # sum\n",
    "        \"DASS-21 Depression scale 0-SUM\": \"DASS-21 Dep\", # sum\n",
    "        \"number_error\": \"uninhibited response\", # sum\n",
    "        \"number_inhibited\":  \"inhibited response\", # sum\n",
    "        \"STAI STATE 1-2 DIFFERENCE\": \"STAI-S Diff\", # sum\n",
    "        ###\n",
    "        \"STAI Trait SUM\": \"STAI-T\", # sum\n",
    "        \"BIS\": \"BIS\", # mean\n",
    "        \"Obsessive-Compulsive WASHING\": \"WASH\", # mean\n",
    "        \"Obsessive-Compulsive OBSESSING\": \"OBSESS\", # mean\n",
    "        \"Obsessive-Compulsive HOARDING\": \"HOARD\", # mean\n",
    "        \"Obsessive-Compulsive ORDERING\": \"ORD\", # mean\n",
    "        \"Obsessive-Compulsive CHECKING\": \"CHECK\", # mean\n",
    "        \"Obsessive-Compulsive NEUTRALIZING\": \"NEU\", # mean\n",
    "        # \"14-Obsessive-Compulsive FULL\": \"OCI-R\",\n",
    "        \"Thought Suppression Inventory\": \"WBSI\", # mean\n",
    "        \"Intolerance of Uncertainty - Prospective Anxiety\": \"IUS-P\", # mean\n",
    "        \"Intolerance of Uncertainty - Inhibitory Anxiety\": \"IUS-I\", # mean\n",
    "        \"Self-Esteem Scale_SES Rosenberga MEAN\": \"SES\", # mean\n",
    "        \"BAS Dzialanie\": 'BAS_D', # mean # drive\n",
    "        \"BAS Poszukiwanie przyjemnosci\": 'BAS_PRZY', # mean # fun seeking\n",
    "        \"BAS Wrazliwosc na nagrode\": 'BAS_NAG', # mean # responsivness\n",
    "        # \"22-Nonforgiveness - Full Scale\": 'NONFOR',\n",
    "        \"Indecisiveness Scale_Frost\": 'INDEC_F', # mean\n",
    "        \"SP (Punishment Sensitivity)\": 'PUN', # sum\n",
    "        \"SR (Reward Sensitivity)\": 'REW', # sum\n",
    "        \"Obsessional Beliefs - Inflated responsibility for harm\": 'HARM', # mean\n",
    "        \"Obsessional Beliefs - Importance/Control of Thoughts\": 'T-CTR', # mean\n",
    "        \"Obsessional Beliefs - Overestimation of threat\": \"OT\", # mean\n",
    "        \"Obsessional Beliefs - Perfectionism/ Intolerance of uncertainty\": 'OB_PERF', # mean\n",
    "        # \"17-Perfectionism CMDA\": 'CMDA',\n",
    "        \"Perfect PS-Personal Standards (7 items mean)\" : 'PS', # mean\n",
    "        \"Guilt sensitivity\": 'G_SE', # mean\n",
    "        \"Nietolerancja wieloznaczności-FULL\": 'AMB', # mean\n",
    "        \"Preferowanie przewidywalności-FULL\": 'PRED', # mean\n",
    "        \"High standards from Maximization Full Scale\" : 'STAND',   # mean\n",
    "    }\n",
    "\n",
    "    data_df = data_df.rename(columns=columns_dict)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a6b99d-7821-44cb-b669-8ce682ce193c",
   "metadata": {},
   "source": [
    "- read Opus train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "9db8c673-5477-4126-b09d-870a8fcd9477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled file found. Loading pickled data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "df_name = \"GNG_autoreject_3_5\"\n",
    "# df_name = \"GNG_reject_auto_3-5\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "info_filename = \"../data/scales/Sonata_scales.csv\"\n",
    "\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_train_opus_df = pd.read_pickle(pickled_data_filename)\n",
    "    epochs_train_opus_df.name = df_name\n",
    "    epochs_train_opus_df = change_column_names(epochs_train_opus_df)\n",
    "    print(\"Done\")\n",
    "    pass\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_train_opus_df = create_df_data(\n",
    "        test_participants=False, info=\"all\", personal=False, info_filename=info_filename\n",
    "    )\n",
    "    epochs_train_opus_df.name = df_name\n",
    "    epochs_train_opus_df = change_column_names(epochs_train_opus_df)\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_train_opus_df.to_pickle(\"../data/\" + epochs_train_opus_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ffa25d09-4ebb-4c3e-a89a-8ae1b80c7a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 188)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train_opus_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5b87e8aa-5ca4-4735-a004-7fd9a5a414d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train_opus_df['STAI-T'] = epochs_train_opus_df['STAI-T'].apply(lambda x: x/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abffccca-5b70-4843-b39f-c90e38ce92a8",
   "metadata": {},
   "source": [
    "- read Sonata train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "06f6b138-bc55-49c5-9eff-940a01b5bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled file found. Loading pickled data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "df_name = \"GNG_autoreject_sonata_3_5_stai\"\n",
    "# df_name = \"GNG_reject_auto_3-5\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "info_filename = \"../data/scales/Sonata_scales.csv\"\n",
    "\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_train_sonata_df = pd.read_pickle(pickled_data_filename)\n",
    "    epochs_train_sonata_df.name = df_name\n",
    "    epochs_train_sonata_df = change_column_names(epochs_train_sonata_df)\n",
    "    print(\"Done\")\n",
    "    pass\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_train_sonata_df = create_df_data(\n",
    "        test_participants=False, info=\"all\", personal=False, info_filename=info_filename\n",
    "    )\n",
    "    epochs_train_sonata_df.name = df_name\n",
    "    epochs_train_sonata_df = change_column_names(epochs_train_sonata_df)\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_train_sonata_df.to_pickle(\"../data/\" + epochs_train_sonata_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "23c4ef30-2d15-43d6-966e-a4118714233b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 110)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train_sonata_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b200393a-2f77-480d-b973-c92c6c64fa1a",
   "metadata": {},
   "source": [
    "Refine some data from questionnaries to reconcile data from two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ffe2568a-e1d2-4c8b-92f7-151b862e1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train_sonata_df.loc[epochs_train_sonata_df['Sex'] == 'Osoba niebinarna', 'Sex'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3e41a7a0-7541-4020-87ae-7f305d7a157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize DASS-21 subscales scores to mean\n",
    "epochs_train_sonata_df['DASS-21 Stress'] = epochs_train_sonata_df['DASS-21 Stress'].apply(lambda x: (x + 7)/7)\n",
    "epochs_train_sonata_df['DASS-21 Anx'] = epochs_train_sonata_df['DASS-21 Anx'].apply(lambda x: (x + 7)/7)\n",
    "epochs_train_sonata_df['DASS-21 Dep'] = epochs_train_sonata_df['DASS-21 Dep'].apply(lambda x: (x + 7)/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7219ac12-4837-41a1-abad-29ae5fdd4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize STAI state scale to mean (divide by amount of items in subscale)\n",
    "epochs_train_sonata_df['STAI-T'] = epochs_train_sonata_df['STAI-T'].apply(lambda x: x/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c2b04671-603a-4678-8889-8f77cf9a28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing value in STAI-S Diff score\n",
    "epochs_train_sonata_df.loc[epochs_train_sonata_df['STAI-S Diff'] == 'None', 'STAI-S Diff'] = None\n",
    "epochs_train_sonata_df['STAI-S Diff'] = np.array(epochs_train_sonata_df['STAI-S Diff'].to_list()).astype(np.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "78171035-125b-4a1b-8b00-a8a8a7cfc594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_train_sonata_df['STAI-S Diff'] = epochs_train_sonata_df['STAI-S Diff'].fillna(epochs_train_sonata_df['STAI-S Diff'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055815fa-0d47-4bdd-9caf-51d60ced5d91",
   "metadata": {},
   "source": [
    "#### Read data for external testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7bdc7-6af8-4c64-957b-33f71c7d5d6e",
   "metadata": {},
   "source": [
    "- read Opus test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "8c990ac1-14fc-4d0c-bf5d-d96f076e1e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled file found. Loading pickled data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "df_name = \"GNG_autoreject_3_5_test_performance\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "# info_filename = \"../data/Demographic_Questionnaires_Behavioral_Results_N=163.csv\"\n",
    "# info_filename = \"../data/scales/all_scales.csv\"\n",
    "info_filename = \"../data/scales/Sonata_scales.csv\"\n",
    "\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_test_opus_df = pd.read_pickle(pickled_data_filename)\n",
    "    epochs_test_opus_df.name = df_name\n",
    "    epochs_test_opus_df = change_column_names(epochs_test_opus_df)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_test_opus_df = create_df_data(\n",
    "        test_participants=True, info=\"all\", personal=False, info_filename=info_filename\n",
    "    )\n",
    "    epochs_test_opus_df.name = df_name\n",
    "    epochs_test_opus_df = change_column_names(epochs_test_opus_df)\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_test_opus_df.to_pickle(\"../data/\" + epochs_test_opus_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "271cd307-5952-47a6-87f9-2a482da8924e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 164)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_test_opus_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "182b6d20-9599-4d6f-bf32-f8b98c14e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_test_opus_df['STAI-T'] = epochs_test_opus_df['STAI-T'].apply(lambda x: x/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b716470-7b11-4423-ac6d-cc65f2446aa3",
   "metadata": {},
   "source": [
    "- read Sonata test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "7f54d80f-6c7f-4c9c-a4a2-4564dd15c949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled file found. Loading pickled data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "df_name = \"GNG_autoreject_sonata_3_5_test_stai\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "# info_filename = \"../data/Demographic_Questionnaires_Behavioral_Results_N=163.csv\"\n",
    "# info_filename = \"../data/scales/all_scales.csv\"\n",
    "info_filename = \"../data/scales/Sonata_scales.csv\"\n",
    "\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_test_sonata_df = pd.read_pickle(pickled_data_filename)\n",
    "    epochs_test_sonata_df.name = df_name\n",
    "    epochs_test_sonata_df = change_column_names(epochs_test_sonata_df)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_test_sonata_df = create_df_data(\n",
    "        test_participants=True, info=\"all\", personal=False, info_filename=info_filename\n",
    "    )\n",
    "    epochs_test_sonata_df.name = df_name\n",
    "    epochs_test_sonata_df = change_column_names(epochs_test_sonata_df)\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_test_sonata_df.to_pickle(\"../data/\" + epochs_test_sonata_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "406ede1f-481c-4e12-9613-db9eeb0c147a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 110)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_test_sonata_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea677c-4f7e-4ec9-b034-823aaa526172",
   "metadata": {},
   "source": [
    "Refine some data from questionnaries to reconcile data from two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "eb09c36d-6613-4093-b6aa-4af0c49b3574",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_test_sonata_df.loc[epochs_test_sonata_df['Sex'] == 'Osoba niebinarna', 'Sex'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e80e3cdb-5907-48e4-99f3-89d2580780cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize DASS-21 subscales scores to mean\n",
    "epochs_test_sonata_df['DASS-21 Stress'] = epochs_test_sonata_df['DASS-21 Stress'].apply(lambda x: (x + 7)/7)\n",
    "epochs_test_sonata_df['DASS-21 Anx'] = epochs_test_sonata_df['DASS-21 Anx'].apply(lambda x: (x + 7)/7)\n",
    "epochs_test_sonata_df['DASS-21 Dep'] = epochs_test_sonata_df['DASS-21 Dep'].apply(lambda x: (x + 7)/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ba725e66-37f2-4b5d-97bc-c509ab15468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize STAI state scale to mean (divide by amount of items in subscale)\n",
    "epochs_test_sonata_df['STAI-T'] = epochs_test_sonata_df['STAI-T'].apply(lambda x: x/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "162b5fa8-e82a-4df8-b9ae-8acaf64a643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing value in STAI-S Diff score\n",
    "epochs_test_sonata_df.loc[epochs_test_sonata_df['STAI-S Diff'] == 'None', 'STAI-S Diff'] = None\n",
    "epochs_test_sonata_df['STAI-S Diff'] = np.array(epochs_test_sonata_df['STAI-S Diff'].to_list()).astype(np.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f715e371-377a-465f-aefa-84cb7b8565cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_test_sonata_df['STAI-S Diff'] = epochs_test_sonata_df['STAI-S Diff'].fillna(epochs_test_sonata_df['STAI-S Diff'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e49fc-28b8-47ef-8a5d-5dd1dcfd915e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "784b4bd7-f3b6-4707-8662-b266913fb3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_columns_list = epochs_train_opus_df.columns.to_list()\n",
    "sonata_columns_list = epochs_train_sonata_df.columns.to_list()\n",
    "\n",
    "columns = list(set(opus_columns_list) & set(sonata_columns_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "f0cec6de-6ce0-458f-ad00-79de41daa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train_sonata_df = epochs_train_sonata_df[columns]\n",
    "epochs_train_opus_df = epochs_train_opus_df[columns]\n",
    "\n",
    "epochs_test_sonata_df = epochs_test_sonata_df[columns]\n",
    "epochs_test_opus_df = epochs_test_opus_df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a01eda1-84ea-4034-834a-7d56bfd8e828",
   "metadata": {},
   "source": [
    "Create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0f96e09d-e718-4a2e-9555-41c942673904",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train_df = pd.concat([epochs_train_sonata_df, epochs_train_opus_df], ignore_index=True)\n",
    "epochs_test_df = pd.concat([epochs_test_sonata_df, epochs_test_opus_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e2f7d8-49ac-4955-b8ff-9af12f4a3dd3",
   "metadata": {},
   "source": [
    "#### Chose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e1b99eb8-aa51-447d-81f2-cc7018f304df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False\n",
    "dataset = 'test' if test else 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "39b940ac-d7f7-44fd-bbda-6a9503a388fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df = epochs_train_df if not test else epochs_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8e98fe0f-a0ae-4022-93d8-b2382a82692e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 40)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bdb66d-6873-42d3-9290-11c006ba28ea",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "97a99ef1-7836-4575-8c1b-ea6f608fe3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "a = epochs_df[['Sex']].to_numpy().astype(int).flatten()\n",
    "print(a.sum())\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "bcdd97c2-eb5e-4485-97c2-6dd04ff0d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi = ['Fz']\n",
    "\n",
    "# for index in range(0, len(epochs_filtered)):\n",
    "#     epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))\n",
    "#     epochs = [epochs_df_copy.iloc[index]['epoch']]\n",
    "#     epochs_ = [epoch.copy().pick(roi) for epoch in epochs]\n",
    "#     epochs = mne.concatenate_epochs(epochs_)\n",
    "    \n",
    "#     evokeds = [epochs[name].copy().crop(tmin=-0.1, tmax=0.6).iter_evoked() for name in ('error_response', 'correct_response')]\n",
    "    \n",
    "#     plt.figure(index)\n",
    "    \n",
    "#     fig = mne.viz.plot_compare_evokeds(\n",
    "#     [list(evokeds[0]),list(evokeds[1])],\n",
    "#     show=False,\n",
    "#     ci=True,\n",
    "#     )\n",
    "\n",
    "#     axes = fig[0].axes\n",
    "\n",
    "#     axes[0].axhline(y=1, color='gray')\n",
    "#     axes[0].axhline(y=6, color='gray')\n",
    "\n",
    "#     # plt.axhline(y = 1*1e-6, color='gray', ls='--')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3f0b5a87-27b3-4bd3-b487-be6e5a3330b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi = ['Fz']\n",
    "# index= 0 # 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3024d376-15e4-4165-b675-ddb272f088c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))\n",
    "# epochs = [epochs_df_copy.iloc[index]['epoch']]\n",
    "# epochs_ = [epoch.copy().pick(roi) for epoch in epochs]\n",
    "# epochs = mne.concatenate_epochs(epochs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "70d0bdf1-f24f-48ee-ba2b-1f2b50be6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evokeds = [epochs[name].copy().crop(tmin=-0.1, tmax=0.6).iter_evoked() for name in ('error_response', 'correct_response')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "5e689efb-fff8-44e9-8995-f9ef8ba4f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.plot_compare_evokeds(\n",
    "#     [list(evokeds[0]),list(evokeds[1])],\n",
    "#     show=False,\n",
    "#     ci=True,\n",
    "# )\n",
    "\n",
    "# axes = fig[0].axes\n",
    "\n",
    "# axes[0].axhline(y=1, color='gray')\n",
    "# axes[0].axhline(y=6, color='gray')\n",
    "\n",
    "# # plt.axhline(y = 1*1e-6, color='gray', ls='--')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4703671a-3adc-4286-8bf2-eb3d9dbd70bc",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d0fd1-f37a-494c-b39f-ebb93f639a11",
   "metadata": {},
   "source": [
    "#### Extract EEG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "bc4a1ed2-674f-4926-98ad-70f1c79fd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeakToPeakBins(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, zero_index=2):\n",
    "        super().__init__()\n",
    "        self.zero_index = zero_index # how many bins before zero the signal started\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "                \n",
    "        peak_to_peaks = np.array(\n",
    "            [\n",
    "                np.array([[max(component[self.zero_index:-1]) - min(component[0:self.zero_index+1])] for component in participant])\n",
    "                for participant in X\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(f\"IN ERN min max RETURN SHAPE: {peak_to_peaks.shape}\")\n",
    "        return peak_to_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a86e297f-bef9-4319-9301-30398f152836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeakToPeakBinsFourComponent(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, zero_index=5):\n",
    "        super().__init__()\n",
    "        self.zero_index = zero_index # how many bins before zero the signal started\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        X_out = []\n",
    "        \n",
    "        for participant in X:\n",
    "            component_0 = participant[0]\n",
    "            component_1 = participant[1]\n",
    "            component_2 = participant[2]\n",
    "            component_3 = participant[3]\n",
    "            \n",
    "            component_0_ptp = np.array([max(component_0[1:self.zero_index+1]) - min(component_0[self.zero_index-1:-1])])\n",
    "            component_2_ptp = np.array([max(component_2[self.zero_index-1:-1]) - min(component_2[1:self.zero_index+1])])\n",
    "            \n",
    "            peak_to_peaks = np.array([component_0_ptp, component_2_ptp])\n",
    "            \n",
    "            X_out.append(peak_to_peaks)\n",
    "        \n",
    "        X_out = np.array(X_out)\n",
    "\n",
    "        print(f\"IN 4 COMP PTP RETURN SHAPE: {X_out.shape}\")\n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0dc11f-ab40-4c36-a825-415f4d17b0bd",
   "metadata": {},
   "source": [
    " 1. ICA (Fast ICA)\n",
    " \n",
    " - ROI\n",
    " - time window: -100 to 200 ms\n",
    " - ICA(n=4)\n",
    " - binning: 24ms (6 tp)\n",
    " - peak-to-peak amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "25e55768-649e-486d-a1aa-59d6b7c2863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints_count = 78\n",
    "spatial_filter_components = 4\n",
    "bin_width = 6\n",
    "# roi = [\"Fpz\", \"AFz\", \"F3\", \"F1\", \"Fz\", \"F2\", \"F4\", \"FC3\", \"FC1\", \"FCz\", \"FC2\", \"FC4\", \"C3\", \"C1\",\"Cz\", \"C2\", \"C4\",]\n",
    "roi = [\"F3\", \"F1\", \"Fz\", \"F2\", \"F4\", \"FC3\", \"FC1\", \"FCz\", \"FC2\", \"FC4\", \"C3\", \"C1\",\"Cz\", \"C2\", \"C4\", \"CP3\", \"CP1\", \"CPz\", \"CP2\", \"CP4\"] # to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "baf26c15-56b7-4827-805b-466b53798879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fd39b2c0-eee2-4b89-ac3c-5785d6fd786e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 20, 78)\n",
      "IN 4 COMP PTP RETURN SHAPE: (112, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "if test:\n",
    "    epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "    preprocessed_X_PCA_6bins = pipeline_ICA.transform(epochs_df_copy)\n",
    "    preprocessed_X_PCA_6bins = preprocessed_X_PCA_6bins.reshape(preprocessed_X_PCA_6bins.shape[0], -1)\n",
    "    \n",
    "else:\n",
    "    epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "    pipeline_ICA = Pipeline([\n",
    "        (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "        (\"trim\", EpochTrim(tmin=-0.1, tmax=0.20)),\n",
    "        (\"average\", Evoked()),\n",
    "        ('extract_averaged_data', ExtractData()),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\"spatial_filter\",FastICA(n_components=spatial_filter_components, random_state=random_state)),\n",
    "        (\"spatial_filter_postprocessing\",SpatialFilterPostprocessing(timepoints_count=timepoints_count)),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\"binning\", BinTransformer(step=6)),\n",
    "        # (\"centering\", CenteredSignalAfterBaseline_this2()),\n",
    "        # (\"ern_data_extraction\", ErnTransformer(stop_ern_bin=6)),\n",
    "        (\"peak-to-peak\", PeakToPeakBinsFourComponent(5)),\n",
    "    ]).fit(epochs_df_copy)\n",
    "\n",
    "    preprocessed_X_PCA_6bins = pipeline_ICA.transform(epochs_df_copy)\n",
    "\n",
    "    preprocessed_X_PCA_6bins = preprocessed_X_PCA_6bins.reshape(preprocessed_X_PCA_6bins.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c3d934e3-4520-4543-889f-bbcc3c066bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 2)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_PCA_6bins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9cc4c-083f-41a8-823e-b295966c91a4",
   "metadata": {},
   "source": [
    "2. ERN\n",
    "\n",
    "- ROI: Fz\n",
    "- time window: 0 - 100 ms\n",
    "- mean amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "772bab73-107f-4fb6-88fd-23c0818c23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = [\n",
    "    \"Fz\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "632787dc-ac9c-45f9-8a96-d4cf8946bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 1, 27)\n",
      "(260, 1, 27)\n"
     ]
    }
   ],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "ern_pipeline = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=0, tmax=0.1)),\n",
    "    (\"average\", Evoked()),\n",
    "    ('extract_averaged_data', ExtractData()),\n",
    "    (\"mean_amplitude\", AverageSignal()),\n",
    "    \n",
    "]).fit(epochs_df_copy)\n",
    "\n",
    "preprocessed_X_ern = ern_pipeline.transform(epochs_df_copy)\n",
    "preprocessed_X_ern = preprocessed_X_ern.reshape(preprocessed_X_ern.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "1ac9a858-21a4-4ec3-896d-f2dcc58aa24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_ern.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809644a-3897-4998-9dea-43400edfdcf4",
   "metadata": {},
   "source": [
    "3. CRN\n",
    "\n",
    "- ROI: Fz\n",
    "- time window: 0 - 100 ms\n",
    "- mean amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8fb9fd22-ce0b-47e3-8e3e-b9c0b9bee2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = [\n",
    "    \"Fz\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f107e50f-6552-4a38-87cc-f388ab629c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 1, 27)\n",
      "(260, 1, 27)\n"
     ]
    }
   ],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "crn_pipeline = Pipeline([\n",
    "   (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=0, tmax=0.1)),\n",
    "    (\"average\", Evoked(condition='correct_response')),\n",
    "    ('extract_averaged_data', ExtractData()),\n",
    "    (\"mean_amplitude\", AverageSignal()),\n",
    "    \n",
    "]).fit(epochs_df_copy)\n",
    "\n",
    "preprocessed_X_crn = crn_pipeline.transform(epochs_df_copy)\n",
    "preprocessed_X_crn = preprocessed_X_crn.reshape(preprocessed_X_crn.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f8315dd8-afa1-4011-924b-c8309a106c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_crn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6536a-c06a-449e-9b47-00896ac1de3b",
   "metadata": {},
   "source": [
    "4. ERN lateralization of peak\n",
    "\n",
    "- ROI\n",
    "- time window: 0 - 100 ms\n",
    "- mean amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "54cf0ba8-54b5-466b-b0d0-20a17e10eed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_channels_with_peaks(evoked, roi):\n",
    "    '''\n",
    "    todo\n",
    "    '''\n",
    "    data = evoked.get_data()\n",
    "    \n",
    "    ch_min = 'Fpz'\n",
    "    amp_min = 200\n",
    "    for channel_index, channel in enumerate(roi):\n",
    "        # plt.plot(np.arange(0, 27), data[channel_index])\n",
    "        if min(data[channel_index]) < amp_min:\n",
    "            amp_min = min(data[channel_index])\n",
    "            ch_min = channel\n",
    "    return ch_min, amp_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3b81a8d9-9930-4718-82f5-7a88636d2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels_with_maximal_signal(evoked, roi):\n",
    "    '''\n",
    "    todo\n",
    "    '''\n",
    "    data = evoked.get_data()\n",
    "    \n",
    "    ch_min = 'Fpz'\n",
    "    amp_min = 200\n",
    "    for channel_index, channel in enumerate(roi):\n",
    "        # plt.plot(np.arange(0, 27), data[channel_index])\n",
    "        if (data[channel_index]).mean() < amp_min:\n",
    "            amp_min = data[channel_index].mean()\n",
    "            ch_min = channel\n",
    "    return ch_min, amp_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "feb34a13-6b20-41fa-aefc-1f4c4bf25d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define channels for maximal signal search\n",
    "roi = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"F3\", \"Fz\", \"F4\",\n",
    "    \"FC3\", \"FCz\", \"FC4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4c895184-0fe7-40a2-9578-555e4b23bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict())) # if use peak, signal must be filtered with strong (e.g. 10 Hz) lowpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8bbaa84b-b978-441a-8b07-bcfc753a61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = 0.0, 0.08\n",
    "channels_type_peak_ern = []\n",
    "channels_type_mean_ern = []\n",
    "\n",
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='error_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()\n",
    "\n",
    "######\n",
    "for subject in X:\n",
    "    ch, amp = get_channels_with_peaks(subject[0], roi)\n",
    "    ch_m, amp_m = get_channels_with_maximal_signal(subject[0], roi)\n",
    "    # print(f\"Channel {ch}\\n Amplitude {amp}\")\n",
    "    channels_type_peak_ern.append(ch)\n",
    "    channels_type_mean_ern.append(ch_m)\n",
    "    \n",
    "# change names of channels to: 0 = midline ; 1 = not midline (left or right)\n",
    "channels_type_peak_ern = list(map(lambda x: 0 if x[-1] == 'z' else 1, channels_type_peak_ern))\n",
    "channels_type_peak_ern = np.array(channels_type_peak_ern).reshape(len(channels_type_peak_ern), -1)    \n",
    "\n",
    "channels_type_mean_ern = list(map(lambda x: 0 if x[-1] == 'z' else 1, channels_type_mean_ern))\n",
    "channels_type_mean_ern = np.array(channels_type_mean_ern).reshape(len(channels_type_mean_ern), -1) \n",
    "\n",
    "channels_type_ern_peak = channels_type_peak_ern\n",
    "channels_type_ern_mean = channels_type_mean_ern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "31970637-5980-41c1-9750-500e87996393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_type_ern = channels_type_ern_mean\n",
    "channels_type_ern.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f4be3-b907-446a-9391-57b032fe7e36",
   "metadata": {},
   "source": [
    "5. CRN lateralization of peak\n",
    "\n",
    "- ROI\n",
    "- time window: 0 - 100 ms\n",
    "- mean amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "468b96fe-a702-403e-8972-f4750691591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"F3\", \"Fz\", \"F4\",\n",
    "    \"FC3\", \"FCz\", \"FC4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "744fb685-41ba-472c-a296-b41cc6319693",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "bfb9c417-41b4-48ba-97c1-33d7c3b0662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = 0.02, 0.08\n",
    "peaks_crn = []\n",
    "channels_type_peak_crn = []\n",
    "channels_type_mean_crn = []\n",
    "\n",
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='correct_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()\n",
    "\n",
    "######\n",
    "for subject in X:\n",
    "    ch, amp = get_channels_with_peaks(subject[0], roi)\n",
    "    ch_m, amp_m = get_channels_with_maximal_signal(subject[0], roi)\n",
    "    # print(f\"Channel {ch}\\n Amplitude {amp}\")\n",
    "    channels_type_peak_crn.append(ch)\n",
    "    channels_type_mean_crn.append(ch_m)\n",
    "\n",
    "# change names of channels to: 0 = midline ; 1 = not midline (left or right)\n",
    "channels_type_peak_crn = list(map(lambda x: 0 if x[-1] == 'z' else 1, channels_type_peak_crn))\n",
    "channels_type_peak_crn = np.array(channels_type_peak_crn).reshape(len(channels_type_peak_crn), -1) \n",
    "\n",
    "channels_type_mean_crn = list(map(lambda x: 0 if x[-1] == 'z' else 1, channels_type_mean_crn))\n",
    "channels_type_mean_crn = np.array(channels_type_mean_crn).reshape(len(channels_type_mean_crn), -1)   \n",
    "\n",
    "channels_type_crn_peak = channels_type_peak_crn\n",
    "channels_type_crn_mean = channels_type_mean_crn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "91374e91-675e-4033-b724-e48cc2ff8665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_type_crn = channels_type_crn_mean\n",
    "channels_type_crn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e0934-882f-4c13-bbba-5aed64e040bd",
   "metadata": {},
   "source": [
    "6. ERN latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c195d-efda-4d92-818f-2c9e1dd7743f",
   "metadata": {},
   "source": [
    "**1. Fractional area latency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d80e0bd2-5952-4cab-9b60-f5fcd1720a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractional_negative_area_latency(evoked, fraction=0.5, tmin=0.0, tmax=0.5, threshold = 0.0):\n",
    "    subject_data = evoked.get_data()\n",
    "    x = np.linspace(tmin, tmax, subject_data.shape[-1])\n",
    "    # print(x)\n",
    "    y = subject_data.flatten()\n",
    "    \n",
    "    # get only negative part of signal\n",
    "    y_negative = [abs(y_item) if y_item < threshold else 0 for y_item in y]\n",
    "    \n",
    "    # calculate area under the signal\n",
    "    area = abs(simpson(y_negative, x))\n",
    "    \n",
    "    if area != 0.0:\n",
    "        fractional_area = area * fraction\n",
    "    \n",
    "        # search for latency point (x) which split area according to fraction provided \n",
    "        current_area = 0\n",
    "        fractional_area_index = 0\n",
    "        i = 2\n",
    "        while abs(simpson(y_negative[:i], x[:i])) <= fractional_area:\n",
    "            current_area = abs(simpson(y_negative[:i], x[:i]))\n",
    "            fractional_area_index = i\n",
    "            i+=1\n",
    "            \n",
    "        # print(f'{fractional_area_index}; {x[fractional_area_index]}')\n",
    "        # print(x)\n",
    "        \n",
    "        return (fractional_area_index, x[fractional_area_index])    \n",
    "    else:\n",
    "        print('No area detected')\n",
    "        return (None, None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c08aa2-c473-4cf2-99ae-ae060aa71f78",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "af1a2ab3-e09a-4465-88ea-ee18f38c7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ['Fz']\n",
    "tmin = -0.05\n",
    "tmax = 0.2\n",
    "threshold = 1*1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f52e32-9503-4c1f-adfa-b58441b5d07e",
   "metadata": {},
   "source": [
    "Estimate fractional area latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4e5f1b4e-ebd9-488f-9fb6-0a052bc2b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "5b876351-bd1e-4312-8eda-57238b7d4e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='error_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f1f3d05b-8df2-4a1a-9a30-2957a3031ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fractional_latencies = []\n",
    "for i in range(0, len(X)):        \n",
    "    subject = X[i][0]\n",
    "    evoked = subject\n",
    "    # print(f\"Index: {i}\")\n",
    "    this_latency = fractional_negative_area_latency(evoked, fraction=0.5, tmin=tmin, tmax=tmax, threshold=threshold)\n",
    "    fractional_latencies.append(this_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "83a6c738-7572-478a-ad64-16c95cb52076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractional_latencies_ern = list(map(lambda x: x[1] ,fractional_latencies))\n",
    "fractional_latencies_ern = np.array(fractional_latencies_ern).reshape(-1,1)\n",
    "fractional_latencies_ern.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383f2c19-7ba8-4405-bcdf-933f66877fea",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6b0ab452-339e-439b-a118-d235443c97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi = ['Fz']\n",
    "# tmin = -0.05\n",
    "# tmax = 0.2\n",
    "\n",
    "# epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "# X = Pipeline([\n",
    "#     (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "#     (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "#     (\"average\", Evoked(condition='error_response')),\n",
    "# ]).fit_transform(epochs_df_copy)\n",
    "\n",
    "# X = X[['evoked']].to_numpy()\n",
    "\n",
    "# for index in range(0, len(X)):\n",
    "#     plt.figure(index)\n",
    "    \n",
    "#     subject_data = X[index][0].get_data()\n",
    "#     x = np.linspace(tmin, tmax, subject_data.shape[-1])\n",
    "#     y = subject_data.flatten()\n",
    "#     # print(f\"Index: {i}\")\n",
    "    \n",
    "#     y_negative = [abs(y_item) if y_item < 0.1*1e-5 else 0 for y_item in y]\n",
    "#     # calculate area under the signal\n",
    "#     area = abs(simpson(y_negative,x))\n",
    "#     fractional_area = area * 0.5\n",
    "    \n",
    "#     if fractional_area != 0:\n",
    "#         # search for latency point (x) which split area according to fraction provided \n",
    "#         current_area = 0\n",
    "#         fractional_area_index = 0\n",
    "#         i = 2\n",
    "#         if area != 0.0:\n",
    "#             while abs(simpson(y_negative[:i], x[:i])) <= fractional_area:\n",
    "#                 current_area = abs(simpson(y_negative[:i], x[:i]))\n",
    "#                 fractional_area_index = i\n",
    "#                 i+=1\n",
    "\n",
    "#         plt.plot(x,y)\n",
    "#         plt.plot(x, y_negative)\n",
    "#         plt.axvline(x=x[fractional_area_index])\n",
    "#     else:\n",
    "#         fractional_area_index = 0\n",
    "#         plt.plot(x,y)\n",
    "#         plt.axvline(x=x[fractional_area_index], color='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184dcf8-edb9-48e1-b461-e76283f15156",
   "metadata": {},
   "source": [
    "**2. Peak Latency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7460d0e6-8643-432b-9897-b095a2c03832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_latency(evoked, tmin=0.0, tmax=0.5, ignore_peaks_before=0.0, favour_peaks_after = 0.0, ):\n",
    "    '''\n",
    "    Most negative peak\n",
    "    '''\n",
    "    subject_data = evoked.get_data()\n",
    "    x = np.linspace(tmin, tmax, subject_data.shape[-1]) * 100\n",
    "    y = subject_data.flatten()\n",
    "\n",
    "    y_spl = UnivariateSpline(x,y,s=0,k=4)\n",
    "    y_spl_1d = y_spl.derivative(n=1) # funkcja 1 pochodnej\n",
    "\n",
    "    x_range = np.linspace(x[0],x[-1],1000)\n",
    "\n",
    "    zeros = y_spl_1d.roots() # first derrivate zero -> peak\n",
    "\n",
    "    personal_peaks = []\n",
    "    lower_peak_x = 0\n",
    "    step  = 0.6\n",
    "\n",
    "    if len(zeros) > 0:\n",
    "        for zero in zeros:\n",
    "            if (zero > ignore_peaks_before*100):\n",
    "                lower_peak_x = zero \n",
    "                personal_peaks.append((lower_peak_x, y_spl(lower_peak_x)))\n",
    "\n",
    "        if len(personal_peaks) > 0:\n",
    "            min_index = np.argmin(personal_peaks, axis=0)[-1]\n",
    "            latency_value = personal_peaks[min_index][0]\n",
    "\n",
    "            while latency_value < favour_peaks_after and len(personal_peaks) > 1:\n",
    "                personal_peaks.pop(min_index)\n",
    "                min_index = np.argmin(personal_peaks, axis=0)[-1]\n",
    "                latency_value = personal_peaks[min_index][0]   \n",
    "        else:\n",
    "            latency_value = None \n",
    "    else:\n",
    "        latency_value = None\n",
    "        \n",
    "    return latency_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbccdf-ab21-4a7e-9710-be28ece8bef9",
   "metadata": {},
   "source": [
    "Lowpass data at 25 Hz for peak finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fce6fef9-12dc-4e28-91be-74a30bc72bb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[221], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lowpass \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25.0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m epochs_df_to_filter \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m epochs_filtered \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlowpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, BandpassFilter(h_freq\u001b[38;5;241m=\u001b[39mlowpass)),\n\u001b[1;32m      7\u001b[0m ])\u001b[38;5;241m.\u001b[39mfit_transform(epochs_df_to_filter)\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/Work/errorNet/venv/lib/python3.8/site-packages/mne/epochs.py:1691\u001b[0m, in \u001b[0;36mBaseEpochs.__deepcopy__\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         memodict[\u001b[38;5;28mid\u001b[39m(v)] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1691\u001b[0m         v \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemodict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1692\u001b[0m     result\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lowpass = 25.0\n",
    "\n",
    "epochs_df_to_filter = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "epochs_filtered = Pipeline([\n",
    "    (\"lowpass\", BandpassFilter(h_freq=lowpass)),\n",
    "]).fit_transform(epochs_df_to_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca54bb-467d-4870-9c55-533981c769e2",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f7d70-c0f5-49d1-b336-63f141d40f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = -0.05 # window start time\n",
    "tmax = 0.12 # window stop time || peak search stop time\n",
    "ignore_peaks_before = -0.025 # peak serach start time\n",
    "roi = ['Fz']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f231885-903e-487b-b76d-aa26d8507106",
   "metadata": {},
   "source": [
    "Estimate peak latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "id": "ec3ee78c-cc2f-4de1-9218-f655bc485317",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "id": "94ff9848-267c-4b18-938a-3447c4ce621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='error_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "id": "730c35a3-fb74-4716-8cbf-1e5dfcc927bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_latencies = []\n",
    "for i in range(0, len(X)):        \n",
    "    subject = X[i][0]\n",
    "    evoked = subject\n",
    "    # print(f\"Index: {i}\")\n",
    "    this_latency = peak_latency(evoked, tmin=tmin, tmax=tmax, ignore_peaks_before=ignore_peaks_before, favour_peaks_after=0.0)\n",
    "    peak_latencies.append(this_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "c49a8d1b-f2cf-4a7e-8189-bc5efc8be242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1)"
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_latencies_ern = np.array(peak_latencies).reshape(-1,1)\n",
    "peak_latencies_ern.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09b4b7-cb20-4d39-a451-f2bca4b139b7",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "id": "22299859-a7b4-4ac3-b0a8-3828d5b55873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowpass = 20.0\n",
    "\n",
    "# epochs_df_to_filter = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "# epochs_filtered = Pipeline([\n",
    "#     (\"lowpass\", BandpassFilter(h_freq=lowpass)),\n",
    "# ]).fit_transform(epochs_df_to_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "id": "6494f1f4-bc46-4389-a7a7-3a3d1b74295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmin = -0.05 # window start time\n",
    "# tmax = 0.12 # window stop time || peak search stop time\n",
    "# ignore_peaks_before = -0.025 # peak serach start time\n",
    "\n",
    "# roi = ['Fz']\n",
    "\n",
    "# epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))\n",
    "\n",
    "# X = Pipeline([\n",
    "#     (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "#     (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "#     (\"average\", Evoked(condition='error_response')),\n",
    "# ]).fit_transform(epochs_df_copy)\n",
    "\n",
    "# X = X[['evoked']].to_numpy()\n",
    "\n",
    "# peaks = []\n",
    "# most_negative_peaks = []\n",
    "\n",
    "# for index in range(0, len(X)):\n",
    "#     plt.figure(index)\n",
    "    \n",
    "#     subject_data = X[index][0].get_data()\n",
    "    \n",
    "#     x = np.linspace(tmin, tmax, subject_data.shape[-1]) * 100\n",
    "#     y = subject_data.flatten()\n",
    "    \n",
    "#     y_spl = UnivariateSpline(x,y,s=0,k=4)\n",
    "#     y_spl_1d = y_spl.derivative(n=1) # funkcja 1 pochodnej\n",
    "\n",
    "#     x_range = np.linspace(x[0],x[-1],1000)\n",
    "    \n",
    "#     plt.plot(x_range,y_spl(x_range)) # funkcja\n",
    "#     plt.plot(x_range,y_spl_1d(x_range)) # 1 pochodna\n",
    "#     plt.axhline(y = 0.0, color='gray') # zero\n",
    "#     plt.axvline(x = 0.0, color='gray', ls='--') # zero\n",
    "#     plt.text(0,0,i)\n",
    "\n",
    "#     zeros = y_spl_1d.roots() # first derrivate zero -> peak\n",
    "\n",
    "#     plt.scatter(x=zeros, y=[0]*len(zeros))\n",
    "\n",
    "#     # define THIS peak\n",
    "    \n",
    "#     personal_peaks = []\n",
    "#     lower_peak_x = 0\n",
    "#     # max_lower_value = 2000\n",
    "#     step  = 0.6\n",
    "\n",
    "#     for zero in zeros:\n",
    "#         if (zero > ignore_peaks_before*100):\n",
    "#             lower_peak_x = zero \n",
    "#             personal_peaks.append((lower_peak_x, y_spl(lower_peak_x)))\n",
    "#         # max_lower_value = y_spl(zero) if y_spl(zero) < max_lower_value and (zero > ignore_peaks_before*100) else max_lower_value\n",
    "#     peaks.append(personal_peaks) \n",
    "#         # if y_spl(zero) < max_lower_value and zero > -2.5:\n",
    "#     for index_2, erns in enumerate(personal_peaks):\n",
    "#         x_ = erns[0]\n",
    "#         plt.scatter(x=x_, y=[0]*len([x_]), color='red')\n",
    "        \n",
    "#     peaks_ = peaks.copy()\n",
    "\n",
    "#     peak_latency = []\n",
    "#     for person in peaks_:\n",
    "#         min_index = np.argmin(person, axis=0)[-1]\n",
    "#         latency_value = person[min_index][0]\n",
    "\n",
    "#         while latency_value < 0 and len(person) > 1:\n",
    "#             person.pop(min_index)\n",
    "#             min_index = np.argmin(person, axis=0)[-1]\n",
    "#             latency_value = person[min_index][0]    \n",
    "#     plt.scatter(x=latency_value, y=[0]*len([latency_value]), color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "da2fa3b3-9f9a-4cc2-a1cd-d9c8341e7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks_ = peaks.copy()\n",
    "# peak_latency = []\n",
    "\n",
    "# for person in peaks_:\n",
    "#     min_index = np.argmin(person, axis=0)[-1]\n",
    "#     latency_value = person[min_index][0]\n",
    "\n",
    "#     while latency_value < 0 and len(person) > 1:\n",
    "#         person.pop(min_index)\n",
    "#         min_index = np.argmin(person, axis=0)[-1]\n",
    "#         latency_value = person[min_index][0]\n",
    "\n",
    "#     peak_latency.append(latency_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "f81fc892-8af5-4e9f-8e3e-0e1f882beda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(peak_latency).reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf9b19c-775a-4534-b204-38a417a20422",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452666fd-0fc3-4cf7-b6e1-afdb8f1f6dd9",
   "metadata": {},
   "source": [
    "CRN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcdc25c-dee9-4b6e-9eaa-809d07a2ca1e",
   "metadata": {},
   "source": [
    "**1. Fractional Area Latency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f2b64-1b66-4c43-8c07-d0b0556d97f4",
   "metadata": {},
   "source": [
    "Parameters: threshold at $2 \\mu V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b9f0b916-767b-4dee-8d15-f3d454bc268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ['Fz']\n",
    "tmin = -0.05\n",
    "tmax = 0.2\n",
    "threshold = 2*1e-6 # przy tym thresholdzie nie lapiemy wszystkich osob 1= 7 os; 2 = wszyscy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a6b29-28dd-4244-8ce4-eea2f724808a",
   "metadata": {},
   "source": [
    "Estimate fractional area latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "afa211f9-1fec-4009-aed7-a511ba36575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "9808b290-0145-437f-860a-ed28d7582371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='correct_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "56e99ebf-31af-4b80-ba4f-90638af325b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fractional_latencies = []\n",
    "for i in range(0, len(X)):        \n",
    "    subject = X[i][0]\n",
    "    evoked = subject\n",
    "    # print(f\"Index: {i}\")\n",
    "    this_latency = fractional_negative_area_latency(evoked, fraction=0.5, tmin=tmin, tmax=tmax, threshold=threshold)\n",
    "    fractional_latencies.append(this_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "11ebf18a-72d3-4826-8c9f-cd3034009ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractional_latencies_crn_2uV = list(map(lambda x: x[1] ,fractional_latencies))\n",
    "fractional_latencies_crn_2uV = np.array(fractional_latencies_crn_2uV).reshape(-1,1)\n",
    "fractional_latencies_crn_2uV.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b54f5e-3699-49a9-9a1c-ca9d5d0e149d",
   "metadata": {},
   "source": [
    "Parameters: threshold at $6 \\mu V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "id": "893d8d35-f4c5-4219-883d-9521bbfc025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ['Fz']\n",
    "tmin = -0.05\n",
    "tmax = 0.2\n",
    "threshold = 6*1e-6 # przy tym thresholdzie nie lapiemy wszystkich osob 1= 7 os; 2 = wszyscy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93538b7c-a49b-494c-865a-f806520d9f87",
   "metadata": {},
   "source": [
    "Estimate fractional area latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "id": "fe881865-1f05-40bd-9c84-45336cd5fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "id": "55765689-e220-4445-b50c-5d186843d304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='correct_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "id": "3ca1c170-84b0-412c-8a1c-bb360dc3bfc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fractional_latencies = []\n",
    "for i in range(0, len(X)):        \n",
    "    subject = X[i][0]\n",
    "    evoked = subject\n",
    "    # print(f\"Index: {i}\")\n",
    "    this_latency = fractional_negative_area_latency(evoked, fraction=0.5, tmin=tmin, tmax=tmax, threshold=threshold)\n",
    "    fractional_latencies.append(this_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "87ea5976-c7f0-4153-b869-459946928fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1)"
      ]
     },
     "execution_count": 1027,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractional_latencies_crn_6uV = list(map(lambda x: x[1] ,fractional_latencies))\n",
    "fractional_latencies_crn_6uV = np.array(fractional_latencies_crn_6uV).reshape(-1,1)\n",
    "fractional_latencies_crn_6uV.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d717da4c-cbf4-4b85-9f2c-37a311eb7ed0",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc3b6f-a668-4c28-aabd-f0f1e5b3674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi = ['Fz']\n",
    "# # tmin = -0.02\n",
    "# # tmax = 0.065\n",
    "# tmin = -0.05\n",
    "# tmax = 0.2\n",
    "# threshold = 2*1e-6\n",
    "# # threshold = 0\n",
    "\n",
    "# epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "# X = Pipeline([\n",
    "#     (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "#     (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "#     (\"average\", Evoked(condition='correct_response')),\n",
    "# ]).fit_transform(epochs_df_copy)\n",
    "\n",
    "# X = X[['evoked']].to_numpy()\n",
    "\n",
    "# for index in range(0, len(X)):\n",
    "#     plt.figure(index)\n",
    "    \n",
    "#     subject_data = X[index][0].get_data()\n",
    "#     x = np.linspace(tmin, tmax, subject_data.shape[-1])\n",
    "#     y = subject_data.flatten()\n",
    "#     # print(f\"Index: {i}\")\n",
    "    \n",
    "#     y_negative = [abs(y_item) if y_item < threshold else 0 for y_item in y]\n",
    "#     # calculate area under the signal\n",
    "#     area = abs(simpson(y_negative,x))\n",
    "#     fractional_area = area * 0.5\n",
    "    \n",
    "#     if fractional_area != 0:\n",
    "#         # search for latency point (x) which split area according to fraction provided \n",
    "#         current_area = 0\n",
    "#         fractional_area_index = 0\n",
    "#         i = 2\n",
    "#         if area != 0.0:\n",
    "#             while abs(simpson(y_negative[:i], x[:i])) <= fractional_area:\n",
    "#                 current_area = abs(simpson(y_negative[:i], x[:i]))\n",
    "#                 fractional_area_index = i\n",
    "#                 i+=1\n",
    "\n",
    "#         plt.plot(x,y)\n",
    "#         plt.plot(x, y_negative)\n",
    "#         plt.axvline(x=x[fractional_area_index])\n",
    "#     else:\n",
    "#         fractional_area_index = 0\n",
    "#         plt.plot(x,y)\n",
    "#         plt.axvline(x=x[fractional_area_index], color='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac1625b-8bbe-4a9e-be95-d8779aa0c94c",
   "metadata": {},
   "source": [
    "**2. Peak Latency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2634956-bd4e-45bf-ab48-fa551a963bfb",
   "metadata": {},
   "source": [
    "Lowpass data at 25 Hz for peak finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "id": "cceb9142-b7e8-4aee-8b98-3930f734dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowpass = 25.0\n",
    "\n",
    "epochs_df_to_filter = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "epochs_filtered = Pipeline([\n",
    "    (\"lowpass\", BandpassFilter(h_freq=lowpass)),\n",
    "]).fit_transform(epochs_df_to_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0259e8-36a9-4c94-a17e-1ac98a80baba",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "id": "c9d45d98-b038-4422-a768-ecd636b042f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = -0.05 # window start time\n",
    "tmax = 0.10 # window stop time || peak search stop time\n",
    "ignore_peaks_before = -0.025 # peak serach start time\n",
    "roi = ['Fz']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8ad00-e7a8-4e12-8a38-13033a0d7da4",
   "metadata": {},
   "source": [
    "Estimate peak latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "id": "a7129150-bc64-4c59-8eb7-6144765d0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "id": "f13e4625-f2eb-495a-a9f8-d7d49ed6c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='correct_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "id": "1ca89d73-3540-49c8-82f5-877362e1729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_latencies = []\n",
    "for i in range(0, len(X)):        \n",
    "    subject = X[i][0]\n",
    "    evoked = subject\n",
    "    # print(f\"Index: {i}\")\n",
    "    this_latency = peak_latency(evoked, tmin=tmin, tmax=tmax, ignore_peaks_before=ignore_peaks_before, favour_peaks_after=-0.025)\n",
    "    peak_latencies.append(this_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "c87f11d8-bd0b-40b2-9b72-8398fdea8a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1)"
      ]
     },
     "execution_count": 1034,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_latencies_crn = np.array(peak_latencies).reshape(-1,1)\n",
    "peak_latencies_crn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc51c2-3985-4280-ad55-c84a7e7cde5b",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "id": "c93897a8-35ac-49b0-b265-6c9cad62fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmin = -0.05 # window start time\n",
    "# tmax = 0.10 # window stop time || peak search stop time\n",
    "# ignore_peaks_before = -0.025 # peak serach start time\n",
    "\n",
    "# roi = ['Fz']\n",
    "\n",
    "# epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))\n",
    "\n",
    "# X = Pipeline([\n",
    "#     (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "#     (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "#     (\"average\", Evoked(condition='correct_response')),\n",
    "# ]).fit_transform(epochs_df_copy)\n",
    "\n",
    "# X = X[['evoked']].to_numpy()\n",
    "\n",
    "# peaks = []\n",
    "# most_negative_peaks = []\n",
    "\n",
    "# for index in range(0, len(X)):\n",
    "#     plt.figure(index)\n",
    "    \n",
    "#     subject_data = X[index][0].get_data()\n",
    "    \n",
    "#     x = np.linspace(tmin, tmax, subject_data.shape[-1]) * 100\n",
    "#     y = subject_data.flatten()\n",
    "    \n",
    "#     y_spl = UnivariateSpline(x,y,s=0,k=4)\n",
    "#     y_spl_1d = y_spl.derivative(n=1) # funkcja 1 pochodnej\n",
    "\n",
    "#     x_range = np.linspace(x[0],x[-1],1000)\n",
    "    \n",
    "#     plt.plot(x_range,y_spl(x_range)) # funkcja\n",
    "#     plt.plot(x_range,y_spl_1d(x_range)) # 1 pochodna\n",
    "#     plt.axhline(y = 0.0, color='gray') # zero\n",
    "#     plt.axvline(x = 0.0, color='gray', ls='--') # zero\n",
    "#     plt.text(0,0,index)\n",
    "\n",
    "#     zeros = y_spl_1d.roots() # first derrivate zero -> peak\n",
    "\n",
    "#     plt.scatter(x=zeros, y=[0]*len(zeros))\n",
    "\n",
    "#     # define THIS peak\n",
    "    \n",
    "#     personal_peaks = []\n",
    "#     lower_peak_x = 0\n",
    "#     # max_lower_value = 2000\n",
    "#     step  = 0.6\n",
    "    \n",
    "#     if len(zeros) != 0:\n",
    "\n",
    "#         for zero in zeros:\n",
    "#             if (zero > ignore_peaks_before*100):\n",
    "#                 lower_peak_x = zero \n",
    "#                 personal_peaks.append((lower_peak_x, y_spl(lower_peak_x)))\n",
    "#             # max_lower_value = y_spl(zero) if y_spl(zero) < max_lower_value and (zero > ignore_peaks_before*100) else max_lower_value\n",
    "\n",
    "#             # if y_spl(zero) < max_lower_value and zero > -2.5:\n",
    "#         for index_2, erns in enumerate(personal_peaks):\n",
    "#             x_ = erns[0]\n",
    "#             plt.scatter(x=x_, y=[0]*len([x_]), color='red')\n",
    "\n",
    "#         peaks_ = personal_peaks.copy()\n",
    "\n",
    "#         if len(peaks_) > 0:\n",
    "#             min_index = np.argmin(peaks_, axis=0)[-1]\n",
    "#             latency_value = peaks_[min_index][0]\n",
    "\n",
    "#             while latency_value < ignore_peaks_before*100 and len(peaks_) > 1:\n",
    "#                 peaks_.pop(min_index)\n",
    "#                 min_index = np.argmin(peaks_, axis=0)[-1]\n",
    "#                 latency_value = peaks_[min_index][0]    \n",
    "            \n",
    "#             plt.scatter(x=latency_value, y=[0]*len([latency_value]), color='purple')\n",
    "\n",
    "#         else:\n",
    "#             for zero in zeros:\n",
    "#                 plt.scatter(x=zero, y=[0]*len([zero]), color='green')\n",
    "#     else:\n",
    "#         plt.scatter(x=0, y=[0]*len([0]), color='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed840b5-1039-4f23-bdc3-426ce0034bda",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e6233-81b8-4f1f-8763-896f5f8beace",
   "metadata": {},
   "source": [
    "#### Extract anxiety-related questionnaires scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7ff716-45b0-45f7-a06d-65e42168d78b",
   "metadata": {},
   "source": [
    "Questionnaires to include in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ef32f83c-fd82-4a88-abd3-5d43f14ce256",
   "metadata": {},
   "outputs": [],
   "source": [
    "rumination = \"RRQ\"\n",
    "dass_anxiety = \"DASS-21 Anx\"\n",
    "dass_stress = \"DASS-21 Stress\"\n",
    "dass_dep = \"DASS-21 Dep\"\n",
    "stai_t = \"STAI-T\" \n",
    "stai_s_diff = \"STAI-S Diff\" \n",
    "uninhibited_responses = \"uninhibited response\"\n",
    "inhibited_responses = \"inhibited response\"\n",
    "bis = \"BIS\"\n",
    "bas_dzialanie = \"BAS_D\"\n",
    "bas_przyjemnosc = \"BAS_PRZY\"\n",
    "bas_nagroda = \"BAS_NAG\"\n",
    "washing = \"WASH\"\n",
    "obsessing = \"OBSESS\"\n",
    "hoarding = \"HOARD\"\n",
    "ordering = \"ORD\"\n",
    "checking = \"CHECK\"\n",
    "neutralizing = \"NEU\"\n",
    "oci_r_full = \"OCI-R\"\n",
    "threat = \"OT\"\n",
    "thought_suppression = \"WBSI\"\n",
    "indecisivness = \"INDEC_F\"\n",
    "IU_prospecitve = \"IUS-P\"\n",
    "IU_inhibitory = \"IUS-I\"\n",
    "self_esteem = \"SES\"\n",
    "punishment_sensitivity = \"PUN\"\n",
    "reward_sensitivity = \"REW\"\n",
    "harm_responsibility = \"HARM\"\n",
    "thought_control = \"T-CTR\"\n",
    "perfectionism_IU = \"OB_PERF\"\n",
    "# perfectionism_cmda = \"17-Perfectionism CMDA\"\n",
    "perfectionism_ps = \"PS\"\n",
    "guilt_sensitivity = \"G_SE\"\n",
    "intolerance_ambiguity = \"AMB\"\n",
    "predictability = \"PRED\"\n",
    "high_standards = \"STAND\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "6fb80bb5-46bd-4aba-b5d9-8402f97ea6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [\n",
    "    rumination,\n",
    "    # dass_anxiety,\n",
    "    dass_stress,\n",
    "    dass_dep,\n",
    "    stai_t,\n",
    "    stai_s_diff,\n",
    "    uninhibited_responses,\n",
    "    inhibited_responses,\n",
    "    bis,\n",
    "    bas_dzialanie,\n",
    "    bas_przyjemnosc,\n",
    "    bas_nagroda,\n",
    "    washing,\n",
    "    obsessing,\n",
    "    hoarding,\n",
    "    ordering,\n",
    "    checking,\n",
    "    neutralizing,\n",
    "    # oci_r_full,\n",
    "    threat,\n",
    "    thought_suppression,\n",
    "    indecisivness,\n",
    "    punishment_sensitivity,\n",
    "    reward_sensitivity,\n",
    "    harm_responsibility,\n",
    "    guilt_sensitivity,\n",
    "    thought_control,\n",
    "    perfectionism_IU,\n",
    "    # perfectionism_cmda,\n",
    "    perfectionism_ps,\n",
    "    intolerance_ambiguity,\n",
    "    predictability,\n",
    "    high_standards,\n",
    "    IU_prospecitve,\n",
    "    IU_inhibitory,\n",
    "    self_esteem,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "05652d55-e054-4c74-a22a-5bba52a28948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>uninhibited response</th>\n",
       "      <th>inhibited response</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>...</th>\n",
       "      <th>G_SE</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.416667</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.25</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20</td>\n",
       "      <td>92</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>88</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.40</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>86</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.916667</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>4.580000</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.88</td>\n",
       "      <td>6.330000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>3.250000</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40</td>\n",
       "      <td>72</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>4.670000</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30</td>\n",
       "      <td>82</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.140000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.88</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>2.75</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31</td>\n",
       "      <td>81</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>3.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20</td>\n",
       "      <td>92</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.290000</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.670000</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RRQ  DASS-21 Stress  DASS-21 Dep  STAI-T  STAI-S Diff  \\\n",
       "0    3.416667        1.285714     2.142857    2.25          6.0   \n",
       "1    3.750000        1.142857     1.285714    2.00          0.0   \n",
       "2    3.833333        1.857143     1.571429    2.40         19.0   \n",
       "3    2.250000        3.000000     2.571429    2.80          0.0   \n",
       "4    3.916667        2.142857     1.571429    2.25          2.0   \n",
       "..        ...             ...          ...     ...          ...   \n",
       "255  4.580000        3.710000     3.140000    2.85          3.0   \n",
       "256  3.250000        2.290000     2.000000    2.15          4.0   \n",
       "257  4.670000        2.430000     2.570000    2.50          6.0   \n",
       "258  2.750000        2.290000     2.570000    2.75          5.0   \n",
       "259  3.250000        2.000000     1.570000    2.05          3.0   \n",
       "\n",
       "     uninhibited response  inhibited response   BIS  BAS_D  BAS_PRZY  ...  \\\n",
       "0                      20                  92  2.90   1.75      2.50  ...   \n",
       "1                      24                  88  2.70   2.00      3.50  ...   \n",
       "2                      52                  60  3.10   1.50      2.50  ...   \n",
       "3                      26                  86  3.00   2.50      2.50  ...   \n",
       "4                      66                  46  3.00   3.00      3.75  ...   \n",
       "..                    ...                 ...   ...    ...       ...  ...   \n",
       "255                     7                 105  4.00   2.25      3.25  ...   \n",
       "256                    40                  72  2.86   2.00      2.50  ...   \n",
       "257                    30                  82  3.00   2.75      1.75  ...   \n",
       "258                    31                  81  3.14   2.00      2.75  ...   \n",
       "259                    20                  92  2.43   2.75      2.75  ...   \n",
       "\n",
       "     G_SE  T-CTR  OB_PERF        PS   AMB  PRED     STAND     IUS-P  IUS-I  \\\n",
       "0     3.0    4.0      4.0  1.428571  4.83  4.25  4.666667  3.142857    2.8   \n",
       "1     3.0    1.6      2.6  2.714286  4.17  3.75  5.000000  2.714286    1.8   \n",
       "2     2.2    1.8      3.2  3.285714  4.00  4.25  4.333333  2.142857    3.0   \n",
       "3     2.8    1.2      2.0  3.428571  3.33  3.00  4.000000  3.428571    3.2   \n",
       "4     3.0    2.0      1.8  2.285714  3.67  3.25  4.000000  2.857143    1.8   \n",
       "..    ...    ...      ...       ...   ...   ...       ...       ...    ...   \n",
       "255   3.8    3.0      6.2  2.860000  4.83  4.88  6.330000  3.860000    4.8   \n",
       "256   2.7    2.0      3.0  2.000000  3.33  3.50  3.000000  3.000000    2.2   \n",
       "257   2.5    1.2      1.2  4.140000  5.00  3.88  5.000000  3.860000    3.0   \n",
       "258   2.5    1.0      1.8  1.710000  5.50  4.75  2.330000  3.430000    3.8   \n",
       "259   2.8    1.2      2.8  3.290000  3.67  3.25  5.670000  1.860000    1.0   \n",
       "\n",
       "     SES  \n",
       "0    2.4  \n",
       "1    3.1  \n",
       "2    2.4  \n",
       "3    2.7  \n",
       "4    3.0  \n",
       "..   ...  \n",
       "255  2.3  \n",
       "256  2.7  \n",
       "257  1.9  \n",
       "258  1.8  \n",
       "259  3.4  \n",
       "\n",
       "[260 rows x 33 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionnaires_scores_df = epochs_df[scales]\n",
    "questionnaires_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3ec4b-64b2-40c1-993b-7bef3cd303b6",
   "metadata": {},
   "source": [
    "Fill missing value from external file - TODO to automatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e3c7dfc9-86e7-4800-b84b-26714905a96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>uninhibited response</th>\n",
       "      <th>inhibited response</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>...</th>\n",
       "      <th>G_SE</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RRQ, DASS-21 Stress, DASS-21 Dep, STAI-T, STAI-S Diff, uninhibited response, inhibited response, BIS, BAS_D, BAS_PRZY, BAS_NAG, WASH, OBSESS, HOARD, ORD, CHECK, NEU, OT, WBSI, INDEC_F, PUN, REW, HARM, G_SE, T-CTR, OB_PERF, PS, AMB, PRED, STAND, IUS-P, IUS-I, SES]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionnaires_scores_df[questionnaires_scores_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "838e685f-3b39-497b-aec3-740c4a038091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None to fill\n"
     ]
    }
   ],
   "source": [
    "if test:\n",
    "    questionnaires_scores_df.at[102, 'uninhibited response'] = 14.0\n",
    "    questionnaires_scores_df.at[102, 'inhibited response'] = 98.0\n",
    "else:\n",
    "    print('None to fill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "e6cd794d-1bf0-4651-9b93-617cacb9ab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>uninhibited response</th>\n",
       "      <th>inhibited response</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>...</th>\n",
       "      <th>G_SE</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RRQ, DASS-21 Stress, DASS-21 Dep, STAI-T, STAI-S Diff, uninhibited response, inhibited response, BIS, BAS_D, BAS_PRZY, BAS_NAG, WASH, OBSESS, HOARD, ORD, CHECK, NEU, OT, WBSI, INDEC_F, PUN, REW, HARM, G_SE, T-CTR, OB_PERF, PS, AMB, PRED, STAND, IUS-P, IUS-I, SES]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionnaires_scores_df[questionnaires_scores_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623ec8b-725a-4067-898a-2017058e90aa",
   "metadata": {},
   "source": [
    "Create performance metric based on inhibited and uninhibited responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6ea34c0d-14ca-457e-9983-86e1e7542b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaires_scores_df['performance'] = questionnaires_scores_df['inhibited response'] / questionnaires_scores_df['uninhibited response']\n",
    "questionnaires_scores_df = questionnaires_scores_df.drop(columns=['inhibited response', 'uninhibited response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ba3c1-4846-4156-8b71-f92f0ae7815a",
   "metadata": {},
   "source": [
    "Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1ee36f5e-20eb-47ea-ac01-442a7405d459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>BAS_NAG</th>\n",
       "      <th>WASH</th>\n",
       "      <th>...</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RRQ, DASS-21 Stress, DASS-21 Dep, STAI-T, STAI-S Diff, BIS, BAS_D, BAS_PRZY, BAS_NAG, WASH, OBSESS, HOARD, ORD, CHECK, NEU, OT, WBSI, INDEC_F, PUN, REW, HARM, G_SE, T-CTR, OB_PERF, PS, AMB, PRED, STAND, IUS-P, IUS-I, SES, performance]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionnaires_scores_df[questionnaires_scores_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0da1a613-7dc1-4247-85ff-92df4e0d082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>BAS_NAG</th>\n",
       "      <th>WASH</th>\n",
       "      <th>OBSESS</th>\n",
       "      <th>HOARD</th>\n",
       "      <th>ORD</th>\n",
       "      <th>CHECK</th>\n",
       "      <th>NEU</th>\n",
       "      <th>OT</th>\n",
       "      <th>WBSI</th>\n",
       "      <th>INDEC_F</th>\n",
       "      <th>PUN</th>\n",
       "      <th>REW</th>\n",
       "      <th>HARM</th>\n",
       "      <th>G_SE</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.585500</td>\n",
       "      <td>2.272088</td>\n",
       "      <td>1.943247</td>\n",
       "      <td>2.277692</td>\n",
       "      <td>3.407099</td>\n",
       "      <td>3.018346</td>\n",
       "      <td>2.392308</td>\n",
       "      <td>2.760577</td>\n",
       "      <td>3.191538</td>\n",
       "      <td>1.662603</td>\n",
       "      <td>2.543526</td>\n",
       "      <td>2.233487</td>\n",
       "      <td>2.482077</td>\n",
       "      <td>2.548654</td>\n",
       "      <td>1.496090</td>\n",
       "      <td>2.966154</td>\n",
       "      <td>3.556218</td>\n",
       "      <td>3.100051</td>\n",
       "      <td>6.165385</td>\n",
       "      <td>4.030769</td>\n",
       "      <td>3.953077</td>\n",
       "      <td>2.981154</td>\n",
       "      <td>2.498462</td>\n",
       "      <td>3.407692</td>\n",
       "      <td>3.059401</td>\n",
       "      <td>4.134000</td>\n",
       "      <td>3.693500</td>\n",
       "      <td>4.584577</td>\n",
       "      <td>3.124775</td>\n",
       "      <td>2.475385</td>\n",
       "      <td>2.802308</td>\n",
       "      <td>4.088899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.850932</td>\n",
       "      <td>0.653790</td>\n",
       "      <td>0.698709</td>\n",
       "      <td>0.469846</td>\n",
       "      <td>7.392636</td>\n",
       "      <td>0.523086</td>\n",
       "      <td>0.627121</td>\n",
       "      <td>0.593671</td>\n",
       "      <td>0.425543</td>\n",
       "      <td>0.823587</td>\n",
       "      <td>1.091452</td>\n",
       "      <td>0.963780</td>\n",
       "      <td>1.077597</td>\n",
       "      <td>1.049201</td>\n",
       "      <td>0.644882</td>\n",
       "      <td>1.218427</td>\n",
       "      <td>0.806418</td>\n",
       "      <td>0.713536</td>\n",
       "      <td>3.570519</td>\n",
       "      <td>2.056869</td>\n",
       "      <td>1.005213</td>\n",
       "      <td>0.773743</td>\n",
       "      <td>0.985218</td>\n",
       "      <td>1.257172</td>\n",
       "      <td>0.938879</td>\n",
       "      <td>0.786534</td>\n",
       "      <td>0.893359</td>\n",
       "      <td>1.239791</td>\n",
       "      <td>0.780033</td>\n",
       "      <td>0.935533</td>\n",
       "      <td>0.630005</td>\n",
       "      <td>4.589143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.330000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.669167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2.475000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>3.627500</td>\n",
       "      <td>3.097500</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.007112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.670000</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4.668333</td>\n",
       "      <td>3.141429</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.148148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.330000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>4.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              RRQ  DASS-21 Stress  DASS-21 Dep      STAI-T  STAI-S Diff  \\\n",
       "count  260.000000      260.000000   260.000000  260.000000   260.000000   \n",
       "mean     3.585500        2.272088     1.943247    2.277692     3.407099   \n",
       "std      0.850932        0.653790     0.698709    0.469846     7.392636   \n",
       "min      1.330000        1.000000     1.000000    1.250000   -17.000000   \n",
       "25%      3.000000        1.857143     1.428571    1.900000    -0.250000   \n",
       "50%      3.670000        2.285714     1.714286    2.250000     2.000000   \n",
       "75%      4.330000        2.714286     2.428571    2.650000     6.000000   \n",
       "max      5.000000        3.860000     4.000000    3.500000    34.000000   \n",
       "\n",
       "              BIS       BAS_D    BAS_PRZY     BAS_NAG        WASH      OBSESS  \\\n",
       "count  260.000000  260.000000  260.000000  260.000000  260.000000  260.000000   \n",
       "mean     3.018346    2.392308    2.760577    3.191538    1.662603    2.543526   \n",
       "std      0.523086    0.627121    0.593671    0.425543    0.823587    1.091452   \n",
       "min      1.700000    1.000000    1.000000    2.200000    1.000000    1.000000   \n",
       "25%      2.700000    2.000000    2.500000    2.800000    1.000000    1.666667   \n",
       "50%      3.000000    2.250000    2.750000    3.200000    1.333333    2.333333   \n",
       "75%      3.400000    2.750000    3.250000    3.400000    2.000000    3.333333   \n",
       "max      4.000000    4.000000    4.000000    4.000000    4.670000    5.000000   \n",
       "\n",
       "            HOARD         ORD       CHECK         NEU          OT        WBSI  \\\n",
       "count  260.000000  260.000000  260.000000  260.000000  260.000000  260.000000   \n",
       "mean     2.233487    2.482077    2.548654    1.496090    2.966154    3.556218   \n",
       "std      0.963780    1.077597    1.049201    0.644882    1.218427    0.806418   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.266667   \n",
       "25%      1.333333    1.666667    1.669167    1.000000    2.000000    3.000000   \n",
       "50%      2.000000    2.333333    2.333333    1.330000    2.800000    3.600000   \n",
       "75%      3.000000    3.330000    3.333333    1.670000    3.800000    4.133333   \n",
       "max      5.000000    5.000000    5.000000    4.000000    6.200000    5.000000   \n",
       "\n",
       "          INDEC_F         PUN         REW        HARM        G_SE       T-CTR  \\\n",
       "count  260.000000  260.000000  260.000000  260.000000  260.000000  260.000000   \n",
       "mean     3.100051    6.165385    4.030769    3.953077    2.981154    2.498462   \n",
       "std      0.713536    3.570519    2.056869    1.005213    0.773743    0.985218   \n",
       "min      1.066667    0.000000    0.000000    1.000000    1.200000    1.000000   \n",
       "25%      2.600000    3.000000    2.000000    3.200000    2.475000    1.800000   \n",
       "50%      3.070000    6.000000    4.000000    4.000000    3.000000    2.300000   \n",
       "75%      3.666667    9.000000    6.000000    4.600000    3.500000    3.200000   \n",
       "max      4.600000   13.000000    8.000000    6.800000    4.900000    6.200000   \n",
       "\n",
       "          OB_PERF          PS         AMB        PRED       STAND       IUS-P  \\\n",
       "count  260.000000  260.000000  260.000000  260.000000  260.000000  260.000000   \n",
       "mean     3.407692    3.059401    4.134000    3.693500    4.584577    3.124775   \n",
       "std      1.257172    0.938879    0.786534    0.893359    1.239791    0.780033   \n",
       "min      1.000000    1.000000    1.670000    1.000000    1.000000    1.000000   \n",
       "25%      2.400000    2.428571    3.627500    3.097500    3.670000    2.571429   \n",
       "50%      3.300000    3.000000    4.170000    3.750000    4.668333    3.141429   \n",
       "75%      4.400000    3.714286    4.670000    4.380000    5.333333    3.714286   \n",
       "max      6.800000    5.000000    6.000000    6.000000    7.000000    5.000000   \n",
       "\n",
       "            IUS-I         SES  performance  \n",
       "count  260.000000  260.000000   260.000000  \n",
       "mean     2.475385    2.802308     4.088899  \n",
       "std      0.935533    0.630005     4.589143  \n",
       "min      1.000000    1.000000     0.258427  \n",
       "25%      1.800000    2.400000     2.007112  \n",
       "50%      2.400000    2.800000     3.148148  \n",
       "75%      3.200000    3.300000     4.894737  \n",
       "max      4.800000    4.000000    55.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None, 'display.max_columns', None):\n",
    "    display(questionnaires_scores_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c58ee5f-ad0f-4149-bb3d-888cc2f2d357",
   "metadata": {},
   "source": [
    "Check skewness and kurtiosis\n",
    "\n",
    "As a general rule of thumb: If skewness is less than -1 or greater than 1, the distribution is highly skewed. If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed. If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n",
    "\n",
    "Analogous to the skewness, the general guideline is that if the kurtosis is greater than +2, the distribution is too peaked. Likewise, a kurtosis of less than −2 indicates a distribution that is too flat. When both skewness and kurtosis are close to zero, the pattern of responses is considered a normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "b053c7b3-cdde-4bd2-bd4a-832aba90247c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RRQ</th>\n",
       "      <td>-0.422316</td>\n",
       "      <td>-0.623886</td>\n",
       "      <td>3.585500</td>\n",
       "      <td>0.850932</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <td>0.248132</td>\n",
       "      <td>-0.492854</td>\n",
       "      <td>2.272088</td>\n",
       "      <td>0.653790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <td>0.802576</td>\n",
       "      <td>0.015942</td>\n",
       "      <td>1.943247</td>\n",
       "      <td>0.698709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAI-T</th>\n",
       "      <td>0.142289</td>\n",
       "      <td>-0.534881</td>\n",
       "      <td>2.277692</td>\n",
       "      <td>0.469846</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <td>1.038349</td>\n",
       "      <td>2.545481</td>\n",
       "      <td>3.407099</td>\n",
       "      <td>7.392636</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS</th>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.619946</td>\n",
       "      <td>3.018346</td>\n",
       "      <td>0.523086</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_D</th>\n",
       "      <td>0.359135</td>\n",
       "      <td>-0.136873</td>\n",
       "      <td>2.392308</td>\n",
       "      <td>0.627121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <td>-0.327866</td>\n",
       "      <td>0.193784</td>\n",
       "      <td>2.760577</td>\n",
       "      <td>0.593671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_NAG</th>\n",
       "      <td>-0.063078</td>\n",
       "      <td>-0.528269</td>\n",
       "      <td>3.191538</td>\n",
       "      <td>0.425543</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WASH</th>\n",
       "      <td>1.485257</td>\n",
       "      <td>1.818988</td>\n",
       "      <td>1.662603</td>\n",
       "      <td>0.823587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBSESS</th>\n",
       "      <td>0.428625</td>\n",
       "      <td>-0.751382</td>\n",
       "      <td>2.543526</td>\n",
       "      <td>1.091452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOARD</th>\n",
       "      <td>0.665551</td>\n",
       "      <td>-0.210918</td>\n",
       "      <td>2.233487</td>\n",
       "      <td>0.963780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORD</th>\n",
       "      <td>0.411956</td>\n",
       "      <td>-0.734084</td>\n",
       "      <td>2.482077</td>\n",
       "      <td>1.077597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHECK</th>\n",
       "      <td>0.378201</td>\n",
       "      <td>-0.766499</td>\n",
       "      <td>2.548654</td>\n",
       "      <td>1.049201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU</th>\n",
       "      <td>1.430917</td>\n",
       "      <td>1.565697</td>\n",
       "      <td>1.496090</td>\n",
       "      <td>0.644882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OT</th>\n",
       "      <td>0.437193</td>\n",
       "      <td>-0.706088</td>\n",
       "      <td>2.966154</td>\n",
       "      <td>1.218427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBSI</th>\n",
       "      <td>-0.373493</td>\n",
       "      <td>-0.357722</td>\n",
       "      <td>3.556218</td>\n",
       "      <td>0.806418</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEC_F</th>\n",
       "      <td>-0.034697</td>\n",
       "      <td>-0.494788</td>\n",
       "      <td>3.100051</td>\n",
       "      <td>0.713536</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUN</th>\n",
       "      <td>0.039968</td>\n",
       "      <td>-1.052653</td>\n",
       "      <td>6.165385</td>\n",
       "      <td>3.570519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REW</th>\n",
       "      <td>0.017369</td>\n",
       "      <td>-0.893402</td>\n",
       "      <td>4.030769</td>\n",
       "      <td>2.056869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HARM</th>\n",
       "      <td>0.097803</td>\n",
       "      <td>-0.006471</td>\n",
       "      <td>3.953077</td>\n",
       "      <td>1.005213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_SE</th>\n",
       "      <td>-0.088084</td>\n",
       "      <td>-0.468526</td>\n",
       "      <td>2.981154</td>\n",
       "      <td>0.773743</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>4.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-CTR</th>\n",
       "      <td>0.676140</td>\n",
       "      <td>0.185978</td>\n",
       "      <td>2.498462</td>\n",
       "      <td>0.985218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OB_PERF</th>\n",
       "      <td>0.273987</td>\n",
       "      <td>-0.560870</td>\n",
       "      <td>3.407692</td>\n",
       "      <td>1.257172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PS</th>\n",
       "      <td>-0.001470</td>\n",
       "      <td>-0.617487</td>\n",
       "      <td>3.059401</td>\n",
       "      <td>0.938879</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMB</th>\n",
       "      <td>-0.141368</td>\n",
       "      <td>-0.079585</td>\n",
       "      <td>4.134000</td>\n",
       "      <td>0.786534</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRED</th>\n",
       "      <td>-0.025952</td>\n",
       "      <td>-0.193336</td>\n",
       "      <td>3.693500</td>\n",
       "      <td>0.893359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAND</th>\n",
       "      <td>-0.470598</td>\n",
       "      <td>0.026507</td>\n",
       "      <td>4.584577</td>\n",
       "      <td>1.239791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IUS-P</th>\n",
       "      <td>-0.223256</td>\n",
       "      <td>-0.476608</td>\n",
       "      <td>3.124775</td>\n",
       "      <td>0.780033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IUS-I</th>\n",
       "      <td>0.367232</td>\n",
       "      <td>-0.755810</td>\n",
       "      <td>2.475385</td>\n",
       "      <td>0.935533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SES</th>\n",
       "      <td>-0.213952</td>\n",
       "      <td>-0.498902</td>\n",
       "      <td>2.802308</td>\n",
       "      <td>0.630005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance</th>\n",
       "      <td>6.944878</td>\n",
       "      <td>67.213253</td>\n",
       "      <td>4.088899</td>\n",
       "      <td>4.589143</td>\n",
       "      <td>0.258427</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    skew   kurtosis      mean       std        min    max\n",
       "RRQ            -0.422316  -0.623886  3.585500  0.850932   1.330000   5.00\n",
       "DASS-21 Stress  0.248132  -0.492854  2.272088  0.653790   1.000000   3.86\n",
       "DASS-21 Dep     0.802576   0.015942  1.943247  0.698709   1.000000   4.00\n",
       "STAI-T          0.142289  -0.534881  2.277692  0.469846   1.250000   3.50\n",
       "STAI-S Diff     1.038349   2.545481  3.407099  7.392636 -17.000000  34.00\n",
       "BIS            -0.003226  -0.619946  3.018346  0.523086   1.700000   4.00\n",
       "BAS_D           0.359135  -0.136873  2.392308  0.627121   1.000000   4.00\n",
       "BAS_PRZY       -0.327866   0.193784  2.760577  0.593671   1.000000   4.00\n",
       "BAS_NAG        -0.063078  -0.528269  3.191538  0.425543   2.200000   4.00\n",
       "WASH            1.485257   1.818988  1.662603  0.823587   1.000000   4.67\n",
       "OBSESS          0.428625  -0.751382  2.543526  1.091452   1.000000   5.00\n",
       "HOARD           0.665551  -0.210918  2.233487  0.963780   1.000000   5.00\n",
       "ORD             0.411956  -0.734084  2.482077  1.077597   1.000000   5.00\n",
       "CHECK           0.378201  -0.766499  2.548654  1.049201   1.000000   5.00\n",
       "NEU             1.430917   1.565697  1.496090  0.644882   1.000000   4.00\n",
       "OT              0.437193  -0.706088  2.966154  1.218427   1.000000   6.20\n",
       "WBSI           -0.373493  -0.357722  3.556218  0.806418   1.266667   5.00\n",
       "INDEC_F        -0.034697  -0.494788  3.100051  0.713536   1.066667   4.60\n",
       "PUN             0.039968  -1.052653  6.165385  3.570519   0.000000  13.00\n",
       "REW             0.017369  -0.893402  4.030769  2.056869   0.000000   8.00\n",
       "HARM            0.097803  -0.006471  3.953077  1.005213   1.000000   6.80\n",
       "G_SE           -0.088084  -0.468526  2.981154  0.773743   1.200000   4.90\n",
       "T-CTR           0.676140   0.185978  2.498462  0.985218   1.000000   6.20\n",
       "OB_PERF         0.273987  -0.560870  3.407692  1.257172   1.000000   6.80\n",
       "PS             -0.001470  -0.617487  3.059401  0.938879   1.000000   5.00\n",
       "AMB            -0.141368  -0.079585  4.134000  0.786534   1.670000   6.00\n",
       "PRED           -0.025952  -0.193336  3.693500  0.893359   1.000000   6.00\n",
       "STAND          -0.470598   0.026507  4.584577  1.239791   1.000000   7.00\n",
       "IUS-P          -0.223256  -0.476608  3.124775  0.780033   1.000000   5.00\n",
       "IUS-I           0.367232  -0.755810  2.475385  0.935533   1.000000   4.80\n",
       "SES            -0.213952  -0.498902  2.802308  0.630005   1.000000   4.00\n",
       "performance     6.944878  67.213253  4.088899  4.589143   0.258427  55.00"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = questionnaires_scores_df.agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec5df3-a3d5-4428-861c-d9b29c70729b",
   "metadata": {},
   "source": [
    "Transform entries with high skewness and kurtosis with BoxCox method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "85a07bab-4d38-45ec-875f-0238d5c7b825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming: STAI-S Diff scale\n",
      "   Stats before transformation:\n",
      "    Skewness: 1.0323492753031647 \n",
      "    Kurtosis: 2.4738033797389267\n",
      "   Stats after transformation:\n",
      "    Skewness: 0.23405124859687698 \n",
      "    Kurtosis: 2.36986672153402\n",
      "Transforming: WASH scale\n",
      "   Stats before transformation:\n",
      "    Skewness: 1.4766744348474652 \n",
      "    Kurtosis: 1.7612065145335878\n",
      "   Stats after transformation:\n",
      "    Skewness: -0.14880224093127736 \n",
      "    Kurtosis: -1.5962530551422216\n",
      "Transforming: NEU scale\n",
      "   Stats before transformation:\n",
      "    Skewness: 1.4226481920861 \n",
      "    Kurtosis: 1.5127609844778958\n",
      "   Stats after transformation:\n",
      "    Skewness: -0.009417647386234898 \n",
      "    Kurtosis: -1.8202331471124864\n",
      "Transforming: performance scale\n",
      "   Stats before transformation:\n",
      "    Skewness: 6.904747031635196 \n",
      "    Kurtosis: 65.90464323885628\n",
      "   Stats after transformation:\n",
      "    Skewness: 0.15928504269028654 \n",
      "    Kurtosis: 3.0399578831611356\n"
     ]
    }
   ],
   "source": [
    "questionnaires_scores_df_transformed = questionnaires_scores_df.copy()\n",
    "\n",
    "for row in summary.iterrows():\n",
    "    item_name = row[0]\n",
    "    skewness_ = row[1]['skew']\n",
    "    kurtosis_ = row[1]['kurtosis']\n",
    "    \n",
    "    if abs(skewness_) > 1 or abs(kurtosis_) > 2:\n",
    "        print(f'Transforming: {item_name} scale')\n",
    "        this_scores = questionnaires_scores_df_transformed[[item_name]].to_numpy().flatten()\n",
    "        this_scores = this_scores - np.min(this_scores) + 0.01\n",
    "        this_scores_transformed, lambda_ = boxcox(this_scores)\n",
    "        print(f'   Stats before transformation:\\n    Skewness: {scipy.stats.skew(this_scores)} \\n    Kurtosis: {scipy.stats.kurtosis(this_scores)}')\n",
    "        print(f'   Stats after transformation:\\n    Skewness: {scipy.stats.skew(this_scores_transformed)} \\n    Kurtosis: {scipy.stats.kurtosis(this_scores_transformed)}')\n",
    "        \n",
    "        questionnaires_scores_df_transformed[[item_name]] = this_scores_transformed.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c9ca294a-0514-4a54-a57a-76aa6859a8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RRQ</th>\n",
       "      <td>-0.422316</td>\n",
       "      <td>-0.623886</td>\n",
       "      <td>3.585500</td>\n",
       "      <td>0.850932</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <td>0.248132</td>\n",
       "      <td>-0.492854</td>\n",
       "      <td>2.272088</td>\n",
       "      <td>0.653790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <td>0.802576</td>\n",
       "      <td>0.015942</td>\n",
       "      <td>1.943247</td>\n",
       "      <td>0.698709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAI-T</th>\n",
       "      <td>0.142289</td>\n",
       "      <td>-0.534881</td>\n",
       "      <td>2.277692</td>\n",
       "      <td>0.469846</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <td>0.235412</td>\n",
       "      <td>2.439517</td>\n",
       "      <td>9.246517</td>\n",
       "      <td>2.576317</td>\n",
       "      <td>-1.459130</td>\n",
       "      <td>18.338396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS</th>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.619946</td>\n",
       "      <td>3.018346</td>\n",
       "      <td>0.523086</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_D</th>\n",
       "      <td>0.359135</td>\n",
       "      <td>-0.136873</td>\n",
       "      <td>2.392308</td>\n",
       "      <td>0.627121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <td>-0.327866</td>\n",
       "      <td>0.193784</td>\n",
       "      <td>2.760577</td>\n",
       "      <td>0.593671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_NAG</th>\n",
       "      <td>-0.063078</td>\n",
       "      <td>-0.528269</td>\n",
       "      <td>3.191538</td>\n",
       "      <td>0.425543</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WASH</th>\n",
       "      <td>-0.149667</td>\n",
       "      <td>-1.603944</td>\n",
       "      <td>-1.452291</td>\n",
       "      <td>1.747292</td>\n",
       "      <td>-3.536578</td>\n",
       "      <td>1.410471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBSESS</th>\n",
       "      <td>0.428625</td>\n",
       "      <td>-0.751382</td>\n",
       "      <td>2.543526</td>\n",
       "      <td>1.091452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOARD</th>\n",
       "      <td>0.665551</td>\n",
       "      <td>-0.210918</td>\n",
       "      <td>2.233487</td>\n",
       "      <td>0.963780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORD</th>\n",
       "      <td>0.411956</td>\n",
       "      <td>-0.734084</td>\n",
       "      <td>2.482077</td>\n",
       "      <td>1.077597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHECK</th>\n",
       "      <td>0.378201</td>\n",
       "      <td>-0.766499</td>\n",
       "      <td>2.548654</td>\n",
       "      <td>1.049201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU</th>\n",
       "      <td>-0.009472</td>\n",
       "      <td>-1.832292</td>\n",
       "      <td>-2.242523</td>\n",
       "      <td>2.176837</td>\n",
       "      <td>-4.531474</td>\n",
       "      <td>1.106216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OT</th>\n",
       "      <td>0.437193</td>\n",
       "      <td>-0.706088</td>\n",
       "      <td>2.966154</td>\n",
       "      <td>1.218427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBSI</th>\n",
       "      <td>-0.373493</td>\n",
       "      <td>-0.357722</td>\n",
       "      <td>3.556218</td>\n",
       "      <td>0.806418</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEC_F</th>\n",
       "      <td>-0.034697</td>\n",
       "      <td>-0.494788</td>\n",
       "      <td>3.100051</td>\n",
       "      <td>0.713536</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUN</th>\n",
       "      <td>0.039968</td>\n",
       "      <td>-1.052653</td>\n",
       "      <td>6.165385</td>\n",
       "      <td>3.570519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REW</th>\n",
       "      <td>0.017369</td>\n",
       "      <td>-0.893402</td>\n",
       "      <td>4.030769</td>\n",
       "      <td>2.056869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HARM</th>\n",
       "      <td>0.097803</td>\n",
       "      <td>-0.006471</td>\n",
       "      <td>3.953077</td>\n",
       "      <td>1.005213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_SE</th>\n",
       "      <td>-0.088084</td>\n",
       "      <td>-0.468526</td>\n",
       "      <td>2.981154</td>\n",
       "      <td>0.773743</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-CTR</th>\n",
       "      <td>0.676140</td>\n",
       "      <td>0.185978</td>\n",
       "      <td>2.498462</td>\n",
       "      <td>0.985218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OB_PERF</th>\n",
       "      <td>0.273987</td>\n",
       "      <td>-0.560870</td>\n",
       "      <td>3.407692</td>\n",
       "      <td>1.257172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PS</th>\n",
       "      <td>-0.001470</td>\n",
       "      <td>-0.617487</td>\n",
       "      <td>3.059401</td>\n",
       "      <td>0.938879</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMB</th>\n",
       "      <td>-0.141368</td>\n",
       "      <td>-0.079585</td>\n",
       "      <td>4.134000</td>\n",
       "      <td>0.786534</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRED</th>\n",
       "      <td>-0.025952</td>\n",
       "      <td>-0.193336</td>\n",
       "      <td>3.693500</td>\n",
       "      <td>0.893359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAND</th>\n",
       "      <td>-0.470598</td>\n",
       "      <td>0.026507</td>\n",
       "      <td>4.584577</td>\n",
       "      <td>1.239791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IUS-P</th>\n",
       "      <td>-0.223256</td>\n",
       "      <td>-0.476608</td>\n",
       "      <td>3.124775</td>\n",
       "      <td>0.780033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IUS-I</th>\n",
       "      <td>0.367232</td>\n",
       "      <td>-0.755810</td>\n",
       "      <td>2.475385</td>\n",
       "      <td>0.935533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SES</th>\n",
       "      <td>-0.213952</td>\n",
       "      <td>-0.498902</td>\n",
       "      <td>2.802308</td>\n",
       "      <td>0.630005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance</th>\n",
       "      <td>0.160211</td>\n",
       "      <td>3.122675</td>\n",
       "      <td>1.171228</td>\n",
       "      <td>1.018372</td>\n",
       "      <td>-3.125479</td>\n",
       "      <td>5.874279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    skew  kurtosis      mean       std       min        max\n",
       "RRQ            -0.422316 -0.623886  3.585500  0.850932  1.330000   5.000000\n",
       "DASS-21 Stress  0.248132 -0.492854  2.272088  0.653790  1.000000   3.860000\n",
       "DASS-21 Dep     0.802576  0.015942  1.943247  0.698709  1.000000   4.000000\n",
       "STAI-T          0.142289 -0.534881  2.277692  0.469846  1.250000   3.500000\n",
       "STAI-S Diff     0.235412  2.439517  9.246517  2.576317 -1.459130  18.338396\n",
       "BIS            -0.003226 -0.619946  3.018346  0.523086  1.700000   4.000000\n",
       "BAS_D           0.359135 -0.136873  2.392308  0.627121  1.000000   4.000000\n",
       "BAS_PRZY       -0.327866  0.193784  2.760577  0.593671  1.000000   4.000000\n",
       "BAS_NAG        -0.063078 -0.528269  3.191538  0.425543  2.200000   4.000000\n",
       "WASH           -0.149667 -1.603944 -1.452291  1.747292 -3.536578   1.410471\n",
       "OBSESS          0.428625 -0.751382  2.543526  1.091452  1.000000   5.000000\n",
       "HOARD           0.665551 -0.210918  2.233487  0.963780  1.000000   5.000000\n",
       "ORD             0.411956 -0.734084  2.482077  1.077597  1.000000   5.000000\n",
       "CHECK           0.378201 -0.766499  2.548654  1.049201  1.000000   5.000000\n",
       "NEU            -0.009472 -1.832292 -2.242523  2.176837 -4.531474   1.106216\n",
       "OT              0.437193 -0.706088  2.966154  1.218427  1.000000   6.200000\n",
       "WBSI           -0.373493 -0.357722  3.556218  0.806418  1.266667   5.000000\n",
       "INDEC_F        -0.034697 -0.494788  3.100051  0.713536  1.066667   4.600000\n",
       "PUN             0.039968 -1.052653  6.165385  3.570519  0.000000  13.000000\n",
       "REW             0.017369 -0.893402  4.030769  2.056869  0.000000   8.000000\n",
       "HARM            0.097803 -0.006471  3.953077  1.005213  1.000000   6.800000\n",
       "G_SE           -0.088084 -0.468526  2.981154  0.773743  1.200000   4.900000\n",
       "T-CTR           0.676140  0.185978  2.498462  0.985218  1.000000   6.200000\n",
       "OB_PERF         0.273987 -0.560870  3.407692  1.257172  1.000000   6.800000\n",
       "PS             -0.001470 -0.617487  3.059401  0.938879  1.000000   5.000000\n",
       "AMB            -0.141368 -0.079585  4.134000  0.786534  1.670000   6.000000\n",
       "PRED           -0.025952 -0.193336  3.693500  0.893359  1.000000   6.000000\n",
       "STAND          -0.470598  0.026507  4.584577  1.239791  1.000000   7.000000\n",
       "IUS-P          -0.223256 -0.476608  3.124775  0.780033  1.000000   5.000000\n",
       "IUS-I           0.367232 -0.755810  2.475385  0.935533  1.000000   4.800000\n",
       "SES            -0.213952 -0.498902  2.802308  0.630005  1.000000   4.000000\n",
       "performance     0.160211  3.122675  1.171228  1.018372 -3.125479   5.874279"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = questionnaires_scores_df_transformed.agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72802dd9-ef2b-46cd-8a9d-08ce93c72229",
   "metadata": {},
   "source": [
    "#### Demographical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d953a83d-5539-4f9d-a130-72c1b5d2456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = \"Age\"\n",
    "sex = \"Sex\"\n",
    "handness = \"Handness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "f2abf7e5-a77b-443d-a8a2-667a83b5d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [\n",
    "    age,\n",
    "    sex,\n",
    "    handness\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "418ef9d2-28d1-4e2b-8ce9-18ef3adea3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographical_scores_df =  epochs_df[scales].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ba5708a5-ce72-43c3-a0cc-16f29d2638a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.598050</td>\n",
       "      <td>3.273384</td>\n",
       "      <td>23.211538</td>\n",
       "      <td>3.983249</td>\n",
       "      <td>18.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.281242</td>\n",
       "      <td>-1.935854</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.496139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Handness</th>\n",
       "      <td>-2.755702</td>\n",
       "      <td>5.637197</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.295371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              skew  kurtosis       mean       std   min   max\n",
       "Age       1.598050  3.273384  23.211538  3.983249  18.0  40.0\n",
       "Sex       0.281242 -1.935854   0.430769  0.496139   0.0   1.0\n",
       "Handness -2.755702  5.637197   0.903846  0.295371   0.0   1.0"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = demographical_scores_df.agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccab4540-8d71-4736-ac33-c50a0428c0cc",
   "metadata": {},
   "source": [
    "Transform skewed age entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "315ad0b9-bc15-47b9-817e-fc466c906f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = demographical_scores_df[['Age']].to_numpy().flatten()\n",
    "age_transformed, lambda_ = boxcox(age)\n",
    "demographical_scores_df[['Age']] = age_transformed.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3626ce17-e5c7-49d6-a790-82c1cd6b271b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.060186</td>\n",
       "      <td>-0.382029</td>\n",
       "      <td>0.424995</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.424806</td>\n",
       "      <td>0.425209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.281242</td>\n",
       "      <td>-1.935854</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.496139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Handness</th>\n",
       "      <td>-2.755702</td>\n",
       "      <td>5.637197</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.295371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              skew  kurtosis      mean       std       min       max\n",
       "Age       0.060186 -0.382029  0.424995  0.000091  0.424806  0.425209\n",
       "Sex       0.281242 -1.935854  0.430769  0.496139  0.000000  1.000000\n",
       "Handness -2.755702  5.637197  0.903846  0.295371  0.000000  1.000000"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = demographical_scores_df.agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf8cbe-77f8-4ff1-94e2-85108eae85cc",
   "metadata": {},
   "source": [
    "#### Concatenate questionnaire and EEG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "0417570f-a028-4df8-afe5-f1b27eeee5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_columns_ica = ['e_PCA_1_6', 'e_PCA_2_6']\n",
    "\n",
    "eeg_columns_ern = ['e_ERN']\n",
    "eeg_columns_crn = ['e_CRN']\n",
    "\n",
    "eeg_column_latencies_fal = ['e_LT_F']\n",
    "eeg_column_latencies_peak = ['e_LT_P']\n",
    "\n",
    "eeg_column_ch_type = ['e_LTR']\n",
    "\n",
    "\n",
    "eeg_column_latencies_fal_2_crn = ['e_LT_F2_C']\n",
    "eeg_column_latencies_fal_6_crn = ['e_LT_F6_C']\n",
    "eeg_column_latencies_peak_crn = ['e_LT_P_C']\n",
    "\n",
    "eeg_column_ch_type_crn = ['e_LTR_C']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7bb57d-3781-4238-a702-ae5ce9ea2a88",
   "metadata": {},
   "source": [
    "1. ERN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "dd693ecc-18af-47d4-86c8-f743fadc35f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "38a5a406-dad4-4e48-ad07-dafca5789770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_ERN</th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>BAS_NAG</th>\n",
       "      <th>...</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.622882e-07</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.25</td>\n",
       "      <td>10.298817</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.684569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.121127e-05</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.376404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.579851e-05</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.40</td>\n",
       "      <td>14.306246</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.098470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.217479e-07</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.239223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.456946e-06</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.25</td>\n",
       "      <td>8.915005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.746350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          e_ERN       RRQ  DASS-21 Stress  DASS-21 Dep  STAI-T  STAI-S Diff  \\\n",
       "0 -6.622882e-07  3.416667        1.285714     2.142857    2.25    10.298817   \n",
       "1 -1.121127e-05  3.750000        1.142857     1.285714    2.00     8.185239   \n",
       "2 -1.579851e-05  3.833333        1.857143     1.571429    2.40    14.306246   \n",
       "3 -5.217479e-07  2.250000        3.000000     2.571429    2.80     8.185239   \n",
       "4 -6.456946e-06  3.916667        2.142857     1.571429    2.25     8.915005   \n",
       "\n",
       "   BIS  BAS_D  BAS_PRZY  BAS_NAG  ...  T-CTR  OB_PERF        PS   AMB  PRED  \\\n",
       "0  2.9   1.75      2.50      3.0  ...    4.0      4.0  1.428571  4.83  4.25   \n",
       "1  2.7   2.00      3.50      2.6  ...    1.6      2.6  2.714286  4.17  3.75   \n",
       "2  3.1   1.50      2.50      2.6  ...    1.8      3.2  3.285714  4.00  4.25   \n",
       "3  3.0   2.50      2.50      2.8  ...    1.2      2.0  3.428571  3.33  3.00   \n",
       "4  3.0   3.00      3.75      3.0  ...    2.0      1.8  2.285714  3.67  3.25   \n",
       "\n",
       "      STAND     IUS-P  IUS-I  SES  performance  \n",
       "0  4.666667  3.142857    2.8  2.4     1.684569  \n",
       "1  5.000000  2.714286    1.8  3.1     1.376404  \n",
       "2  4.333333  2.142857    3.0  2.4    -0.098470  \n",
       "3  4.000000  3.428571    3.2  2.7     1.239223  \n",
       "4  4.000000  2.857143    1.8  3.0    -0.746350  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ern_df = pd.DataFrame()\n",
    "\n",
    "results_ern_df[eeg_columns_ern] = preprocessed_X_ern # simple mean amp of ERN in 0 -100 m\n",
    "results_ern_df = pd.concat([results_ern_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "results_ern_df.to_pickle(f\"../data/models_pickles_new_dass/ern_models_{dataset}.pkl\")\n",
    "results_ern_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7ea02-ae5e-4f45-89b7-a278b631ad55",
   "metadata": {},
   "source": [
    "1' CRN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "8bc00e6d-580a-4eeb-89c9-2b8573976554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_CRN</th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>BAS_NAG</th>\n",
       "      <th>...</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.337408e-07</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.25</td>\n",
       "      <td>10.298817</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.684569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.552095e-06</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.376404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.552639e-06</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.40</td>\n",
       "      <td>14.306246</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.098470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.879014e-06</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.239223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.275722e-07</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.25</td>\n",
       "      <td>8.915005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.746350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          e_CRN       RRQ  DASS-21 Stress  DASS-21 Dep  STAI-T  STAI-S Diff  \\\n",
       "0 -4.337408e-07  3.416667        1.285714     2.142857    2.25    10.298817   \n",
       "1 -2.552095e-06  3.750000        1.142857     1.285714    2.00     8.185239   \n",
       "2 -8.552639e-06  3.833333        1.857143     1.571429    2.40    14.306246   \n",
       "3  4.879014e-06  2.250000        3.000000     2.571429    2.80     8.185239   \n",
       "4 -6.275722e-07  3.916667        2.142857     1.571429    2.25     8.915005   \n",
       "\n",
       "   BIS  BAS_D  BAS_PRZY  BAS_NAG  ...  T-CTR  OB_PERF        PS   AMB  PRED  \\\n",
       "0  2.9   1.75      2.50      3.0  ...    4.0      4.0  1.428571  4.83  4.25   \n",
       "1  2.7   2.00      3.50      2.6  ...    1.6      2.6  2.714286  4.17  3.75   \n",
       "2  3.1   1.50      2.50      2.6  ...    1.8      3.2  3.285714  4.00  4.25   \n",
       "3  3.0   2.50      2.50      2.8  ...    1.2      2.0  3.428571  3.33  3.00   \n",
       "4  3.0   3.00      3.75      3.0  ...    2.0      1.8  2.285714  3.67  3.25   \n",
       "\n",
       "      STAND     IUS-P  IUS-I  SES  performance  \n",
       "0  4.666667  3.142857    2.8  2.4     1.684569  \n",
       "1  5.000000  2.714286    1.8  3.1     1.376404  \n",
       "2  4.333333  2.142857    3.0  2.4    -0.098470  \n",
       "3  4.000000  3.428571    3.2  2.7     1.239223  \n",
       "4  4.000000  2.857143    1.8  3.0    -0.746350  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_crn_df = pd.DataFrame()\n",
    "\n",
    "results_crn_df[eeg_columns_crn] = preprocessed_X_crn # simple mean amp of ERN in 0 -100 ms\n",
    "results_crn_df = pd.concat([results_crn_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "results_crn_df.to_pickle(f\"../data/models_pickles_new_dass/crn_models_{dataset}.pkl\")\n",
    "results_crn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9e322-46a5-468a-af1e-0254feeaf3ea",
   "metadata": {},
   "source": [
    "2. ERN, Fractional Area Latency + DEMO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "d2f33769-958e-41e6-a3d6-0270db6d44d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_ERN</th>\n",
       "      <th>e_LT_F</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Handness</th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.622882e-07</td>\n",
       "      <td>0.082812</td>\n",
       "      <td>0.424951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.25</td>\n",
       "      <td>10.298817</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.684569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.121127e-05</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.424985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.376404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.579851e-05</td>\n",
       "      <td>0.063281</td>\n",
       "      <td>0.425040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.40</td>\n",
       "      <td>14.306246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.098470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.217479e-07</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.239223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.456946e-06</td>\n",
       "      <td>0.059375</td>\n",
       "      <td>0.425062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.25</td>\n",
       "      <td>8.915005</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.746350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          e_ERN    e_LT_F       Age  Sex  Handness       RRQ  DASS-21 Stress  \\\n",
       "0 -6.622882e-07  0.082812  0.424951  1.0       1.0  3.416667        1.285714   \n",
       "1 -1.121127e-05  0.106250  0.424985  1.0       1.0  3.750000        1.142857   \n",
       "2 -1.579851e-05  0.063281  0.425040  1.0       1.0  3.833333        1.857143   \n",
       "3 -5.217479e-07  0.004687  0.425113  1.0       1.0  2.250000        3.000000   \n",
       "4 -6.456946e-06  0.059375  0.425062  1.0       1.0  3.916667        2.142857   \n",
       "\n",
       "   DASS-21 Dep  STAI-T  STAI-S Diff  ...  T-CTR  OB_PERF        PS   AMB  \\\n",
       "0     2.142857    2.25    10.298817  ...    4.0      4.0  1.428571  4.83   \n",
       "1     1.285714    2.00     8.185239  ...    1.6      2.6  2.714286  4.17   \n",
       "2     1.571429    2.40    14.306246  ...    1.8      3.2  3.285714  4.00   \n",
       "3     2.571429    2.80     8.185239  ...    1.2      2.0  3.428571  3.33   \n",
       "4     1.571429    2.25     8.915005  ...    2.0      1.8  2.285714  3.67   \n",
       "\n",
       "   PRED     STAND     IUS-P  IUS-I  SES  performance  \n",
       "0  4.25  4.666667  3.142857    2.8  2.4     1.684569  \n",
       "1  3.75  5.000000  2.714286    1.8  3.1     1.376404  \n",
       "2  4.25  4.333333  2.142857    3.0  2.4    -0.098470  \n",
       "3  3.00  4.000000  3.428571    3.2  2.7     1.239223  \n",
       "4  3.25  4.000000  2.857143    1.8  3.0    -0.746350  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ern_lat_df = pd.DataFrame()\n",
    "\n",
    "results_ern_lat_df[eeg_columns_ern] = preprocessed_X_ern # simple mean amp of ERN in 0 -100 ms\n",
    "results_ern_lat_df[eeg_column_latencies_fal] = fractional_latencies_ern # latency of the largest amplitude within channels in ms\n",
    "# results_ern_lat_df[eeg_column_ch_type] = channels_type_ern # the biggest peak on the central || left || right channels \n",
    "results_ern_lat_df = pd.concat([results_ern_lat_df, demographical_scores_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "results_ern_lat_df.to_pickle(f\"../data/models_pickles_new_dass/ern_cov_fal_models_{dataset}.pkl\")\n",
    "results_ern_lat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4b59d-c4f6-4981-8c24-e15469a1a3d0",
   "metadata": {},
   "source": [
    "2' CRN, Fractional Area Latency (2 uV) + DEMO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "90ba4903-e223-45ed-9abf-cdccc5920eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_CRN</th>\n",
       "      <th>e_LT_F2_C</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Handness</th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.337408e-07</td>\n",
       "      <td>0.133594</td>\n",
       "      <td>0.424951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.25</td>\n",
       "      <td>10.298817</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.684569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.552095e-06</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.424985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.376404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.552639e-06</td>\n",
       "      <td>0.098437</td>\n",
       "      <td>0.425040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.40</td>\n",
       "      <td>14.306246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.098470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.879014e-06</td>\n",
       "      <td>-0.007031</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.239223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.275722e-07</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.425062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.25</td>\n",
       "      <td>8.915005</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.746350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          e_CRN  e_LT_F2_C       Age  Sex  Handness       RRQ  DASS-21 Stress  \\\n",
       "0 -4.337408e-07   0.133594  0.424951  1.0       1.0  3.416667        1.285714   \n",
       "1 -2.552095e-06   0.137500  0.424985  1.0       1.0  3.750000        1.142857   \n",
       "2 -8.552639e-06   0.098437  0.425040  1.0       1.0  3.833333        1.857143   \n",
       "3  4.879014e-06  -0.007031  0.425113  1.0       1.0  2.250000        3.000000   \n",
       "4 -6.275722e-07   0.043750  0.425062  1.0       1.0  3.916667        2.142857   \n",
       "\n",
       "   DASS-21 Dep  STAI-T  STAI-S Diff  ...  T-CTR  OB_PERF        PS   AMB  \\\n",
       "0     2.142857    2.25    10.298817  ...    4.0      4.0  1.428571  4.83   \n",
       "1     1.285714    2.00     8.185239  ...    1.6      2.6  2.714286  4.17   \n",
       "2     1.571429    2.40    14.306246  ...    1.8      3.2  3.285714  4.00   \n",
       "3     2.571429    2.80     8.185239  ...    1.2      2.0  3.428571  3.33   \n",
       "4     1.571429    2.25     8.915005  ...    2.0      1.8  2.285714  3.67   \n",
       "\n",
       "   PRED     STAND     IUS-P  IUS-I  SES  performance  \n",
       "0  4.25  4.666667  3.142857    2.8  2.4     1.684569  \n",
       "1  3.75  5.000000  2.714286    1.8  3.1     1.376404  \n",
       "2  4.25  4.333333  2.142857    3.0  2.4    -0.098470  \n",
       "3  3.00  4.000000  3.428571    3.2  2.7     1.239223  \n",
       "4  3.25  4.000000  2.857143    1.8  3.0    -0.746350  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_crn_lat_demo_df = pd.DataFrame()\n",
    "\n",
    "results_crn_lat_demo_df[eeg_columns_crn] = preprocessed_X_crn # simple mean amp of ERN in 0 -100 ms\n",
    "results_crn_lat_demo_df[eeg_column_latencies_fal_2_crn] = fractional_latencies_crn_2uV # latency of the largest amplitude within channels in ms\n",
    "# results_crn_lat_demo_df[eeg_column_ch_type_crn] = channels_type_crn # the biggest peak on the central || left || right channels \n",
    "results_crn_lat_demo_df = pd.concat([results_crn_lat_demo_df, demographical_scores_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "results_crn_lat_demo_df.to_pickle(f\"../data/models_pickles_new_dass/crn_cov_fal2_models_{dataset}.pkl\")\n",
    "results_crn_lat_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54434d7-37ce-40ff-8264-ddb0c0e470b2",
   "metadata": {},
   "source": [
    "2'' CRN, Fractional Area Latency (6 uV), Lateralization + DEMO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ce2b51-c8cb-4120-ac03-3a9ac13d6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_crn_lat_demo_df = pd.DataFrame()\n",
    "\n",
    "# results_crn_lat_demo_df[eeg_columns_crn] = preprocessed_X_crn # simple mean amp of ERN in 0 -100 ms\n",
    "# results_crn_lat_demo_df[eeg_column_latencies_fal_6_crn] = fractional_latencies_crn_6uV # latency of the largest amplitude within channels in ms\n",
    "# # results_crn_lat_demo_df[eeg_column_ch_type_crn] = channels_type_crn # the biggest peak on the central || left || right channels \n",
    "# results_crn_lat_demo_df = pd.concat([results_crn_lat_demo_df, demographical_scores_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "# results_crn_lat_demo_df.to_pickle(f\"../data/models_pickles_new/crn_cov_fal6_models_{dataset}.pkl\")\n",
    "# results_crn_lat_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ff81e-8fd4-49a6-9fb0-f40d25d9c9e5",
   "metadata": {},
   "source": [
    "3.ERN, Peak Latency, Lateralization + DEMO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a121a0d1-afea-479e-8d39-1133e4bc40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_ern_lat_df = pd.DataFrame()\n",
    "\n",
    "# results_ern_lat_df[eeg_columns_ern] = preprocessed_X_ern # simple mean amp of ERN in 0 -100 ms\n",
    "# results_ern_lat_df[eeg_column_latencies_peak] = peak_latencies_ern # latency of the largest amplitude within channels in ms\n",
    "# # results_ern_lat_df[eeg_column_ch_type] = channels_type_ern # the biggest peak on the central || left || right channels \n",
    "# results_ern_lat_df = pd.concat([results_ern_lat_df, demographical_scores_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "# results_ern_lat_df.to_pickle(f\"../data/models_pickles_new/ern_cov_peak_models_{dataset}.pkl\")\n",
    "# results_ern_lat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20587b64-72f6-4920-b492-f1a5eb44afa8",
   "metadata": {},
   "source": [
    "3'. CRN, Peak Latency, Lateralization + DEMO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6011800d-63dc-4f2b-b7b5-9911b29ede68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_crn_lat_demo_df = pd.DataFrame()\n",
    "\n",
    "# results_crn_lat_demo_df[eeg_columns_crn] = preprocessed_X_crn # simple mean amp of ERN in 0 -100 ms\n",
    "# results_crn_lat_demo_df[eeg_column_latencies_peak_crn] = peak_latencies_crn # latency of the largest amplitude within channels in ms\n",
    "# # results_crn_lat_demo_df[eeg_column_ch_type_crn] = channels_type_crn # the biggest peak on the central || left || right channels \n",
    "# results_crn_lat_demo_df = pd.concat([results_crn_lat_demo_df, demographical_scores_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "# results_crn_lat_demo_df.to_pickle(f\"../data/models_pickles_new/crn_cov_peak_models_{dataset}.pkl\")\n",
    "# results_crn_lat_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e596490-fa93-4c4c-9831-90b84c968bc7",
   "metadata": {},
   "source": [
    "----\n",
    "## Transform non-normal data distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987f3894-aee7-4858-ac6c-5f51a4b38afa",
   "metadata": {},
   "source": [
    "Check skewness and kurtiosis\n",
    "\n",
    "As a general rule of thumb: If skewness is less than -1 or greater than 1, the distribution is highly skewed. If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed. If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n",
    "\n",
    "Analogous to the skewness, the general guideline is that if the kurtosis is greater than +2, the distribution is too peaked. Likewise, a kurtosis of less than −2 indicates a distribution that is too flat. When both skewness and kurtosis are close to zero, the pattern of responses is considered a normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "0f1da5d0-e2f9-45dd-8886-0a757073c362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "a02b2b34-86fd-4319-997e-c23a6eae9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_data_df = pd.read_pickle(f\"../data/models_pickles_new_dass/ern_models_{dataset}.pkl\")\n",
    "ern_cov_fal_data_df = pd.read_pickle(f\"../data/models_pickles_new_dass/ern_cov_fal_models_{dataset}.pkl\")\n",
    "# ern_cov_peak_data_df = pd.read_pickle(f'../data/models_pickles_new/ern_cov_peak_models_{dataset}.pkl')\n",
    "\n",
    "crn_data_df = pd.read_pickle(f\"../data/models_pickles_new_dass/crn_models_{dataset}.pkl\")\n",
    "crn_cov_fal2_data_df = pd.read_pickle(f\"../data/models_pickles_new_dass/crn_cov_fal2_models_{dataset}.pkl\")\n",
    "# crn_cov_fal6_data_df = pd.read_pickle(f\"../data/models_pickles_new/crn_cov_fal6_models_{dataset}.pkl\")\n",
    "# crn_cov_peak_data_df = pd.read_pickle(f'../data/models_pickles_new/crn_cov_peak_models_{dataset}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "cab16a18-c5d3-45c7-9ed3-383588f69404",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ern_data_df, \n",
    "    ern_cov_fal_data_df, \n",
    "    # ern_cov_peak_data_df,\n",
    "    crn_data_df,\n",
    "    crn_cov_fal2_data_df,\n",
    "    # crn_cov_fal6_data_df,\n",
    "    # crn_cov_peak_data_df,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650acd8d-11e7-4e5c-a438-ebb819b81b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_exclude = ['Sex', 'Handness', 'e_LTR_C', 'e_LTR']\n",
    "# datasets_transformed = []\n",
    "\n",
    "# for dataset in datasets:\n",
    "#     columns = dataset.columns\n",
    "#     columns_to_process =  list(set(columns) - set(columns_to_exclude))\n",
    "#     summary = dataset[columns_to_process].agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "#     # display(summary)\n",
    "    \n",
    "#     dataset_transformed = dataset.copy()\n",
    "\n",
    "#     for row in summary.iterrows():\n",
    "#         item_name = row[0]\n",
    "#         skewness_ = row[1]['skew']\n",
    "#         kurtosis_ = row[1]['kurtosis']\n",
    "\n",
    "#         if abs(skewness_) > 1 or abs(kurtosis_) > 2:\n",
    "#             print(f'Transforming: {item_name} scale')\n",
    "#             this_scores = dataset_transformed[[item_name]].to_numpy().flatten()\n",
    "#             this_scores = this_scores - 0.99\n",
    "#             this_scores_transformed, lambda_ = boxcox(this_scores)\n",
    "#             print(f'   Stats before transformation:\\n    Skewness: {skew(this_scores)} \\n    Kurtosis: {scipy.stats.kurtosis(this_scores)}')\n",
    "#             print(f'   Stats after transformation:\\n    Skewness: {skew(this_scores_transformed)} \\n    Kurtosis: {scipy.stats.kurtosis(this_scores_transformed)}')\n",
    "\n",
    "#             dataset_transformed[[item_name]] = this_scores_transformed.reshape(-1,1)\n",
    "#         else:\n",
    "#             # print(f\"Nothing to transform\")\n",
    "#             pass\n",
    "#     summary = dataset_transformed[columns_to_process].agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "#     # display(summary)   \n",
    "    \n",
    "#     datasets_transformed.append(dataset_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31a9f2e9-1ae3-46d0-9438-8ce44b90fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to transform now, so no write"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net",
   "language": "python",
   "name": "net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
