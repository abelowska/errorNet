{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a73099-38c1-4bf0-afd3-5481df7c3d19",
   "metadata": {},
   "source": [
    "# Extraction of features for different models of error-related brain activity and anxiety dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff9f56-5483-44c7-b9cc-486a31838279",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e84d26-b32c-41ae-b3f4-81e0ee55156b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "import ast\n",
    "import os.path as op\n",
    "import pickle\n",
    "import mne\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "\n",
    "import pygsp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.utils import resample\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.integrate import simpson\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from autoreject import AutoReject\n",
    "\n",
    "from transformers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c69899-6a32-4418-9079-8bd66aed497f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Load data\n",
    "\n",
    "Loading EEG data and data from rumination questionnaire. By default create_df_data loads all info from given file but one can specify it by passing a list of desired labels from csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc483a7-410f-4b65-9955-9df42c783bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths TODO\n",
    "dir_path = os.path.dirname(os.path.abspath(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a25389-d030-415b-982d-b68df981b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = -0.1, 0.6  # Start and end of the segments\n",
    "signal_frequency = 256\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c412f36-66a2-4fd8-bfa7-caa98c4a315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_data(\n",
    "    test_participants=False,\n",
    "    test_epochs=False,\n",
    "    info_filename=None,\n",
    "    info=\"all\",\n",
    "    personal=True,\n",
    "):\n",
    "    \"\"\"Loads data for all participants and create DataFrame with optional additional info from given .csv file.\n",
    "\n",
    "    On default, loads a train set: chooses only 80% of participants\n",
    "    and for each of them chooses 80% of epochs.\n",
    "    It will choose them deterministically.\n",
    "\n",
    "    Participants with less than 10 epochs per condition are rejected.\n",
    "\n",
    "    If test_participants is set to True, it will load remaining 20% of participants.\n",
    "    If test_epochs is set to True, it will load remaining 20% of epochs.\n",
    "    Test epochs are chronologically after train epochs,\n",
    "    because it reflects real usage (first callibration and then classification).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_participants: bool\n",
    "        whether load data for training or final testing.\n",
    "        If true load participants data for testing.\n",
    "    test_epochs: bool\n",
    "        whether load data for training or final testing.\n",
    "        If true load epochs of each participants data for testing.\n",
    "    info_filename: String | None\n",
    "        path to .csv file with additional data.\n",
    "    info: array\n",
    "        listed parameters from the info file to be loaded.\n",
    "        if 'all', load all parameters\n",
    "    personal: bool\n",
    "        whether a model will be both trained and tested on epochs from one person\n",
    "        if false, person's epochs aren't split into test and train\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    go_nogo_data_df : pandas.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    print(os.path.abspath(\"\"))\n",
    "    dir_path = os.path.dirname(os.path.abspath(\"\"))\n",
    "    print(dir_path)\n",
    "    header_files_glob = os.path.join(dir_path, \"data/responses_100_600_sonata/*.vhdr\")\n",
    "    header_files = glob.glob(header_files_glob)\n",
    "\n",
    "    header_files = sorted(header_files)\n",
    "    go_nogo_data_df = pd.DataFrame()\n",
    "\n",
    "    # cut 20% of data for testing\n",
    "    h_train, h_test = train_test_split(header_files, test_size=0.3, random_state=0)\n",
    "    \n",
    "    print(f\"train size: {len(h_train)} ; test size: {len(h_test)}\")\n",
    "\n",
    "    if test_participants:\n",
    "        header_files = h_test\n",
    "    else:\n",
    "        header_files = h_train\n",
    "\n",
    "    for file in header_files:\n",
    "        #  load eeg data for given participant\n",
    "        participant_epochs = load_epochs_from_file(file)\n",
    "\n",
    "        # and compute participant's id from file_name\n",
    "        participant_id = re.match(r\".*GNG-(\\d+).*\", file).group(1)\n",
    "\n",
    "        error = participant_epochs[\"error_response\"]._data\n",
    "        correct = participant_epochs[\"correct_response\"]._data\n",
    "\n",
    "        # exclude those participants who have too few samples\n",
    "        if len(error) < 5 or len(correct) < 5:\n",
    "            # not enough data for this participant\n",
    "            continue\n",
    "\n",
    "        # construct dataframe for participant with: id|epoch_data|response_type|additional info...\n",
    "        participant_df = create_df_from_epochs(\n",
    "            participant_id, participant_epochs, info_filename, info\n",
    "        )\n",
    "        print(participant_id)\n",
    "        go_nogo_data_df = go_nogo_data_df.append(participant_df, ignore_index=True)\n",
    "\n",
    "    return go_nogo_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0991419b-7acd-42bc-b048-e5e9fa3cb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_epochs(id, participant_epochs, info_filename, info):\n",
    "    \"\"\"Create df for each participant. DF structure is like: {id: String ; epoch: epoch_data ; marker: 1.0|0.0}\n",
    "    1.0 means correct and 0.0 means error response.\n",
    "    Default info extracted form .csv file is 'Rumination Full Scale' and participants' ids.\n",
    "    With this info df structure is like:\n",
    "    {id: String ; epoch: epoch_data ; marker: 1.0|0.0 ; File: id ; 'Rumination Full Scale': int}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    id: String\n",
    "        participant's id extracted from filename\n",
    "    correct: array\n",
    "        correct responses' data\n",
    "    error: array\n",
    "        error responses' data\n",
    "    info_filename: String\n",
    "        path to .csv file with additional data.\n",
    "    info: array\n",
    "        listed parameters from the info file to be loaded.\n",
    "        if 'all', load all parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    participant_df : pandas.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    participant_df = pd.DataFrame()\n",
    "    info_df = pd.DataFrame()\n",
    "\n",
    "    # get additional info from file\n",
    "    if info_filename is not None:\n",
    "        if info == \"all\":\n",
    "            rumination_df = pd.read_csv(info_filename, dtype={'Demo_kod': object})\n",
    "        else:\n",
    "            rumination_df = pd.read_csv(info_filename, usecols=[\"Demo_kod\"] + info, dtype={'Demo_kod': object})\n",
    "        info_df = (\n",
    "            rumination_df.loc[rumination_df[\"Demo_kod\"] == id]\n",
    "            .reset_index()\n",
    "            .drop(\"index\", axis=1)\n",
    "        )      \n",
    "    epoch_df = pd.DataFrame({\"id\": [id], \"epoch\": [participant_epochs]}).join(\n",
    "            info_df\n",
    "        )\n",
    "    participant_df = participant_df.append(epoch_df, ignore_index=True)\n",
    "\n",
    "    return participant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa88517e-884a-4b5b-9652-1bf2e7787aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_epochs_from_file(file, reject_bad_segments=\"auto\", mask=None):\n",
    "    \"\"\"Load epochs from a header file.\n",
    "\n",
    "    Args:\n",
    "        file: path to a header file (.vhdr)\n",
    "        reject_bad_segments: 'auto' means that bad segments are rejected automatically.\n",
    "\n",
    "    Returns:\n",
    "        mne Epochs\n",
    "\n",
    "    \"\"\"\n",
    "    # Import the BrainVision data into an MNE Raw object\n",
    "    raw = mne.io.read_raw_brainvision(file)\n",
    "\n",
    "    # Construct annotation filename\n",
    "    annot_file = file[:-4] + \"vmrk\"\n",
    "\n",
    "    # Read in the event information as MNE annotations\n",
    "    annotations = mne.read_annotations(annot_file)\n",
    "\n",
    "    # Add the annotations to our raw object so we can use them with the data\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    # Map with response markers only\n",
    "    # event_dict = {\n",
    "    #     \"Stimulus/RE*ex*1_n*1_c_1*R*FB\": 10004,\n",
    "    #     \"Stimulus/RE*ex*1_n*1_c_1*R*FG\": 10005,\n",
    "    #     \"Stimulus/RE*ex*1_n*1_c_2*R\": 10006,\n",
    "    #     \"Stimulus/RE*ex*1_n*2_c_1*R\": 10007,\n",
    "    #     \"Stimulus/RE*ex*2_n*1_c_1*R\": 10008,\n",
    "    #     \"Stimulus/RE*ex*2_n*2_c_1*R*FB\": 10009,\n",
    "    #     \"Stimulus/RE*ex*2_n*2_c_1*R*FG\": 10010,\n",
    "    #     \"Stimulus/RE*ex*2_n*2_c_2*R\": 10011,\n",
    "    # }\n",
    "    \n",
    "    event_dict = {\n",
    "        'Stimulus/RE*ex*1_n*1_c_1*R*FB': 10003,\n",
    "        'Stimulus/RE*ex*1_n*1_c_1*R*FG': 10004,\n",
    "        'Stimulus/RE*ex*1_n*1_c_2*R': 10005,\n",
    "        'Stimulus/RE*ex*1_n*2_c_1*R': 10006,\n",
    "        'Stimulus/RE*ex*2_n*1_c_1*R': 10007,\n",
    "        'Stimulus/RE*ex*2_n*2_c_1*R*FB': 10008,\n",
    "        'Stimulus/RE*ex*2_n*2_c_1*R*FG': 10009,\n",
    "        'Stimulus/RE*ex*2_n*2_c_2*R': 10010,\n",
    "    }\n",
    "\n",
    "    # Map for merged correct/error response markers\n",
    "    merged_event_dict = {\"correct_response\": 0, \"error_response\": 1}\n",
    "\n",
    "    # Reconstruct the original events from Raw object\n",
    "    events, event_ids = mne.events_from_annotations(raw, event_id=event_dict)\n",
    "\n",
    "    # Merge correct/error response events\n",
    "    merged_events = mne.merge_events(\n",
    "        events,\n",
    "        [10003, 10004, 10008, 10009],\n",
    "        merged_event_dict[\"correct_response\"],\n",
    "        replace_events=True,\n",
    "    )\n",
    "    merged_events = mne.merge_events(\n",
    "        merged_events,\n",
    "        [10005, 10006, 10007, 10010],\n",
    "        merged_event_dict[\"error_response\"],\n",
    "        replace_events=True,\n",
    "    )\n",
    "\n",
    "    epochs = []\n",
    "    bads = []\n",
    "    this_reject_by_annotation = False\n",
    "    \n",
    "    # Read epochs\n",
    "    epochs = mne.Epochs(\n",
    "        raw=raw,\n",
    "        events=merged_events,\n",
    "        event_id=merged_event_dict,\n",
    "        tmin=tmin,\n",
    "        tmax=tmax,\n",
    "        baseline=None,\n",
    "        reject_by_annotation=this_reject_by_annotation,\n",
    "        preload=True,\n",
    "    )\n",
    "    \n",
    "    ar = AutoReject(random_state=random_state, n_jobs=10, verbose=0)\n",
    "    epochs_ar, reject_log = ar.fit_transform(epochs, return_log=True)\n",
    "    \n",
    "    return epochs_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5e07d-9618-47de-a706-687a529fb2fe",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "264dc68c-de05-4885-b579-2d887884ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_column_names(data_df):\n",
    "    columns_dict = {\n",
    "        \"16-Rumination Full Scale\": \"RRQ\", # mean\n",
    "        \"05-DASS-21 Anxiety scale\": \"DASS-21 Anx\", # mean\n",
    "        ###\n",
    "        \"05-DASS-21 Stress scale\": \"DASS-21 Stress\", # mean\n",
    "        \"05-DASS-21 Depression scale\": \"DASS-21 Dep\", # mean\n",
    "        \"04-STAI Trait MEAN\": \"STAI-T_M\", # mean\n",
    "        \"04-STAI STATE 1-2 DIFFERENCE\": \"STAI-S Diff\", # sum\n",
    "        \"number_error\" : \"uninhibited response\", # sum\n",
    "        \"number_inhibited\" : \"inhibited response\", # sum\n",
    "        ###\n",
    "        \"04-STAI Trait SUM\": \"STAI-T\", # sum\n",
    "        \"07-BIS\": \"BIS\", # mean\n",
    "        \"14-Obsessive-Compulsive WASHING\": \"WASH\", # mean\n",
    "        \"14-Obsessive-Compulsive OBSESSING\": \"OBSESS\", # mean\n",
    "        \"14-Obsessive-Compulsive HOARDING\": \"HOARD\", # mean\n",
    "        \"14-Obsessive-Compulsive ORDERING\": \"ORD\", # mean\n",
    "        \"14-Obsessive-Compulsive CHECKING\": \"CHECK\", # mean\n",
    "        \"14-Obsessive-Compulsive NEUTRALIZING\": \"NEU\", # mean\n",
    "        # \"14-Obsessive-Compulsive FULL\": \"OCI-R\",\n",
    "        \"18-Thought Suppression Inventory\": \"WBSI\", # mean\n",
    "        \"28-Intolerance of Uncertainty - Prospective Anxiety\": \"IUS-P\", # mean\n",
    "        \"28-Intolerance of Uncertainty - Inhibitory Anxiety\": \"IUS-I\", # mean\n",
    "        \"06-Self-Esteem Scale_SES Rosenberga\": \"SES\", # mean\n",
    "        \"07-BAS Dzialanie\": 'BAS_D', # mean\n",
    "        \"07-BAS Poszukiwanie przyjemnosci\": 'BAS_PRZY', # mean\n",
    "        \"07-BAS Wrazliwosc na nagrode\": 'BAS_NAG', # mean\n",
    "        \"22-Nonforgiveness - Full Scale\": 'NONFOR',\n",
    "        \"27-Indecisiveness Scale_Frost\": 'INDEC_F', # mean\n",
    "        \"03-SP (Punishment Sensitivity)\": 'PUN', # sum\n",
    "        \"03-SR (Reward Sensitivity)\": 'REW', # sum\n",
    "        \"15-Obsessional Beliefs - Inflated responsibility for harm\": 'HARM', # mean\n",
    "        \"15-Obsessional Beliefs - Importance/Control of Thoughts\": 'T-CTR', # mean\n",
    "        \"15-Obsessional Beliefs - Overestimation of threat\": \"OT\", # mean\n",
    "        \"15-Obsessional Beliefs - Perfectionism/ Intolerance of uncertainty\": 'OB_PERF', # mean\n",
    "        \"17-Perfectionism CMDA\": 'CMDA', # mean\n",
    "        \"17-Perfect PS-Personal Standards (7 items mean)\" : 'PS', # mean\n",
    "        \"19-Guilt sensitivity\": 'G_SE', # mean\n",
    "        \"31-NFC Nietolerancja wieloznaczności-FULL\": 'AMB', # mean\n",
    "        \"31-NFC Preferowanie przewidywalności-FULL\": 'PRED', # mean\n",
    "        \"32-High standards from Maximization Full Scale\" : 'STAND',   # mean\n",
    "        \"Wiek\": \"Age\",\n",
    "        \"Płeć\": \"Sex\",\n",
    "        \"Ręczność\": \"Handness\",    \n",
    "\n",
    "        #######\n",
    "        \"Rumination Full Scale\": \"RRQ\",\n",
    "        \"DASS-21 Anxiety scale 0-SUM\": \"DASS-21 Anx\", # sum\n",
    "        \"DASS-21 Stress scale 0-SUM\": \"DASS-21 Stress\", # sum\n",
    "        \"DASS-21 Depression scale 0-SUM\": \"DASS-21 Dep\", # sum\n",
    "        \"number_error\": \"uninhibited response\", # sum\n",
    "        \"number_inhibited\":  \"inhibited response\", # sum\n",
    "        \"STAI STATE 1-2 DIFFERENCE\": \"STAI-S Diff\", # sum\n",
    "        ###\n",
    "        \"STAI Trait SUM\": \"STAI-T\", # sum\n",
    "        \"BIS\": \"BIS\", # mean\n",
    "        \"Obsessive-Compulsive WASHING\": \"WASH\", # mean\n",
    "        \"Obsessive-Compulsive OBSESSING\": \"OBSESS\", # mean\n",
    "        \"Obsessive-Compulsive HOARDING\": \"HOARD\", # mean\n",
    "        \"Obsessive-Compulsive ORDERING\": \"ORD\", # mean\n",
    "        \"Obsessive-Compulsive CHECKING\": \"CHECK\", # mean\n",
    "        \"Obsessive-Compulsive NEUTRALIZING\": \"NEU\", # mean\n",
    "        # \"14-Obsessive-Compulsive FULL\": \"OCI-R\",\n",
    "        \"Thought Suppression Inventory\": \"WBSI\", # mean\n",
    "        \"Intolerance of Uncertainty - Prospective Anxiety\": \"IUS-P\", # mean\n",
    "        \"Intolerance of Uncertainty - Inhibitory Anxiety\": \"IUS-I\", # mean\n",
    "        \"Self-Esteem Scale_SES Rosenberga MEAN\": \"SES\", # mean\n",
    "        \"BAS Dzialanie\": 'BAS_D', # mean # drive\n",
    "        \"BAS Poszukiwanie przyjemnosci\": 'BAS_PRZY', # mean # fun seeking\n",
    "        \"BAS Wrazliwosc na nagrode\": 'BAS_NAG', # mean # responsivness\n",
    "        # \"22-Nonforgiveness - Full Scale\": 'NONFOR',\n",
    "        \"Indecisiveness Scale_Frost\": 'INDEC_F', # mean\n",
    "        \"SP (Punishment Sensitivity)\": 'PUN', # sum\n",
    "        \"SR (Reward Sensitivity)\": 'REW', # sum\n",
    "        \"Obsessional Beliefs - Inflated responsibility for harm\": 'HARM', # mean\n",
    "        \"Obsessional Beliefs - Importance/Control of Thoughts\": 'T-CTR', # mean\n",
    "        \"Obsessional Beliefs - Overestimation of threat\": \"OT\", # mean\n",
    "        \"Obsessional Beliefs - Perfectionism/ Intolerance of uncertainty\": 'OB_PERF', # mean\n",
    "        # \"17-Perfectionism CMDA\": 'CMDA',\n",
    "        \"Perfect PS-Personal Standards (7 items mean)\" : 'PS', # mean\n",
    "        \"Guilt sensitivity\": 'G_SE', # mean\n",
    "        \"Nietolerancja wieloznaczności-FULL\": 'AMB', # mean\n",
    "        \"Preferowanie przewidywalności-FULL\": 'PRED', # mean\n",
    "        \"High standards from Maximization Full Scale\" : 'STAND',   # mean\n",
    "    }\n",
    "\n",
    "    data_df = data_df.rename(columns=columns_dict)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a6b99d-7821-44cb-b669-8ce682ce193c",
   "metadata": {},
   "source": [
    "- read Opus train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9db8c673-5477-4126-b09d-870a8fcd9477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled file found. Loading pickled data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "df_name = \"GNG_autoreject_3_5\"\n",
    "# df_name = \"GNG_reject_auto_3-5\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "info_filename = \"../data/scales/Sonata_scales.csv\"\n",
    "\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_train_opus_df = pd.read_pickle(pickled_data_filename)\n",
    "    epochs_train_opus_df.name = df_name\n",
    "    epochs_train_opus_df = change_column_names(epochs_train_opus_df)\n",
    "    print(\"Done\")\n",
    "    pass\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_train_opus_df = create_df_data(\n",
    "        test_participants=False, info=\"all\", personal=False, info_filename=info_filename\n",
    "    )\n",
    "    epochs_train_opus_df.name = df_name\n",
    "    epochs_train_opus_df = change_column_names(epochs_train_opus_df)\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_train_opus_df.to_pickle(\"../data/\" + epochs_train_opus_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa25d09-4ebb-4c3e-a89a-8ae1b80c7a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 188)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train_opus_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b87e8aa-5ca4-4735-a004-7fd9a5a414d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train_opus_df['STAI-T'] = epochs_train_opus_df['STAI-T'].apply(lambda x: x/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abffccca-5b70-4843-b39f-c90e38ce92a8",
   "metadata": {},
   "source": [
    "- read Sonata train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f6b138-bc55-49c5-9eff-940a01b5bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled file found. Loading pickled data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "df_name = \"GNG_autoreject_sonata_3_5_stai\"\n",
    "# df_name = \"GNG_reject_auto_3-5\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "info_filename = \"../data/scales/Sonata_scales.csv\"\n",
    "\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_train_sonata_df = pd.read_pickle(pickled_data_filename)\n",
    "    epochs_train_sonata_df.name = df_name\n",
    "    epochs_train_sonata_df = change_column_names(epochs_train_sonata_df)\n",
    "    print(\"Done\")\n",
    "    pass\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_train_sonata_df = create_df_data(\n",
    "        test_participants=False, info=\"all\", personal=False, info_filename=info_filename\n",
    "    )\n",
    "    epochs_train_sonata_df.name = df_name\n",
    "    epochs_train_sonata_df = change_column_names(epochs_train_sonata_df)\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_train_sonata_df.to_pickle(\"../data/\" + epochs_train_sonata_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23c4ef30-2d15-43d6-966e-a4118714233b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 110)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train_sonata_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b200393a-2f77-480d-b973-c92c6c64fa1a",
   "metadata": {},
   "source": [
    "Refine some data from questionnaries to reconcile data from two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe2568a-e1d2-4c8b-92f7-151b862e1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train_sonata_df.loc[epochs_train_sonata_df['Sex'] == 'Osoba niebinarna', 'Sex'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e41a7a0-7541-4020-87ae-7f305d7a157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize DASS-21 subscales scores to mean\n",
    "epochs_train_sonata_df['DASS-21 Stress'] = epochs_train_sonata_df['DASS-21 Stress'].apply(lambda x: (x + 7)/7)\n",
    "epochs_train_sonata_df['DASS-21 Anx'] = epochs_train_sonata_df['DASS-21 Anx'].apply(lambda x: (x + 7)/7)\n",
    "epochs_train_sonata_df['DASS-21 Dep'] = epochs_train_sonata_df['DASS-21 Dep'].apply(lambda x: (x + 7)/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7219ac12-4837-41a1-abad-29ae5fdd4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize STAI state scale to mean (divide by amount of items in subscale)\n",
    "epochs_train_sonata_df['STAI-T'] = epochs_train_sonata_df['STAI-T'].apply(lambda x: x/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b04671-603a-4678-8889-8f77cf9a28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing value in STAI-S Diff score\n",
    "epochs_train_sonata_df.loc[epochs_train_sonata_df['STAI-S Diff'] == 'None', 'STAI-S Diff'] = None\n",
    "epochs_train_sonata_df['STAI-S Diff'] = np.array(epochs_train_sonata_df['STAI-S Diff'].to_list()).astype(np.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78171035-125b-4a1b-8b00-a8a8a7cfc594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_train_sonata_df['STAI-S Diff'] = epochs_train_sonata_df['STAI-S Diff'].fillna(epochs_train_sonata_df['STAI-S Diff'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055815fa-0d47-4bdd-9caf-51d60ced5d91",
   "metadata": {},
   "source": [
    "#### Read data for external testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7bdc7-6af8-4c64-957b-33f71c7d5d6e",
   "metadata": {},
   "source": [
    "- read Opus test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c990ac1-14fc-4d0c-bf5d-d96f076e1e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled file found. Loading pickled data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "df_name = \"GNG_autoreject_3_5_test_performance\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "# info_filename = \"../data/Demographic_Questionnaires_Behavioral_Results_N=163.csv\"\n",
    "# info_filename = \"../data/scales/all_scales.csv\"\n",
    "info_filename = \"../data/scales/Sonata_scales.csv\"\n",
    "\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_test_opus_df = pd.read_pickle(pickled_data_filename)\n",
    "    epochs_test_opus_df.name = df_name\n",
    "    epochs_test_opus_df = change_column_names(epochs_test_opus_df)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_test_opus_df = create_df_data(\n",
    "        test_participants=True, info=\"all\", personal=False, info_filename=info_filename\n",
    "    )\n",
    "    epochs_test_opus_df.name = df_name\n",
    "    epochs_test_opus_df = change_column_names(epochs_test_opus_df)\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_test_opus_df.to_pickle(\"../data/\" + epochs_test_opus_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "271cd307-5952-47a6-87f9-2a482da8924e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 164)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_test_opus_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "182b6d20-9599-4d6f-bf32-f8b98c14e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_test_opus_df['STAI-T'] = epochs_test_opus_df['STAI-T'].apply(lambda x: x/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b716470-7b11-4423-ac6d-cc65f2446aa3",
   "metadata": {},
   "source": [
    "- read Sonata test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f54d80f-6c7f-4c9c-a4a2-4564dd15c949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled file found. Loading pickled data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "df_name = \"GNG_autoreject_sonata_3_5_test_stai\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "# info_filename = \"../data/Demographic_Questionnaires_Behavioral_Results_N=163.csv\"\n",
    "# info_filename = \"../data/scales/all_scales.csv\"\n",
    "info_filename = \"../data/scales/Sonata_scales.csv\"\n",
    "\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_test_sonata_df = pd.read_pickle(pickled_data_filename)\n",
    "    epochs_test_sonata_df.name = df_name\n",
    "    epochs_test_sonata_df = change_column_names(epochs_test_sonata_df)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_test_sonata_df = create_df_data(\n",
    "        test_participants=True, info=\"all\", personal=False, info_filename=info_filename\n",
    "    )\n",
    "    epochs_test_sonata_df.name = df_name\n",
    "    epochs_test_sonata_df = change_column_names(epochs_test_sonata_df)\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_test_sonata_df.to_pickle(\"../data/\" + epochs_test_sonata_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "406ede1f-481c-4e12-9613-db9eeb0c147a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 110)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_test_sonata_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea677c-4f7e-4ec9-b034-823aaa526172",
   "metadata": {},
   "source": [
    "Refine some data from questionnaries to reconcile data from two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb09c36d-6613-4093-b6aa-4af0c49b3574",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_test_sonata_df.loc[epochs_test_sonata_df['Sex'] == 'Osoba niebinarna', 'Sex'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e80e3cdb-5907-48e4-99f3-89d2580780cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize DASS-21 subscales scores to mean\n",
    "epochs_test_sonata_df['DASS-21 Stress'] = epochs_test_sonata_df['DASS-21 Stress'].apply(lambda x: (x + 7)/7)\n",
    "epochs_test_sonata_df['DASS-21 Anx'] = epochs_test_sonata_df['DASS-21 Anx'].apply(lambda x: (x + 7)/7)\n",
    "epochs_test_sonata_df['DASS-21 Dep'] = epochs_test_sonata_df['DASS-21 Dep'].apply(lambda x: (x + 7)/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba725e66-37f2-4b5d-97bc-c509ab15468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize STAI state scale to mean (divide by amount of items in subscale)\n",
    "epochs_test_sonata_df['STAI-T'] = epochs_test_sonata_df['STAI-T'].apply(lambda x: x/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "162b5fa8-e82a-4df8-b9ae-8acaf64a643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing value in STAI-S Diff score\n",
    "epochs_test_sonata_df.loc[epochs_test_sonata_df['STAI-S Diff'] == 'None', 'STAI-S Diff'] = None\n",
    "epochs_test_sonata_df['STAI-S Diff'] = np.array(epochs_test_sonata_df['STAI-S Diff'].to_list()).astype(np.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f715e371-377a-465f-aefa-84cb7b8565cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_test_sonata_df['STAI-S Diff'] = epochs_test_sonata_df['STAI-S Diff'].fillna(epochs_test_sonata_df['STAI-S Diff'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e49fc-28b8-47ef-8a5d-5dd1dcfd915e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "784b4bd7-f3b6-4707-8662-b266913fb3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_columns_list = epochs_train_opus_df.columns.to_list()\n",
    "sonata_columns_list = epochs_train_sonata_df.columns.to_list()\n",
    "\n",
    "columns = list(set(opus_columns_list) & set(sonata_columns_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0cec6de-6ce0-458f-ad00-79de41daa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train_sonata_df = epochs_train_sonata_df[columns]\n",
    "epochs_train_opus_df = epochs_train_opus_df[columns]\n",
    "\n",
    "epochs_test_sonata_df = epochs_test_sonata_df[columns]\n",
    "epochs_test_opus_df = epochs_test_opus_df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a01eda1-84ea-4034-834a-7d56bfd8e828",
   "metadata": {},
   "source": [
    "Create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f96e09d-e718-4a2e-9555-41c942673904",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train_df = pd.concat([epochs_train_sonata_df, epochs_train_opus_df], ignore_index=True)\n",
    "epochs_test_df = pd.concat([epochs_test_sonata_df, epochs_test_opus_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e2f7d8-49ac-4955-b8ff-9af12f4a3dd3",
   "metadata": {},
   "source": [
    "#### Chose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1b99eb8-aa51-447d-81f2-cc7018f304df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = True\n",
    "dataset = 'test' if test else 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "39b940ac-d7f7-44fd-bbda-6a9503a388fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df = epochs_train_df if not test else epochs_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e98fe0f-a0ae-4022-93d8-b2382a82692e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 40)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bdb66d-6873-42d3-9290-11c006ba28ea",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "97a99ef1-7836-4575-8c1b-ea6f608fe3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "a = epochs_df[['Sex']].to_numpy().astype(int).flatten()\n",
    "print(a.sum())\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "bcdd97c2-eb5e-4485-97c2-6dd04ff0d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi = ['Fz']\n",
    "\n",
    "# for index in range(0, len(epochs_filtered)):\n",
    "#     epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))\n",
    "#     epochs = [epochs_df_copy.iloc[index]['epoch']]\n",
    "#     epochs_ = [epoch.copy().pick(roi) for epoch in epochs]\n",
    "#     epochs = mne.concatenate_epochs(epochs_)\n",
    "    \n",
    "#     evokeds = [epochs[name].copy().crop(tmin=-0.1, tmax=0.6).iter_evoked() for name in ('error_response', 'correct_response')]\n",
    "    \n",
    "#     plt.figure(index)\n",
    "    \n",
    "#     fig = mne.viz.plot_compare_evokeds(\n",
    "#     [list(evokeds[0]),list(evokeds[1])],\n",
    "#     show=False,\n",
    "#     ci=True,\n",
    "#     )\n",
    "\n",
    "#     axes = fig[0].axes\n",
    "\n",
    "#     axes[0].axhline(y=1, color='gray')\n",
    "#     axes[0].axhline(y=6, color='gray')\n",
    "\n",
    "#     # plt.axhline(y = 1*1e-6, color='gray', ls='--')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3f0b5a87-27b3-4bd3-b487-be6e5a3330b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi = ['Fz']\n",
    "# index= 0 # 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3024d376-15e4-4165-b675-ddb272f088c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))\n",
    "# epochs = [epochs_df_copy.iloc[index]['epoch']]\n",
    "# epochs_ = [epoch.copy().pick(roi) for epoch in epochs]\n",
    "# epochs = mne.concatenate_epochs(epochs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "70d0bdf1-f24f-48ee-ba2b-1f2b50be6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evokeds = [epochs[name].copy().crop(tmin=-0.1, tmax=0.6).iter_evoked() for name in ('error_response', 'correct_response')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "5e689efb-fff8-44e9-8995-f9ef8ba4f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.plot_compare_evokeds(\n",
    "#     [list(evokeds[0]),list(evokeds[1])],\n",
    "#     show=False,\n",
    "#     ci=True,\n",
    "# )\n",
    "\n",
    "# axes = fig[0].axes\n",
    "\n",
    "# axes[0].axhline(y=1, color='gray')\n",
    "# axes[0].axhline(y=6, color='gray')\n",
    "\n",
    "# # plt.axhline(y = 1*1e-6, color='gray', ls='--')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4703671a-3adc-4286-8bf2-eb3d9dbd70bc",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d0fd1-f37a-494c-b39f-ebb93f639a11",
   "metadata": {},
   "source": [
    "#### Extract EEG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "bc4a1ed2-674f-4926-98ad-70f1c79fd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeakToPeakBins(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, zero_index=2):\n",
    "        super().__init__()\n",
    "        self.zero_index = zero_index # how many bins before zero the signal started\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "                \n",
    "        peak_to_peaks = np.array(\n",
    "            [\n",
    "                np.array([[max(component[self.zero_index:-1]) - min(component[0:self.zero_index+1])] for component in participant])\n",
    "                for participant in X\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(f\"IN ERN min max RETURN SHAPE: {peak_to_peaks.shape}\")\n",
    "        return peak_to_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a86e297f-bef9-4319-9301-30398f152836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeakToPeakBinsFourComponent(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, zero_index=5):\n",
    "        super().__init__()\n",
    "        self.zero_index = zero_index # how many bins before zero the signal started\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        X_out = []\n",
    "        \n",
    "        for participant in X:\n",
    "            component_0 = participant[0]\n",
    "            component_1 = participant[1]\n",
    "            component_2 = participant[2]\n",
    "            component_3 = participant[3]\n",
    "            \n",
    "            component_0_ptp = np.array([max(component_0[1:self.zero_index+1]) - min(component_0[self.zero_index-1:-1])])\n",
    "            component_2_ptp = np.array([max(component_2[self.zero_index-1:-1]) - min(component_2[1:self.zero_index+1])])\n",
    "            \n",
    "            peak_to_peaks = np.array([component_0_ptp, component_2_ptp])\n",
    "            \n",
    "            X_out.append(peak_to_peaks)\n",
    "        \n",
    "        X_out = np.array(X_out)\n",
    "\n",
    "        print(f\"IN 4 COMP PTP RETURN SHAPE: {X_out.shape}\")\n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0dc11f-ab40-4c36-a825-415f4d17b0bd",
   "metadata": {},
   "source": [
    " 1. ICA (Fast ICA)\n",
    " \n",
    " - ROI\n",
    " - time window: -100 to 200 ms\n",
    " - ICA(n=4)\n",
    " - binning: 24ms (6 tp)\n",
    " - peak-to-peak amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "25e55768-649e-486d-a1aa-59d6b7c2863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints_count = 78\n",
    "spatial_filter_components = 4\n",
    "bin_width = 6\n",
    "# roi = [\"Fpz\", \"AFz\", \"F3\", \"F1\", \"Fz\", \"F2\", \"F4\", \"FC3\", \"FC1\", \"FCz\", \"FC2\", \"FC4\", \"C3\", \"C1\",\"Cz\", \"C2\", \"C4\",]\n",
    "roi = [\"F3\", \"F1\", \"Fz\", \"F2\", \"F4\", \"FC3\", \"FC1\", \"FCz\", \"FC2\", \"FC4\", \"C3\", \"C1\",\"Cz\", \"C2\", \"C4\", \"CP3\", \"CP1\", \"CPz\", \"CP2\", \"CP4\"] # to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "baf26c15-56b7-4827-805b-466b53798879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fd39b2c0-eee2-4b89-ac3c-5785d6fd786e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 20, 78)\n",
      "IN 4 COMP PTP RETURN SHAPE: (112, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "if test:\n",
    "    epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "    preprocessed_X_PCA_6bins = pipeline_ICA.transform(epochs_df_copy)\n",
    "    preprocessed_X_PCA_6bins = preprocessed_X_PCA_6bins.reshape(preprocessed_X_PCA_6bins.shape[0], -1)\n",
    "    \n",
    "else:\n",
    "    epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "    pipeline_ICA = Pipeline([\n",
    "        (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "        (\"trim\", EpochTrim(tmin=-0.1, tmax=0.20)),\n",
    "        (\"average\", Evoked()),\n",
    "        ('extract_averaged_data', ExtractData()),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\"spatial_filter\",FastICA(n_components=spatial_filter_components, random_state=random_state)),\n",
    "        (\"spatial_filter_postprocessing\",SpatialFilterPostprocessing(timepoints_count=timepoints_count)),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\"binning\", BinTransformer(step=6)),\n",
    "        # (\"centering\", CenteredSignalAfterBaseline_this2()),\n",
    "        # (\"ern_data_extraction\", ErnTransformer(stop_ern_bin=6)),\n",
    "        (\"peak-to-peak\", PeakToPeakBinsFourComponent(5)),\n",
    "    ]).fit(epochs_df_copy)\n",
    "\n",
    "    preprocessed_X_PCA_6bins = pipeline_ICA.transform(epochs_df_copy)\n",
    "\n",
    "    preprocessed_X_PCA_6bins = preprocessed_X_PCA_6bins.reshape(preprocessed_X_PCA_6bins.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c3d934e3-4520-4543-889f-bbcc3c066bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 2)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_PCA_6bins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9cc4c-083f-41a8-823e-b295966c91a4",
   "metadata": {},
   "source": [
    "2. ERN\n",
    "\n",
    "- ROI: Fz\n",
    "- time window: 0 - 100 ms\n",
    "- mean amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "772bab73-107f-4fb6-88fd-23c0818c23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = [\n",
    "    \"Fz\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "632787dc-ac9c-45f9-8a96-d4cf8946bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 1, 27)\n",
      "(112, 1, 27)\n"
     ]
    }
   ],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "ern_pipeline = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=0, tmax=0.1)),\n",
    "    (\"average\", Evoked()),\n",
    "    ('extract_averaged_data', ExtractData()),\n",
    "    (\"mean_amplitude\", AverageSignal()),\n",
    "    \n",
    "]).fit(epochs_df_copy)\n",
    "\n",
    "preprocessed_X_ern = ern_pipeline.transform(epochs_df_copy)\n",
    "preprocessed_X_ern = preprocessed_X_ern.reshape(preprocessed_X_ern.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ac9a858-21a4-4ec3-896d-f2dcc58aa24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_ern.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809644a-3897-4998-9dea-43400edfdcf4",
   "metadata": {},
   "source": [
    "3. CRN\n",
    "\n",
    "- ROI: Fz\n",
    "- time window: 0 - 100 ms\n",
    "- mean amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8fb9fd22-ce0b-47e3-8e3e-b9c0b9bee2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = [\n",
    "    \"Fz\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f107e50f-6552-4a38-87cc-f388ab629c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 1, 27)\n",
      "(112, 1, 27)\n"
     ]
    }
   ],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "crn_pipeline = Pipeline([\n",
    "   (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=0, tmax=0.1)),\n",
    "    (\"average\", Evoked(condition='correct_response')),\n",
    "    ('extract_averaged_data', ExtractData()),\n",
    "    (\"mean_amplitude\", AverageSignal()),\n",
    "    \n",
    "]).fit(epochs_df_copy)\n",
    "\n",
    "preprocessed_X_crn = crn_pipeline.transform(epochs_df_copy)\n",
    "preprocessed_X_crn = preprocessed_X_crn.reshape(preprocessed_X_crn.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8315dd8-afa1-4011-924b-c8309a106c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_crn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6536a-c06a-449e-9b47-00896ac1de3b",
   "metadata": {},
   "source": [
    "4. ERN lateralization of peak\n",
    "\n",
    "- ROI\n",
    "- time window: 0 - 100 ms\n",
    "- mean amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54cf0ba8-54b5-466b-b0d0-20a17e10eed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_channels_with_peaks(evoked, roi):\n",
    "    '''\n",
    "    todo\n",
    "    '''\n",
    "    data = evoked.get_data()\n",
    "    \n",
    "    ch_min = 'Fpz'\n",
    "    amp_min = 200\n",
    "    for channel_index, channel in enumerate(roi):\n",
    "        # plt.plot(np.arange(0, 27), data[channel_index])\n",
    "        if min(data[channel_index]) < amp_min:\n",
    "            amp_min = min(data[channel_index])\n",
    "            ch_min = channel\n",
    "    return ch_min, amp_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b81a8d9-9930-4718-82f5-7a88636d2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels_with_maximal_signal(evoked, roi):\n",
    "    '''\n",
    "    todo\n",
    "    '''\n",
    "    data = evoked.get_data()\n",
    "    \n",
    "    ch_min = 'Fpz'\n",
    "    amp_min = 200\n",
    "    for channel_index, channel in enumerate(roi):\n",
    "        # plt.plot(np.arange(0, 27), data[channel_index])\n",
    "        if (data[channel_index]).mean() < amp_min:\n",
    "            amp_min = data[channel_index].mean()\n",
    "            ch_min = channel\n",
    "    return ch_min, amp_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "feb34a13-6b20-41fa-aefc-1f4c4bf25d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define channels for maximal signal search\n",
    "roi = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"F3\", \"Fz\", \"F4\",\n",
    "    \"FC3\", \"FCz\", \"FC4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4c895184-0fe7-40a2-9578-555e4b23bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict())) # if use peak, signal must be filtered with strong (e.g. 10 Hz) lowpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8bbaa84b-b978-441a-8b07-bcfc753a61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = 0.0, 0.08\n",
    "channels_type_peak_ern = []\n",
    "channels_type_mean_ern = []\n",
    "\n",
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='error_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()\n",
    "\n",
    "######\n",
    "for subject in X:\n",
    "    ch, amp = get_channels_with_peaks(subject[0], roi)\n",
    "    ch_m, amp_m = get_channels_with_maximal_signal(subject[0], roi)\n",
    "    # print(f\"Channel {ch}\\n Amplitude {amp}\")\n",
    "    channels_type_peak_ern.append(ch)\n",
    "    channels_type_mean_ern.append(ch_m)\n",
    "    \n",
    "# change names of channels to: 0 = midline ; 1 = not midline (left or right)\n",
    "channels_type_peak_ern = list(map(lambda x: 0 if x[-1] == 'z' else 1, channels_type_peak_ern))\n",
    "channels_type_peak_ern = np.array(channels_type_peak_ern).reshape(len(channels_type_peak_ern), -1)    \n",
    "\n",
    "channels_type_mean_ern = list(map(lambda x: 0 if x[-1] == 'z' else 1, channels_type_mean_ern))\n",
    "channels_type_mean_ern = np.array(channels_type_mean_ern).reshape(len(channels_type_mean_ern), -1) \n",
    "\n",
    "channels_type_ern_peak = channels_type_peak_ern\n",
    "channels_type_ern_mean = channels_type_mean_ern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "31970637-5980-41c1-9750-500e87996393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_type_ern = channels_type_ern_mean\n",
    "channels_type_ern.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f4be3-b907-446a-9391-57b032fe7e36",
   "metadata": {},
   "source": [
    "5. CRN lateralization of peak\n",
    "\n",
    "- ROI\n",
    "- time window: 0 - 100 ms\n",
    "- mean amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "468b96fe-a702-403e-8972-f4750691591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"F3\", \"Fz\", \"F4\",\n",
    "    \"FC3\", \"FCz\", \"FC4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "744fb685-41ba-472c-a296-b41cc6319693",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "bfb9c417-41b4-48ba-97c1-33d7c3b0662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = 0.02, 0.08\n",
    "peaks_crn = []\n",
    "channels_type_peak_crn = []\n",
    "channels_type_mean_crn = []\n",
    "\n",
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='correct_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()\n",
    "\n",
    "######\n",
    "for subject in X:\n",
    "    ch, amp = get_channels_with_peaks(subject[0], roi)\n",
    "    ch_m, amp_m = get_channels_with_maximal_signal(subject[0], roi)\n",
    "    # print(f\"Channel {ch}\\n Amplitude {amp}\")\n",
    "    channels_type_peak_crn.append(ch)\n",
    "    channels_type_mean_crn.append(ch_m)\n",
    "\n",
    "# change names of channels to: 0 = midline ; 1 = not midline (left or right)\n",
    "channels_type_peak_crn = list(map(lambda x: 0 if x[-1] == 'z' else 1, channels_type_peak_crn))\n",
    "channels_type_peak_crn = np.array(channels_type_peak_crn).reshape(len(channels_type_peak_crn), -1) \n",
    "\n",
    "channels_type_mean_crn = list(map(lambda x: 0 if x[-1] == 'z' else 1, channels_type_mean_crn))\n",
    "channels_type_mean_crn = np.array(channels_type_mean_crn).reshape(len(channels_type_mean_crn), -1)   \n",
    "\n",
    "channels_type_crn_peak = channels_type_peak_crn\n",
    "channels_type_crn_mean = channels_type_mean_crn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "91374e91-675e-4033-b724-e48cc2ff8665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_type_crn = channels_type_crn_mean\n",
    "channels_type_crn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e0934-882f-4c13-bbba-5aed64e040bd",
   "metadata": {},
   "source": [
    "6. ERN latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c195d-efda-4d92-818f-2c9e1dd7743f",
   "metadata": {},
   "source": [
    "**1. Fractional area latency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d80e0bd2-5952-4cab-9b60-f5fcd1720a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractional_negative_area_latency(evoked, fraction=0.5, tmin=0.0, tmax=0.5, threshold = 0.0):\n",
    "    subject_data = evoked.get_data()\n",
    "    x = np.linspace(tmin, tmax, subject_data.shape[-1])\n",
    "    # print(x)\n",
    "    y = subject_data.flatten()\n",
    "    \n",
    "    # get only negative part of signal\n",
    "    y_negative = [abs(y_item) if y_item < threshold else 0 for y_item in y]\n",
    "    \n",
    "    # calculate area under the signal\n",
    "    area = abs(simpson(y_negative, x))\n",
    "    \n",
    "    if area != 0.0:\n",
    "        fractional_area = area * fraction\n",
    "    \n",
    "        # search for latency point (x) which split area according to fraction provided \n",
    "        current_area = 0\n",
    "        fractional_area_index = 0\n",
    "        i = 2\n",
    "        while abs(simpson(y_negative[:i], x[:i])) <= fractional_area:\n",
    "            current_area = abs(simpson(y_negative[:i], x[:i]))\n",
    "            fractional_area_index = i\n",
    "            i+=1\n",
    "            \n",
    "        # print(f'{fractional_area_index}; {x[fractional_area_index]}')\n",
    "        # print(x)\n",
    "        \n",
    "        return (fractional_area_index, x[fractional_area_index])    \n",
    "    else:\n",
    "        print('No area detected')\n",
    "        return (None, None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c08aa2-c473-4cf2-99ae-ae060aa71f78",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "af1a2ab3-e09a-4465-88ea-ee18f38c7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ['Fz']\n",
    "tmin = -0.05\n",
    "tmax = 0.2\n",
    "threshold = 1*1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f52e32-9503-4c1f-adfa-b58441b5d07e",
   "metadata": {},
   "source": [
    "Estimate fractional area latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e5f1b4e-ebd9-488f-9fb6-0a052bc2b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5b876351-bd1e-4312-8eda-57238b7d4e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='error_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1f3d05b-8df2-4a1a-9a30-2957a3031ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fractional_latencies = []\n",
    "for i in range(0, len(X)):        \n",
    "    subject = X[i][0]\n",
    "    evoked = subject\n",
    "    # print(f\"Index: {i}\")\n",
    "    this_latency = fractional_negative_area_latency(evoked, fraction=0.5, tmin=tmin, tmax=tmax, threshold=threshold)\n",
    "    fractional_latencies.append(this_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "83a6c738-7572-478a-ad64-16c95cb52076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractional_latencies_ern = list(map(lambda x: x[1] ,fractional_latencies))\n",
    "fractional_latencies_ern = np.array(fractional_latencies_ern).reshape(-1,1)\n",
    "fractional_latencies_ern.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383f2c19-7ba8-4405-bcdf-933f66877fea",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6b0ab452-339e-439b-a118-d235443c97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi = ['Fz']\n",
    "# tmin = -0.05\n",
    "# tmax = 0.2\n",
    "\n",
    "# epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "# X = Pipeline([\n",
    "#     (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "#     (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "#     (\"average\", Evoked(condition='error_response')),\n",
    "# ]).fit_transform(epochs_df_copy)\n",
    "\n",
    "# X = X[['evoked']].to_numpy()\n",
    "\n",
    "# for index in range(0, len(X)):\n",
    "#     plt.figure(index)\n",
    "    \n",
    "#     subject_data = X[index][0].get_data()\n",
    "#     x = np.linspace(tmin, tmax, subject_data.shape[-1])\n",
    "#     y = subject_data.flatten()\n",
    "#     # print(f\"Index: {i}\")\n",
    "    \n",
    "#     y_negative = [abs(y_item) if y_item < 0.1*1e-5 else 0 for y_item in y]\n",
    "#     # calculate area under the signal\n",
    "#     area = abs(simpson(y_negative,x))\n",
    "#     fractional_area = area * 0.5\n",
    "    \n",
    "#     if fractional_area != 0:\n",
    "#         # search for latency point (x) which split area according to fraction provided \n",
    "#         current_area = 0\n",
    "#         fractional_area_index = 0\n",
    "#         i = 2\n",
    "#         if area != 0.0:\n",
    "#             while abs(simpson(y_negative[:i], x[:i])) <= fractional_area:\n",
    "#                 current_area = abs(simpson(y_negative[:i], x[:i]))\n",
    "#                 fractional_area_index = i\n",
    "#                 i+=1\n",
    "\n",
    "#         plt.plot(x,y)\n",
    "#         plt.plot(x, y_negative)\n",
    "#         plt.axvline(x=x[fractional_area_index])\n",
    "#     else:\n",
    "#         fractional_area_index = 0\n",
    "#         plt.plot(x,y)\n",
    "#         plt.axvline(x=x[fractional_area_index], color='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184dcf8-edb9-48e1-b461-e76283f15156",
   "metadata": {},
   "source": [
    "**2. Peak Latency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7460d0e6-8643-432b-9897-b095a2c03832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_latency(evoked, tmin=0.0, tmax=0.5, ignore_peaks_before=0.0, favour_peaks_after = 0.0, ):\n",
    "    '''\n",
    "    Most negative peak\n",
    "    '''\n",
    "    subject_data = evoked.get_data()\n",
    "    x = np.linspace(tmin, tmax, subject_data.shape[-1]) * 100\n",
    "    y = subject_data.flatten()\n",
    "\n",
    "    y_spl = UnivariateSpline(x,y,s=0,k=4)\n",
    "    y_spl_1d = y_spl.derivative(n=1) # funkcja 1 pochodnej\n",
    "\n",
    "    x_range = np.linspace(x[0],x[-1],1000)\n",
    "\n",
    "    zeros = y_spl_1d.roots() # first derrivate zero -> peak\n",
    "\n",
    "    personal_peaks = []\n",
    "    lower_peak_x = 0\n",
    "    step  = 0.6\n",
    "\n",
    "    if len(zeros) > 0:\n",
    "        for zero in zeros:\n",
    "            if (zero > ignore_peaks_before*100):\n",
    "                lower_peak_x = zero \n",
    "                personal_peaks.append((lower_peak_x, y_spl(lower_peak_x)))\n",
    "\n",
    "        if len(personal_peaks) > 0:\n",
    "            min_index = np.argmin(personal_peaks, axis=0)[-1]\n",
    "            latency_value = personal_peaks[min_index][0]\n",
    "\n",
    "            while latency_value < favour_peaks_after and len(personal_peaks) > 1:\n",
    "                personal_peaks.pop(min_index)\n",
    "                min_index = np.argmin(personal_peaks, axis=0)[-1]\n",
    "                latency_value = personal_peaks[min_index][0]   \n",
    "        else:\n",
    "            latency_value = None \n",
    "    else:\n",
    "        latency_value = None\n",
    "        \n",
    "    return latency_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbccdf-ab21-4a7e-9710-be28ece8bef9",
   "metadata": {},
   "source": [
    "Lowpass data at 25 Hz for peak finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6fef9-12dc-4e28-91be-74a30bc72bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowpass = 25.0\n",
    "\n",
    "epochs_df_to_filter = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "epochs_filtered = Pipeline([\n",
    "    (\"lowpass\", BandpassFilter(h_freq=lowpass)),\n",
    "]).fit_transform(epochs_df_to_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca54bb-467d-4870-9c55-533981c769e2",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f7d70-c0f5-49d1-b336-63f141d40f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = -0.05 # window start time\n",
    "tmax = 0.12 # window stop time || peak search stop time\n",
    "ignore_peaks_before = -0.025 # peak serach start time\n",
    "roi = ['Fz']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f231885-903e-487b-b76d-aa26d8507106",
   "metadata": {},
   "source": [
    "Estimate peak latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "id": "ec3ee78c-cc2f-4de1-9218-f655bc485317",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "id": "94ff9848-267c-4b18-938a-3447c4ce621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='error_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "id": "730c35a3-fb74-4716-8cbf-1e5dfcc927bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_latencies = []\n",
    "for i in range(0, len(X)):        \n",
    "    subject = X[i][0]\n",
    "    evoked = subject\n",
    "    # print(f\"Index: {i}\")\n",
    "    this_latency = peak_latency(evoked, tmin=tmin, tmax=tmax, ignore_peaks_before=ignore_peaks_before, favour_peaks_after=0.0)\n",
    "    peak_latencies.append(this_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "c49a8d1b-f2cf-4a7e-8189-bc5efc8be242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1)"
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_latencies_ern = np.array(peak_latencies).reshape(-1,1)\n",
    "peak_latencies_ern.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09b4b7-cb20-4d39-a451-f2bca4b139b7",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "id": "22299859-a7b4-4ac3-b0a8-3828d5b55873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowpass = 20.0\n",
    "\n",
    "# epochs_df_to_filter = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "# epochs_filtered = Pipeline([\n",
    "#     (\"lowpass\", BandpassFilter(h_freq=lowpass)),\n",
    "# ]).fit_transform(epochs_df_to_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "id": "6494f1f4-bc46-4389-a7a7-3a3d1b74295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmin = -0.05 # window start time\n",
    "# tmax = 0.12 # window stop time || peak search stop time\n",
    "# ignore_peaks_before = -0.025 # peak serach start time\n",
    "\n",
    "# roi = ['Fz']\n",
    "\n",
    "# epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))\n",
    "\n",
    "# X = Pipeline([\n",
    "#     (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "#     (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "#     (\"average\", Evoked(condition='error_response')),\n",
    "# ]).fit_transform(epochs_df_copy)\n",
    "\n",
    "# X = X[['evoked']].to_numpy()\n",
    "\n",
    "# peaks = []\n",
    "# most_negative_peaks = []\n",
    "\n",
    "# for index in range(0, len(X)):\n",
    "#     plt.figure(index)\n",
    "    \n",
    "#     subject_data = X[index][0].get_data()\n",
    "    \n",
    "#     x = np.linspace(tmin, tmax, subject_data.shape[-1]) * 100\n",
    "#     y = subject_data.flatten()\n",
    "    \n",
    "#     y_spl = UnivariateSpline(x,y,s=0,k=4)\n",
    "#     y_spl_1d = y_spl.derivative(n=1) # funkcja 1 pochodnej\n",
    "\n",
    "#     x_range = np.linspace(x[0],x[-1],1000)\n",
    "    \n",
    "#     plt.plot(x_range,y_spl(x_range)) # funkcja\n",
    "#     plt.plot(x_range,y_spl_1d(x_range)) # 1 pochodna\n",
    "#     plt.axhline(y = 0.0, color='gray') # zero\n",
    "#     plt.axvline(x = 0.0, color='gray', ls='--') # zero\n",
    "#     plt.text(0,0,i)\n",
    "\n",
    "#     zeros = y_spl_1d.roots() # first derrivate zero -> peak\n",
    "\n",
    "#     plt.scatter(x=zeros, y=[0]*len(zeros))\n",
    "\n",
    "#     # define THIS peak\n",
    "    \n",
    "#     personal_peaks = []\n",
    "#     lower_peak_x = 0\n",
    "#     # max_lower_value = 2000\n",
    "#     step  = 0.6\n",
    "\n",
    "#     for zero in zeros:\n",
    "#         if (zero > ignore_peaks_before*100):\n",
    "#             lower_peak_x = zero \n",
    "#             personal_peaks.append((lower_peak_x, y_spl(lower_peak_x)))\n",
    "#         # max_lower_value = y_spl(zero) if y_spl(zero) < max_lower_value and (zero > ignore_peaks_before*100) else max_lower_value\n",
    "#     peaks.append(personal_peaks) \n",
    "#         # if y_spl(zero) < max_lower_value and zero > -2.5:\n",
    "#     for index_2, erns in enumerate(personal_peaks):\n",
    "#         x_ = erns[0]\n",
    "#         plt.scatter(x=x_, y=[0]*len([x_]), color='red')\n",
    "        \n",
    "#     peaks_ = peaks.copy()\n",
    "\n",
    "#     peak_latency = []\n",
    "#     for person in peaks_:\n",
    "#         min_index = np.argmin(person, axis=0)[-1]\n",
    "#         latency_value = person[min_index][0]\n",
    "\n",
    "#         while latency_value < 0 and len(person) > 1:\n",
    "#             person.pop(min_index)\n",
    "#             min_index = np.argmin(person, axis=0)[-1]\n",
    "#             latency_value = person[min_index][0]    \n",
    "#     plt.scatter(x=latency_value, y=[0]*len([latency_value]), color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "da2fa3b3-9f9a-4cc2-a1cd-d9c8341e7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks_ = peaks.copy()\n",
    "# peak_latency = []\n",
    "\n",
    "# for person in peaks_:\n",
    "#     min_index = np.argmin(person, axis=0)[-1]\n",
    "#     latency_value = person[min_index][0]\n",
    "\n",
    "#     while latency_value < 0 and len(person) > 1:\n",
    "#         person.pop(min_index)\n",
    "#         min_index = np.argmin(person, axis=0)[-1]\n",
    "#         latency_value = person[min_index][0]\n",
    "\n",
    "#     peak_latency.append(latency_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "f81fc892-8af5-4e9f-8e3e-0e1f882beda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(peak_latency).reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf9b19c-775a-4534-b204-38a417a20422",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452666fd-0fc3-4cf7-b6e1-afdb8f1f6dd9",
   "metadata": {},
   "source": [
    "CRN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcdc25c-dee9-4b6e-9eaa-809d07a2ca1e",
   "metadata": {},
   "source": [
    "**1. Fractional Area Latency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f2b64-1b66-4c43-8c07-d0b0556d97f4",
   "metadata": {},
   "source": [
    "Parameters: threshold at $2 \\mu V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b9f0b916-767b-4dee-8d15-f3d454bc268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ['Fz']\n",
    "tmin = -0.05\n",
    "tmax = 0.2\n",
    "threshold = 2*1e-6 # przy tym thresholdzie nie lapiemy wszystkich osob 1= 7 os; 2 = wszyscy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a6b29-28dd-4244-8ce4-eea2f724808a",
   "metadata": {},
   "source": [
    "Estimate fractional area latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "afa211f9-1fec-4009-aed7-a511ba36575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9808b290-0145-437f-860a-ed28d7582371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='correct_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "56e99ebf-31af-4b80-ba4f-90638af325b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No area detected\n"
     ]
    }
   ],
   "source": [
    "fractional_latencies = []\n",
    "for i in range(0, len(X)):        \n",
    "    subject = X[i][0]\n",
    "    evoked = subject\n",
    "    # print(f\"Index: {i}\")\n",
    "    this_latency = fractional_negative_area_latency(evoked, fraction=0.5, tmin=tmin, tmax=tmax, threshold=threshold)\n",
    "    fractional_latencies.append(this_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "11ebf18a-72d3-4826-8c9f-cd3034009ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractional_latencies_crn_2uV = list(map(lambda x: x[1] ,fractional_latencies))\n",
    "fractional_latencies_crn_2uV = np.array(fractional_latencies_crn_2uV).reshape(-1,1)\n",
    "fractional_latencies_crn_2uV.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b54f5e-3699-49a9-9a1c-ca9d5d0e149d",
   "metadata": {},
   "source": [
    "Parameters: threshold at $6 \\mu V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "id": "893d8d35-f4c5-4219-883d-9521bbfc025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ['Fz']\n",
    "tmin = -0.05\n",
    "tmax = 0.2\n",
    "threshold = 6*1e-6 # przy tym thresholdzie nie lapiemy wszystkich osob 1= 7 os; 2 = wszyscy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93538b7c-a49b-494c-865a-f806520d9f87",
   "metadata": {},
   "source": [
    "Estimate fractional area latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "id": "fe881865-1f05-40bd-9c84-45336cd5fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "id": "55765689-e220-4445-b50c-5d186843d304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='correct_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "id": "3ca1c170-84b0-412c-8a1c-bb360dc3bfc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fractional_latencies = []\n",
    "for i in range(0, len(X)):        \n",
    "    subject = X[i][0]\n",
    "    evoked = subject\n",
    "    # print(f\"Index: {i}\")\n",
    "    this_latency = fractional_negative_area_latency(evoked, fraction=0.5, tmin=tmin, tmax=tmax, threshold=threshold)\n",
    "    fractional_latencies.append(this_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "87ea5976-c7f0-4153-b869-459946928fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1)"
      ]
     },
     "execution_count": 1027,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractional_latencies_crn_6uV = list(map(lambda x: x[1] ,fractional_latencies))\n",
    "fractional_latencies_crn_6uV = np.array(fractional_latencies_crn_6uV).reshape(-1,1)\n",
    "fractional_latencies_crn_6uV.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d717da4c-cbf4-4b85-9f2c-37a311eb7ed0",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc3b6f-a668-4c28-aabd-f0f1e5b3674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi = ['Fz']\n",
    "# # tmin = -0.02\n",
    "# # tmax = 0.065\n",
    "# tmin = -0.05\n",
    "# tmax = 0.2\n",
    "# threshold = 2*1e-6\n",
    "# # threshold = 0\n",
    "\n",
    "# epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "# X = Pipeline([\n",
    "#     (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "#     (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "#     (\"average\", Evoked(condition='correct_response')),\n",
    "# ]).fit_transform(epochs_df_copy)\n",
    "\n",
    "# X = X[['evoked']].to_numpy()\n",
    "\n",
    "# for index in range(0, len(X)):\n",
    "#     plt.figure(index)\n",
    "    \n",
    "#     subject_data = X[index][0].get_data()\n",
    "#     x = np.linspace(tmin, tmax, subject_data.shape[-1])\n",
    "#     y = subject_data.flatten()\n",
    "#     # print(f\"Index: {i}\")\n",
    "    \n",
    "#     y_negative = [abs(y_item) if y_item < threshold else 0 for y_item in y]\n",
    "#     # calculate area under the signal\n",
    "#     area = abs(simpson(y_negative,x))\n",
    "#     fractional_area = area * 0.5\n",
    "    \n",
    "#     if fractional_area != 0:\n",
    "#         # search for latency point (x) which split area according to fraction provided \n",
    "#         current_area = 0\n",
    "#         fractional_area_index = 0\n",
    "#         i = 2\n",
    "#         if area != 0.0:\n",
    "#             while abs(simpson(y_negative[:i], x[:i])) <= fractional_area:\n",
    "#                 current_area = abs(simpson(y_negative[:i], x[:i]))\n",
    "#                 fractional_area_index = i\n",
    "#                 i+=1\n",
    "\n",
    "#         plt.plot(x,y)\n",
    "#         plt.plot(x, y_negative)\n",
    "#         plt.axvline(x=x[fractional_area_index])\n",
    "#     else:\n",
    "#         fractional_area_index = 0\n",
    "#         plt.plot(x,y)\n",
    "#         plt.axvline(x=x[fractional_area_index], color='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac1625b-8bbe-4a9e-be95-d8779aa0c94c",
   "metadata": {},
   "source": [
    "**2. Peak Latency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2634956-bd4e-45bf-ab48-fa551a963bfb",
   "metadata": {},
   "source": [
    "Lowpass data at 25 Hz for peak finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "id": "cceb9142-b7e8-4aee-8b98-3930f734dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowpass = 25.0\n",
    "\n",
    "epochs_df_to_filter = pd.DataFrame(copy.deepcopy(epochs_df.to_dict()))\n",
    "\n",
    "epochs_filtered = Pipeline([\n",
    "    (\"lowpass\", BandpassFilter(h_freq=lowpass)),\n",
    "]).fit_transform(epochs_df_to_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0259e8-36a9-4c94-a17e-1ac98a80baba",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "id": "c9d45d98-b038-4422-a768-ecd636b042f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = -0.05 # window start time\n",
    "tmax = 0.10 # window stop time || peak search stop time\n",
    "ignore_peaks_before = -0.025 # peak serach start time\n",
    "roi = ['Fz']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8ad00-e7a8-4e12-8a38-13033a0d7da4",
   "metadata": {},
   "source": [
    "Estimate peak latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "id": "a7129150-bc64-4c59-8eb7-6144765d0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "id": "f13e4625-f2eb-495a-a9f8-d7d49ed6c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Pipeline([\n",
    "    (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "    (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "    (\"average\", Evoked(condition='correct_response')),\n",
    "]).fit_transform(epochs_df_copy)\n",
    "\n",
    "X = X[['evoked']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "id": "1ca89d73-3540-49c8-82f5-877362e1729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_latencies = []\n",
    "for i in range(0, len(X)):        \n",
    "    subject = X[i][0]\n",
    "    evoked = subject\n",
    "    # print(f\"Index: {i}\")\n",
    "    this_latency = peak_latency(evoked, tmin=tmin, tmax=tmax, ignore_peaks_before=ignore_peaks_before, favour_peaks_after=-0.025)\n",
    "    peak_latencies.append(this_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "c87f11d8-bd0b-40b2-9b72-8398fdea8a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1)"
      ]
     },
     "execution_count": 1034,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_latencies_crn = np.array(peak_latencies).reshape(-1,1)\n",
    "peak_latencies_crn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc51c2-3985-4280-ad55-c84a7e7cde5b",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "id": "c93897a8-35ac-49b0-b265-6c9cad62fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmin = -0.05 # window start time\n",
    "# tmax = 0.10 # window stop time || peak search stop time\n",
    "# ignore_peaks_before = -0.025 # peak serach start time\n",
    "\n",
    "# roi = ['Fz']\n",
    "\n",
    "# epochs_df_copy = pd.DataFrame(copy.deepcopy(epochs_filtered.to_dict()))\n",
    "\n",
    "# X = Pipeline([\n",
    "#     (\"channels_extraction\",PickChannels(channels_list=roi)),\n",
    "#     (\"trim\", EpochTrim(tmin=tmin, tmax=tmax)),\n",
    "#     (\"average\", Evoked(condition='correct_response')),\n",
    "# ]).fit_transform(epochs_df_copy)\n",
    "\n",
    "# X = X[['evoked']].to_numpy()\n",
    "\n",
    "# peaks = []\n",
    "# most_negative_peaks = []\n",
    "\n",
    "# for index in range(0, len(X)):\n",
    "#     plt.figure(index)\n",
    "    \n",
    "#     subject_data = X[index][0].get_data()\n",
    "    \n",
    "#     x = np.linspace(tmin, tmax, subject_data.shape[-1]) * 100\n",
    "#     y = subject_data.flatten()\n",
    "    \n",
    "#     y_spl = UnivariateSpline(x,y,s=0,k=4)\n",
    "#     y_spl_1d = y_spl.derivative(n=1) # funkcja 1 pochodnej\n",
    "\n",
    "#     x_range = np.linspace(x[0],x[-1],1000)\n",
    "    \n",
    "#     plt.plot(x_range,y_spl(x_range)) # funkcja\n",
    "#     plt.plot(x_range,y_spl_1d(x_range)) # 1 pochodna\n",
    "#     plt.axhline(y = 0.0, color='gray') # zero\n",
    "#     plt.axvline(x = 0.0, color='gray', ls='--') # zero\n",
    "#     plt.text(0,0,index)\n",
    "\n",
    "#     zeros = y_spl_1d.roots() # first derrivate zero -> peak\n",
    "\n",
    "#     plt.scatter(x=zeros, y=[0]*len(zeros))\n",
    "\n",
    "#     # define THIS peak\n",
    "    \n",
    "#     personal_peaks = []\n",
    "#     lower_peak_x = 0\n",
    "#     # max_lower_value = 2000\n",
    "#     step  = 0.6\n",
    "    \n",
    "#     if len(zeros) != 0:\n",
    "\n",
    "#         for zero in zeros:\n",
    "#             if (zero > ignore_peaks_before*100):\n",
    "#                 lower_peak_x = zero \n",
    "#                 personal_peaks.append((lower_peak_x, y_spl(lower_peak_x)))\n",
    "#             # max_lower_value = y_spl(zero) if y_spl(zero) < max_lower_value and (zero > ignore_peaks_before*100) else max_lower_value\n",
    "\n",
    "#             # if y_spl(zero) < max_lower_value and zero > -2.5:\n",
    "#         for index_2, erns in enumerate(personal_peaks):\n",
    "#             x_ = erns[0]\n",
    "#             plt.scatter(x=x_, y=[0]*len([x_]), color='red')\n",
    "\n",
    "#         peaks_ = personal_peaks.copy()\n",
    "\n",
    "#         if len(peaks_) > 0:\n",
    "#             min_index = np.argmin(peaks_, axis=0)[-1]\n",
    "#             latency_value = peaks_[min_index][0]\n",
    "\n",
    "#             while latency_value < ignore_peaks_before*100 and len(peaks_) > 1:\n",
    "#                 peaks_.pop(min_index)\n",
    "#                 min_index = np.argmin(peaks_, axis=0)[-1]\n",
    "#                 latency_value = peaks_[min_index][0]    \n",
    "            \n",
    "#             plt.scatter(x=latency_value, y=[0]*len([latency_value]), color='purple')\n",
    "\n",
    "#         else:\n",
    "#             for zero in zeros:\n",
    "#                 plt.scatter(x=zero, y=[0]*len([zero]), color='green')\n",
    "#     else:\n",
    "#         plt.scatter(x=0, y=[0]*len([0]), color='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed840b5-1039-4f23-bdc3-426ce0034bda",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e6233-81b8-4f1f-8763-896f5f8beace",
   "metadata": {},
   "source": [
    "#### Extract anxiety-related questionnaires scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7ff716-45b0-45f7-a06d-65e42168d78b",
   "metadata": {},
   "source": [
    "Questionnaires to include in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef32f83c-fd82-4a88-abd3-5d43f14ce256",
   "metadata": {},
   "outputs": [],
   "source": [
    "rumination = \"RRQ\"\n",
    "dass_anxiety = \"DASS-21 Anx\"\n",
    "dass_stress = \"DASS-21 Stress\"\n",
    "dass_dep = \"DASS-21 Dep\"\n",
    "stai_t = \"STAI-T\" \n",
    "stai_s_diff = \"STAI-S Diff\" \n",
    "uninhibited_responses = \"uninhibited response\"\n",
    "inhibited_responses = \"inhibited response\"\n",
    "bis = \"BIS\"\n",
    "bas_dzialanie = \"BAS_D\"\n",
    "bas_przyjemnosc = \"BAS_PRZY\"\n",
    "bas_nagroda = \"BAS_NAG\"\n",
    "washing = \"WASH\"\n",
    "obsessing = \"OBSESS\"\n",
    "hoarding = \"HOARD\"\n",
    "ordering = \"ORD\"\n",
    "checking = \"CHECK\"\n",
    "neutralizing = \"NEU\"\n",
    "oci_r_full = \"OCI-R\"\n",
    "threat = \"OT\"\n",
    "thought_suppression = \"WBSI\"\n",
    "indecisivness = \"INDEC_F\"\n",
    "IU_prospecitve = \"IUS-P\"\n",
    "IU_inhibitory = \"IUS-I\"\n",
    "self_esteem = \"SES\"\n",
    "punishment_sensitivity = \"PUN\"\n",
    "reward_sensitivity = \"REW\"\n",
    "harm_responsibility = \"HARM\"\n",
    "thought_control = \"T-CTR\"\n",
    "perfectionism_IU = \"OB_PERF\"\n",
    "# perfectionism_cmda = \"17-Perfectionism CMDA\"\n",
    "perfectionism_ps = \"PS\"\n",
    "guilt_sensitivity = \"G_SE\"\n",
    "intolerance_ambiguity = \"AMB\"\n",
    "predictability = \"PRED\"\n",
    "high_standards = \"STAND\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6fb80bb5-46bd-4aba-b5d9-8402f97ea6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [\n",
    "    rumination,\n",
    "    # dass_anxiety,\n",
    "    dass_stress,\n",
    "    dass_dep,\n",
    "    stai_t,\n",
    "    stai_s_diff,\n",
    "    uninhibited_responses,\n",
    "    inhibited_responses,\n",
    "    bis,\n",
    "    bas_dzialanie,\n",
    "    bas_przyjemnosc,\n",
    "    bas_nagroda,\n",
    "    washing,\n",
    "    obsessing,\n",
    "    hoarding,\n",
    "    ordering,\n",
    "    checking,\n",
    "    neutralizing,\n",
    "    # oci_r_full,\n",
    "    threat,\n",
    "    thought_suppression,\n",
    "    indecisivness,\n",
    "    punishment_sensitivity,\n",
    "    reward_sensitivity,\n",
    "    harm_responsibility,\n",
    "    guilt_sensitivity,\n",
    "    thought_control,\n",
    "    perfectionism_IU,\n",
    "    # perfectionism_cmda,\n",
    "    perfectionism_ps,\n",
    "    intolerance_ambiguity,\n",
    "    predictability,\n",
    "    high_standards,\n",
    "    IU_prospecitve,\n",
    "    IU_inhibitory,\n",
    "    self_esteem,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "05652d55-e054-4c74-a22a-5bba52a28948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>uninhibited response</th>\n",
       "      <th>inhibited response</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>...</th>\n",
       "      <th>G_SE</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.250000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>2.35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.63</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.90</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.95</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.25</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.416667</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.63</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>4.250000</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>3.05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.75</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3.14</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3.250000</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>6.330000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.920000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>3.920000</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RRQ  DASS-21 Stress  DASS-21 Dep  STAI-T  STAI-S Diff  \\\n",
       "0    4.250000        1.714286     1.428571    2.35          8.0   \n",
       "1    2.500000        1.714286     2.142857    2.00          9.0   \n",
       "2    4.166667        2.285714     3.142857    2.90         14.0   \n",
       "3    2.250000        2.428571     1.857143    1.95          6.0   \n",
       "4    2.416667        1.857143     1.142857    1.75         -1.0   \n",
       "..        ...             ...          ...     ...          ...   \n",
       "107  4.250000        2.710000     2.570000    3.05         -1.0   \n",
       "108  2.500000        3.000000     2.140000    2.55          2.0   \n",
       "109  3.250000        2.430000     1.710000    2.50         -2.0   \n",
       "110  1.920000        2.140000     1.710000    1.65          0.0   \n",
       "111  3.920000        2.430000     1.290000    2.50          4.0   \n",
       "\n",
       "     uninhibited response  inhibited response   BIS  BAS_D  BAS_PRZY  ...  \\\n",
       "0                    28.0                84.0  3.40   4.00      3.00  ...   \n",
       "1                    45.0                67.0  3.10   1.75      2.50  ...   \n",
       "2                    17.0                95.0  3.10   2.00      3.00  ...   \n",
       "3                    31.0                81.0  2.70   3.00      2.50  ...   \n",
       "4                    11.0               101.0  3.00   2.50      2.50  ...   \n",
       "..                    ...                 ...   ...    ...       ...  ...   \n",
       "107                  10.0               102.0  4.00   3.50      2.25  ...   \n",
       "108                  26.0                86.0  3.14   1.50      1.50  ...   \n",
       "109                  22.0                90.0  2.71   3.00      2.75  ...   \n",
       "110                  29.0                83.0  2.71   1.75      2.50  ...   \n",
       "111                  14.0                98.0  2.71   1.75      3.50  ...   \n",
       "\n",
       "     G_SE  T-CTR  OB_PERF        PS   AMB  PRED     STAND     IUS-P  IUS-I  \\\n",
       "0     3.9    3.2      5.2  3.285714  4.00  4.63  5.333333  3.428571    2.0   \n",
       "1     2.4    3.4      3.4  1.571429  4.50  3.63  2.666667  2.857143    2.0   \n",
       "2     4.0    3.0      4.0  2.714286  4.50  4.00  3.666667  3.000000    3.2   \n",
       "3     2.9    3.4      2.2  4.285714  3.67  2.25  6.000000  3.571429    1.8   \n",
       "4     2.5    1.0      2.0  3.142857  4.00  2.63  5.333333  2.571429    1.2   \n",
       "..    ...    ...      ...       ...   ...   ...       ...       ...    ...   \n",
       "107   4.2    4.6      5.2  3.570000  4.83  2.75  4.670000  2.860000    4.2   \n",
       "108   3.9    2.0      4.6  2.710000  4.00  3.25  3.330000  3.710000    2.6   \n",
       "109   3.1    3.6      3.8  4.000000  3.50  3.25  6.330000  3.000000    3.0   \n",
       "110   3.2    2.2      2.4  2.290000  3.17  3.63  3.670000  2.710000    1.4   \n",
       "111   2.9    3.0      2.6  2.000000  4.17  3.63  3.670000  2.860000    2.6   \n",
       "\n",
       "     SES  \n",
       "0    3.0  \n",
       "1    2.5  \n",
       "2    1.6  \n",
       "3    3.4  \n",
       "4    3.5  \n",
       "..   ...  \n",
       "107  2.4  \n",
       "108  2.2  \n",
       "109  3.6  \n",
       "110  3.4  \n",
       "111  3.3  \n",
       "\n",
       "[112 rows x 33 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionnaires_scores_df = epochs_df[scales]\n",
    "questionnaires_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3ec4b-64b2-40c1-993b-7bef3cd303b6",
   "metadata": {},
   "source": [
    "Fill missing value from external file - TODO to automatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e3c7dfc9-86e7-4800-b84b-26714905a96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>uninhibited response</th>\n",
       "      <th>inhibited response</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>...</th>\n",
       "      <th>G_SE</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>4.08</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.57</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.71</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RRQ  DASS-21 Stress  DASS-21 Dep  STAI-T  STAI-S Diff  \\\n",
       "102  4.08            2.43          2.0     2.4         -2.0   \n",
       "\n",
       "     uninhibited response  inhibited response   BIS  BAS_D  BAS_PRZY  ...  \\\n",
       "102                   NaN                 NaN  3.57   2.75      3.25  ...   \n",
       "\n",
       "     G_SE  T-CTR  OB_PERF    PS  AMB  PRED  STAND  IUS-P  IUS-I  SES  \n",
       "102   4.1    2.8      2.8  1.71  4.5  4.63    4.0    4.0    3.8  3.7  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionnaires_scores_df[questionnaires_scores_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "838e685f-3b39-497b-aec3-740c4a038091",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    questionnaires_scores_df.at[102, 'uninhibited response'] = 14.0\n",
    "    questionnaires_scores_df.at[102, 'inhibited response'] = 98.0\n",
    "else:\n",
    "    print('None to fill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e6cd794d-1bf0-4651-9b93-617cacb9ab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>uninhibited response</th>\n",
       "      <th>inhibited response</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>...</th>\n",
       "      <th>G_SE</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RRQ, DASS-21 Stress, DASS-21 Dep, STAI-T, STAI-S Diff, uninhibited response, inhibited response, BIS, BAS_D, BAS_PRZY, BAS_NAG, WASH, OBSESS, HOARD, ORD, CHECK, NEU, OT, WBSI, INDEC_F, PUN, REW, HARM, G_SE, T-CTR, OB_PERF, PS, AMB, PRED, STAND, IUS-P, IUS-I, SES]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionnaires_scores_df[questionnaires_scores_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623ec8b-725a-4067-898a-2017058e90aa",
   "metadata": {},
   "source": [
    "Create performance metric based on inhibited and uninhibited responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6ea34c0d-14ca-457e-9983-86e1e7542b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaires_scores_df['performance'] = questionnaires_scores_df['inhibited response'] / questionnaires_scores_df['uninhibited response']\n",
    "questionnaires_scores_df = questionnaires_scores_df.drop(columns=['inhibited response', 'uninhibited response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ba3c1-4846-4156-8b71-f92f0ae7815a",
   "metadata": {},
   "source": [
    "Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ee36f5e-20eb-47ea-ac01-442a7405d459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>BAS_NAG</th>\n",
       "      <th>WASH</th>\n",
       "      <th>...</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RRQ, DASS-21 Stress, DASS-21 Dep, STAI-T, STAI-S Diff, BIS, BAS_D, BAS_PRZY, BAS_NAG, WASH, OBSESS, HOARD, ORD, CHECK, NEU, OT, WBSI, INDEC_F, PUN, REW, HARM, G_SE, T-CTR, OB_PERF, PS, AMB, PRED, STAND, IUS-P, IUS-I, SES, performance]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionnaires_scores_df[questionnaires_scores_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0da1a613-7dc1-4247-85ff-92df4e0d082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>BAS_NAG</th>\n",
       "      <th>WASH</th>\n",
       "      <th>OBSESS</th>\n",
       "      <th>HOARD</th>\n",
       "      <th>ORD</th>\n",
       "      <th>CHECK</th>\n",
       "      <th>NEU</th>\n",
       "      <th>OT</th>\n",
       "      <th>WBSI</th>\n",
       "      <th>INDEC_F</th>\n",
       "      <th>PUN</th>\n",
       "      <th>REW</th>\n",
       "      <th>HARM</th>\n",
       "      <th>G_SE</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.542411</td>\n",
       "      <td>2.208202</td>\n",
       "      <td>1.855612</td>\n",
       "      <td>2.237054</td>\n",
       "      <td>4.053571</td>\n",
       "      <td>3.003661</td>\n",
       "      <td>2.455357</td>\n",
       "      <td>2.774554</td>\n",
       "      <td>3.226786</td>\n",
       "      <td>1.672262</td>\n",
       "      <td>2.422381</td>\n",
       "      <td>2.056518</td>\n",
       "      <td>2.461458</td>\n",
       "      <td>2.577530</td>\n",
       "      <td>1.487738</td>\n",
       "      <td>2.808929</td>\n",
       "      <td>3.488899</td>\n",
       "      <td>3.091845</td>\n",
       "      <td>5.946429</td>\n",
       "      <td>4.464286</td>\n",
       "      <td>3.996429</td>\n",
       "      <td>3.068750</td>\n",
       "      <td>2.412500</td>\n",
       "      <td>3.373214</td>\n",
       "      <td>3.137806</td>\n",
       "      <td>4.148839</td>\n",
       "      <td>3.607232</td>\n",
       "      <td>4.517798</td>\n",
       "      <td>3.211684</td>\n",
       "      <td>2.405357</td>\n",
       "      <td>2.846429</td>\n",
       "      <td>3.893995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.895835</td>\n",
       "      <td>0.649908</td>\n",
       "      <td>0.654062</td>\n",
       "      <td>0.458343</td>\n",
       "      <td>6.726095</td>\n",
       "      <td>0.551110</td>\n",
       "      <td>0.630685</td>\n",
       "      <td>0.559480</td>\n",
       "      <td>0.426590</td>\n",
       "      <td>0.754135</td>\n",
       "      <td>0.987241</td>\n",
       "      <td>0.898047</td>\n",
       "      <td>1.137774</td>\n",
       "      <td>1.066730</td>\n",
       "      <td>0.716969</td>\n",
       "      <td>1.165383</td>\n",
       "      <td>0.776863</td>\n",
       "      <td>0.773604</td>\n",
       "      <td>3.704974</td>\n",
       "      <td>1.990647</td>\n",
       "      <td>1.001614</td>\n",
       "      <td>0.743746</td>\n",
       "      <td>1.002081</td>\n",
       "      <td>1.275831</td>\n",
       "      <td>0.876994</td>\n",
       "      <td>0.798313</td>\n",
       "      <td>0.822479</td>\n",
       "      <td>1.115602</td>\n",
       "      <td>0.706690</td>\n",
       "      <td>0.913348</td>\n",
       "      <td>0.629304</td>\n",
       "      <td>3.074056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.097500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.475000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.831667</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>3.131667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.250000</td>\n",
       "      <td>2.606071</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.512500</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>3.050000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>4.032500</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>4.976608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.920000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.630000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              RRQ  DASS-21 Stress  DASS-21 Dep      STAI-T  STAI-S Diff  \\\n",
       "count  112.000000      112.000000   112.000000  112.000000   112.000000   \n",
       "mean     3.542411        2.208202     1.855612    2.237054     4.053571   \n",
       "std      0.895835        0.649908     0.654062    0.458343     6.726095   \n",
       "min      1.083333        1.000000     1.000000    1.300000   -11.000000   \n",
       "25%      2.833333        1.714286     1.290000    1.900000    -0.250000   \n",
       "50%      3.831667        2.214286     1.714286    2.200000     3.000000   \n",
       "75%      4.250000        2.606071     2.142857    2.512500     8.000000   \n",
       "max      4.920000        4.000000     3.714286    3.450000    30.000000   \n",
       "\n",
       "              BIS       BAS_D    BAS_PRZY     BAS_NAG        WASH      OBSESS  \\\n",
       "count  112.000000  112.000000  112.000000  112.000000  112.000000  112.000000   \n",
       "mean     3.003661    2.455357    2.774554    3.226786    1.672262    2.422381   \n",
       "std      0.551110    0.630685    0.559480    0.426590    0.754135    0.987241   \n",
       "min      1.290000    1.000000    1.250000    1.800000    1.000000    1.000000   \n",
       "25%      2.600000    2.000000    2.500000    3.000000    1.000000    1.666667   \n",
       "50%      3.000000    2.500000    2.750000    3.200000    1.333333    2.330000   \n",
       "75%      3.430000    2.750000    3.000000    3.600000    2.000000    3.000000   \n",
       "max      4.000000    4.000000    4.000000    4.000000    4.670000    5.000000   \n",
       "\n",
       "            HOARD         ORD       CHECK         NEU          OT        WBSI  \\\n",
       "count  112.000000  112.000000  112.000000  112.000000  112.000000  112.000000   \n",
       "mean     2.056518    2.461458    2.577530    1.487738    2.808929    3.488899   \n",
       "std      0.898047    1.137774    1.066730    0.716969    1.165383    0.776863   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.330000   \n",
       "25%      1.330000    1.583333    1.670000    1.000000    2.000000    3.000000   \n",
       "50%      2.000000    2.330000    2.333333    1.330000    2.800000    3.533333   \n",
       "75%      2.666667    3.333333    3.333333    1.670000    3.400000    4.000000   \n",
       "max      4.670000    5.000000    5.000000    5.000000    5.800000    5.000000   \n",
       "\n",
       "          INDEC_F         PUN         REW        HARM        G_SE       T-CTR  \\\n",
       "count  112.000000  112.000000  112.000000  112.000000  112.000000  112.000000   \n",
       "mean     3.091845    5.946429    4.464286    3.996429    3.068750    2.412500   \n",
       "std      0.773604    3.704974    1.990647    1.001614    0.743746    1.002081   \n",
       "min      1.270000    0.000000    0.000000    2.000000    1.200000    1.000000   \n",
       "25%      2.533333    3.000000    3.000000    3.400000    2.600000    1.600000   \n",
       "50%      3.131667    6.000000    5.000000    3.800000    3.100000    2.200000   \n",
       "75%      3.616667    9.000000    6.000000    4.600000    3.625000    3.050000   \n",
       "max      4.733333   13.000000    8.000000    6.800000    4.500000    5.200000   \n",
       "\n",
       "          OB_PERF          PS         AMB        PRED       STAND       IUS-P  \\\n",
       "count  112.000000  112.000000  112.000000  112.000000  112.000000  112.000000   \n",
       "mean     3.373214    3.137806    4.148839    3.607232    4.517798    3.211684   \n",
       "std      1.275831    0.876994    0.798313    0.822479    1.115602    0.706690   \n",
       "min      1.000000    1.285714    2.500000    1.880000    2.000000    1.285714   \n",
       "25%      2.400000    2.430000    3.670000    3.097500    4.000000    2.714286   \n",
       "50%      3.400000    3.285714    4.000000    3.500000    4.666667    3.142857   \n",
       "75%      4.200000    3.714286    4.670000    4.032500    5.330000    3.571429   \n",
       "max      6.600000    4.860000    6.000000    5.630000    7.000000    5.000000   \n",
       "\n",
       "            IUS-I         SES  performance  \n",
       "count  112.000000  112.000000   112.000000  \n",
       "mean     2.405357    2.846429     3.893995  \n",
       "std      0.913348    0.629304     3.074056  \n",
       "min      1.000000    1.400000     0.365854  \n",
       "25%      1.800000    2.475000     1.800000  \n",
       "50%      2.400000    2.900000     2.862069  \n",
       "75%      3.000000    3.300000     4.976608  \n",
       "max      5.000000    4.000000    15.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None, 'display.max_columns', None):\n",
    "    display(questionnaires_scores_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c58ee5f-ad0f-4149-bb3d-888cc2f2d357",
   "metadata": {},
   "source": [
    "Check skewness and kurtiosis\n",
    "\n",
    "As a general rule of thumb: If skewness is less than -1 or greater than 1, the distribution is highly skewed. If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed. If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n",
    "\n",
    "Analogous to the skewness, the general guideline is that if the kurtosis is greater than +2, the distribution is too peaked. Likewise, a kurtosis of less than −2 indicates a distribution that is too flat. When both skewness and kurtosis are close to zero, the pattern of responses is considered a normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b053c7b3-cdde-4bd2-bd4a-832aba90247c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RRQ</th>\n",
       "      <td>-0.476740</td>\n",
       "      <td>-0.799871</td>\n",
       "      <td>3.542411</td>\n",
       "      <td>0.895835</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>4.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <td>0.214291</td>\n",
       "      <td>-0.458841</td>\n",
       "      <td>2.208202</td>\n",
       "      <td>0.649908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <td>0.928685</td>\n",
       "      <td>0.361288</td>\n",
       "      <td>1.855612</td>\n",
       "      <td>0.654062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAI-T</th>\n",
       "      <td>0.254574</td>\n",
       "      <td>-0.406814</td>\n",
       "      <td>2.237054</td>\n",
       "      <td>0.458343</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>3.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <td>0.990347</td>\n",
       "      <td>1.493530</td>\n",
       "      <td>4.053571</td>\n",
       "      <td>6.726095</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS</th>\n",
       "      <td>-0.325488</td>\n",
       "      <td>-0.040535</td>\n",
       "      <td>3.003661</td>\n",
       "      <td>0.551110</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_D</th>\n",
       "      <td>0.064607</td>\n",
       "      <td>-0.345385</td>\n",
       "      <td>2.455357</td>\n",
       "      <td>0.630685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <td>-0.071123</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>2.774554</td>\n",
       "      <td>0.559480</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_NAG</th>\n",
       "      <td>-0.262946</td>\n",
       "      <td>0.418897</td>\n",
       "      <td>3.226786</td>\n",
       "      <td>0.426590</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WASH</th>\n",
       "      <td>1.562366</td>\n",
       "      <td>3.159867</td>\n",
       "      <td>1.672262</td>\n",
       "      <td>0.754135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBSESS</th>\n",
       "      <td>0.676671</td>\n",
       "      <td>-0.257087</td>\n",
       "      <td>2.422381</td>\n",
       "      <td>0.987241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOARD</th>\n",
       "      <td>0.671578</td>\n",
       "      <td>-0.122653</td>\n",
       "      <td>2.056518</td>\n",
       "      <td>0.898047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORD</th>\n",
       "      <td>0.559241</td>\n",
       "      <td>-0.583565</td>\n",
       "      <td>2.461458</td>\n",
       "      <td>1.137774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHECK</th>\n",
       "      <td>0.572379</td>\n",
       "      <td>-0.470027</td>\n",
       "      <td>2.577530</td>\n",
       "      <td>1.066730</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU</th>\n",
       "      <td>2.092391</td>\n",
       "      <td>5.553988</td>\n",
       "      <td>1.487738</td>\n",
       "      <td>0.716969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OT</th>\n",
       "      <td>0.286173</td>\n",
       "      <td>-0.619961</td>\n",
       "      <td>2.808929</td>\n",
       "      <td>1.165383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBSI</th>\n",
       "      <td>-0.499615</td>\n",
       "      <td>0.108198</td>\n",
       "      <td>3.488899</td>\n",
       "      <td>0.776863</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEC_F</th>\n",
       "      <td>-0.079163</td>\n",
       "      <td>-0.568319</td>\n",
       "      <td>3.091845</td>\n",
       "      <td>0.773604</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>4.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUN</th>\n",
       "      <td>0.211907</td>\n",
       "      <td>-0.981469</td>\n",
       "      <td>5.946429</td>\n",
       "      <td>3.704974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REW</th>\n",
       "      <td>-0.190551</td>\n",
       "      <td>-0.610675</td>\n",
       "      <td>4.464286</td>\n",
       "      <td>1.990647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HARM</th>\n",
       "      <td>0.533920</td>\n",
       "      <td>-0.006686</td>\n",
       "      <td>3.996429</td>\n",
       "      <td>1.001614</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_SE</th>\n",
       "      <td>-0.290144</td>\n",
       "      <td>-0.457931</td>\n",
       "      <td>3.068750</td>\n",
       "      <td>0.743746</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-CTR</th>\n",
       "      <td>0.560984</td>\n",
       "      <td>-0.082408</td>\n",
       "      <td>2.412500</td>\n",
       "      <td>1.002081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OB_PERF</th>\n",
       "      <td>0.238732</td>\n",
       "      <td>-0.523657</td>\n",
       "      <td>3.373214</td>\n",
       "      <td>1.275831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PS</th>\n",
       "      <td>-0.038523</td>\n",
       "      <td>-0.755104</td>\n",
       "      <td>3.137806</td>\n",
       "      <td>0.876994</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>4.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMB</th>\n",
       "      <td>0.345783</td>\n",
       "      <td>-0.308675</td>\n",
       "      <td>4.148839</td>\n",
       "      <td>0.798313</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRED</th>\n",
       "      <td>0.290743</td>\n",
       "      <td>-0.237326</td>\n",
       "      <td>3.607232</td>\n",
       "      <td>0.822479</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>5.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAND</th>\n",
       "      <td>-0.183202</td>\n",
       "      <td>-0.233935</td>\n",
       "      <td>4.517798</td>\n",
       "      <td>1.115602</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IUS-P</th>\n",
       "      <td>0.094507</td>\n",
       "      <td>0.392694</td>\n",
       "      <td>3.211684</td>\n",
       "      <td>0.706690</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IUS-I</th>\n",
       "      <td>0.463743</td>\n",
       "      <td>-0.122766</td>\n",
       "      <td>2.405357</td>\n",
       "      <td>0.913348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SES</th>\n",
       "      <td>-0.025765</td>\n",
       "      <td>-0.452866</td>\n",
       "      <td>2.846429</td>\n",
       "      <td>0.629304</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance</th>\n",
       "      <td>1.551817</td>\n",
       "      <td>2.113061</td>\n",
       "      <td>3.893995</td>\n",
       "      <td>3.074056</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    skew  kurtosis      mean       std        min        max\n",
       "RRQ            -0.476740 -0.799871  3.542411  0.895835   1.083333   4.920000\n",
       "DASS-21 Stress  0.214291 -0.458841  2.208202  0.649908   1.000000   4.000000\n",
       "DASS-21 Dep     0.928685  0.361288  1.855612  0.654062   1.000000   3.714286\n",
       "STAI-T          0.254574 -0.406814  2.237054  0.458343   1.300000   3.450000\n",
       "STAI-S Diff     0.990347  1.493530  4.053571  6.726095 -11.000000  30.000000\n",
       "BIS            -0.325488 -0.040535  3.003661  0.551110   1.290000   4.000000\n",
       "BAS_D           0.064607 -0.345385  2.455357  0.630685   1.000000   4.000000\n",
       "BAS_PRZY       -0.071123 -0.000214  2.774554  0.559480   1.250000   4.000000\n",
       "BAS_NAG        -0.262946  0.418897  3.226786  0.426590   1.800000   4.000000\n",
       "WASH            1.562366  3.159867  1.672262  0.754135   1.000000   4.670000\n",
       "OBSESS          0.676671 -0.257087  2.422381  0.987241   1.000000   5.000000\n",
       "HOARD           0.671578 -0.122653  2.056518  0.898047   1.000000   4.670000\n",
       "ORD             0.559241 -0.583565  2.461458  1.137774   1.000000   5.000000\n",
       "CHECK           0.572379 -0.470027  2.577530  1.066730   1.000000   5.000000\n",
       "NEU             2.092391  5.553988  1.487738  0.716969   1.000000   5.000000\n",
       "OT              0.286173 -0.619961  2.808929  1.165383   1.000000   5.800000\n",
       "WBSI           -0.499615  0.108198  3.488899  0.776863   1.330000   5.000000\n",
       "INDEC_F        -0.079163 -0.568319  3.091845  0.773604   1.270000   4.733333\n",
       "PUN             0.211907 -0.981469  5.946429  3.704974   0.000000  13.000000\n",
       "REW            -0.190551 -0.610675  4.464286  1.990647   0.000000   8.000000\n",
       "HARM            0.533920 -0.006686  3.996429  1.001614   2.000000   6.800000\n",
       "G_SE           -0.290144 -0.457931  3.068750  0.743746   1.200000   4.500000\n",
       "T-CTR           0.560984 -0.082408  2.412500  1.002081   1.000000   5.200000\n",
       "OB_PERF         0.238732 -0.523657  3.373214  1.275831   1.000000   6.600000\n",
       "PS             -0.038523 -0.755104  3.137806  0.876994   1.285714   4.860000\n",
       "AMB             0.345783 -0.308675  4.148839  0.798313   2.500000   6.000000\n",
       "PRED            0.290743 -0.237326  3.607232  0.822479   1.880000   5.630000\n",
       "STAND          -0.183202 -0.233935  4.517798  1.115602   2.000000   7.000000\n",
       "IUS-P           0.094507  0.392694  3.211684  0.706690   1.285714   5.000000\n",
       "IUS-I           0.463743 -0.122766  2.405357  0.913348   1.000000   5.000000\n",
       "SES            -0.025765 -0.452866  2.846429  0.629304   1.400000   4.000000\n",
       "performance     1.551817  2.113061  3.893995  3.074056   0.365854  15.000000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = questionnaires_scores_df.agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec5df3-a3d5-4428-861c-d9b29c70729b",
   "metadata": {},
   "source": [
    "Transform entries with high skewness and kurtosis with BoxCox method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "85a07bab-4d38-45ec-875f-0238d5c7b825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming: WASH scale\n",
      "   Stats before transformation:\n",
      "    Skewness: 1.5413628603389684 \n",
      "    Kurtosis: 2.9674566003084673\n",
      "   Stats after transformation:\n",
      "    Skewness: -0.25338118848472924 \n",
      "    Kurtosis: -1.41609490504058\n",
      "Transforming: NEU scale\n",
      "   Stats before transformation:\n",
      "    Skewness: 2.0642627404563108 \n",
      "    Kurtosis: 5.256024486294313\n",
      "   Stats after transformation:\n",
      "    Skewness: 0.08311082609199352 \n",
      "    Kurtosis: -1.8411140597757605\n",
      "Transforming: performance scale\n",
      "   Stats before transformation:\n",
      "    Skewness: 1.5309559055773823 \n",
      "    Kurtosis: 1.9668026810831947\n",
      "   Stats after transformation:\n",
      "    Skewness: 0.039061326772987154 \n",
      "    Kurtosis: 0.1999562476342307\n"
     ]
    }
   ],
   "source": [
    "questionnaires_scores_df_transformed = questionnaires_scores_df.copy()\n",
    "\n",
    "for row in summary.iterrows():\n",
    "    item_name = row[0]\n",
    "    skewness_ = row[1]['skew']\n",
    "    kurtosis_ = row[1]['kurtosis']\n",
    "    \n",
    "    if abs(skewness_) > 1 or abs(kurtosis_) > 2:\n",
    "        print(f'Transforming: {item_name} scale')\n",
    "        this_scores = questionnaires_scores_df_transformed[[item_name]].to_numpy().flatten()\n",
    "        this_scores = this_scores - np.min(this_scores) + 0.01\n",
    "        this_scores_transformed, lambda_ = boxcox(this_scores)\n",
    "        print(f'   Stats before transformation:\\n    Skewness: {scipy.stats.skew(this_scores)} \\n    Kurtosis: {scipy.stats.kurtosis(this_scores)}')\n",
    "        print(f'   Stats after transformation:\\n    Skewness: {scipy.stats.skew(this_scores_transformed)} \\n    Kurtosis: {scipy.stats.kurtosis(this_scores_transformed)}')\n",
    "        \n",
    "        questionnaires_scores_df_transformed[[item_name]] = this_scores_transformed.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c9ca294a-0514-4a54-a57a-76aa6859a8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RRQ</th>\n",
       "      <td>-0.476740</td>\n",
       "      <td>-0.799871</td>\n",
       "      <td>3.542411</td>\n",
       "      <td>0.895835</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>4.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <td>0.214291</td>\n",
       "      <td>-0.458841</td>\n",
       "      <td>2.208202</td>\n",
       "      <td>0.649908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <td>0.928685</td>\n",
       "      <td>0.361288</td>\n",
       "      <td>1.855612</td>\n",
       "      <td>0.654062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAI-T</th>\n",
       "      <td>0.254574</td>\n",
       "      <td>-0.406814</td>\n",
       "      <td>2.237054</td>\n",
       "      <td>0.458343</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>3.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <td>0.990347</td>\n",
       "      <td>1.493530</td>\n",
       "      <td>4.053571</td>\n",
       "      <td>6.726095</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS</th>\n",
       "      <td>-0.325488</td>\n",
       "      <td>-0.040535</td>\n",
       "      <td>3.003661</td>\n",
       "      <td>0.551110</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_D</th>\n",
       "      <td>0.064607</td>\n",
       "      <td>-0.345385</td>\n",
       "      <td>2.455357</td>\n",
       "      <td>0.630685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <td>-0.071123</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>2.774554</td>\n",
       "      <td>0.559480</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS_NAG</th>\n",
       "      <td>-0.262946</td>\n",
       "      <td>0.418897</td>\n",
       "      <td>3.226786</td>\n",
       "      <td>0.426590</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WASH</th>\n",
       "      <td>-0.256834</td>\n",
       "      <td>-1.425861</td>\n",
       "      <td>-1.074865</td>\n",
       "      <td>1.415516</td>\n",
       "      <td>-2.903676</td>\n",
       "      <td>1.507260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBSESS</th>\n",
       "      <td>0.676671</td>\n",
       "      <td>-0.257087</td>\n",
       "      <td>2.422381</td>\n",
       "      <td>0.987241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOARD</th>\n",
       "      <td>0.671578</td>\n",
       "      <td>-0.122653</td>\n",
       "      <td>2.056518</td>\n",
       "      <td>0.898047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORD</th>\n",
       "      <td>0.559241</td>\n",
       "      <td>-0.583565</td>\n",
       "      <td>2.461458</td>\n",
       "      <td>1.137774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHECK</th>\n",
       "      <td>0.572379</td>\n",
       "      <td>-0.470027</td>\n",
       "      <td>2.577530</td>\n",
       "      <td>1.066730</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU</th>\n",
       "      <td>0.084243</td>\n",
       "      <td>-1.870483</td>\n",
       "      <td>-2.766254</td>\n",
       "      <td>2.569693</td>\n",
       "      <td>-5.318520</td>\n",
       "      <td>1.331488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OT</th>\n",
       "      <td>0.286173</td>\n",
       "      <td>-0.619961</td>\n",
       "      <td>2.808929</td>\n",
       "      <td>1.165383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBSI</th>\n",
       "      <td>-0.499615</td>\n",
       "      <td>0.108198</td>\n",
       "      <td>3.488899</td>\n",
       "      <td>0.776863</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEC_F</th>\n",
       "      <td>-0.079163</td>\n",
       "      <td>-0.568319</td>\n",
       "      <td>3.091845</td>\n",
       "      <td>0.773604</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>4.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUN</th>\n",
       "      <td>0.211907</td>\n",
       "      <td>-0.981469</td>\n",
       "      <td>5.946429</td>\n",
       "      <td>3.704974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REW</th>\n",
       "      <td>-0.190551</td>\n",
       "      <td>-0.610675</td>\n",
       "      <td>4.464286</td>\n",
       "      <td>1.990647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HARM</th>\n",
       "      <td>0.533920</td>\n",
       "      <td>-0.006686</td>\n",
       "      <td>3.996429</td>\n",
       "      <td>1.001614</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_SE</th>\n",
       "      <td>-0.290144</td>\n",
       "      <td>-0.457931</td>\n",
       "      <td>3.068750</td>\n",
       "      <td>0.743746</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-CTR</th>\n",
       "      <td>0.560984</td>\n",
       "      <td>-0.082408</td>\n",
       "      <td>2.412500</td>\n",
       "      <td>1.002081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OB_PERF</th>\n",
       "      <td>0.238732</td>\n",
       "      <td>-0.523657</td>\n",
       "      <td>3.373214</td>\n",
       "      <td>1.275831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PS</th>\n",
       "      <td>-0.038523</td>\n",
       "      <td>-0.755104</td>\n",
       "      <td>3.137806</td>\n",
       "      <td>0.876994</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>4.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMB</th>\n",
       "      <td>0.345783</td>\n",
       "      <td>-0.308675</td>\n",
       "      <td>4.148839</td>\n",
       "      <td>0.798313</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRED</th>\n",
       "      <td>0.290743</td>\n",
       "      <td>-0.237326</td>\n",
       "      <td>3.607232</td>\n",
       "      <td>0.822479</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>5.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAND</th>\n",
       "      <td>-0.183202</td>\n",
       "      <td>-0.233935</td>\n",
       "      <td>4.517798</td>\n",
       "      <td>1.115602</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IUS-P</th>\n",
       "      <td>0.094507</td>\n",
       "      <td>0.392694</td>\n",
       "      <td>3.211684</td>\n",
       "      <td>0.706690</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IUS-I</th>\n",
       "      <td>0.463743</td>\n",
       "      <td>-0.122766</td>\n",
       "      <td>2.405357</td>\n",
       "      <td>0.913348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SES</th>\n",
       "      <td>-0.025765</td>\n",
       "      <td>-0.452866</td>\n",
       "      <td>2.846429</td>\n",
       "      <td>0.629304</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance</th>\n",
       "      <td>0.039594</td>\n",
       "      <td>0.264725</td>\n",
       "      <td>1.146289</td>\n",
       "      <td>1.197071</td>\n",
       "      <td>-2.616927</td>\n",
       "      <td>3.964060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    skew  kurtosis      mean       std        min        max\n",
       "RRQ            -0.476740 -0.799871  3.542411  0.895835   1.083333   4.920000\n",
       "DASS-21 Stress  0.214291 -0.458841  2.208202  0.649908   1.000000   4.000000\n",
       "DASS-21 Dep     0.928685  0.361288  1.855612  0.654062   1.000000   3.714286\n",
       "STAI-T          0.254574 -0.406814  2.237054  0.458343   1.300000   3.450000\n",
       "STAI-S Diff     0.990347  1.493530  4.053571  6.726095 -11.000000  30.000000\n",
       "BIS            -0.325488 -0.040535  3.003661  0.551110   1.290000   4.000000\n",
       "BAS_D           0.064607 -0.345385  2.455357  0.630685   1.000000   4.000000\n",
       "BAS_PRZY       -0.071123 -0.000214  2.774554  0.559480   1.250000   4.000000\n",
       "BAS_NAG        -0.262946  0.418897  3.226786  0.426590   1.800000   4.000000\n",
       "WASH           -0.256834 -1.425861 -1.074865  1.415516  -2.903676   1.507260\n",
       "OBSESS          0.676671 -0.257087  2.422381  0.987241   1.000000   5.000000\n",
       "HOARD           0.671578 -0.122653  2.056518  0.898047   1.000000   4.670000\n",
       "ORD             0.559241 -0.583565  2.461458  1.137774   1.000000   5.000000\n",
       "CHECK           0.572379 -0.470027  2.577530  1.066730   1.000000   5.000000\n",
       "NEU             0.084243 -1.870483 -2.766254  2.569693  -5.318520   1.331488\n",
       "OT              0.286173 -0.619961  2.808929  1.165383   1.000000   5.800000\n",
       "WBSI           -0.499615  0.108198  3.488899  0.776863   1.330000   5.000000\n",
       "INDEC_F        -0.079163 -0.568319  3.091845  0.773604   1.270000   4.733333\n",
       "PUN             0.211907 -0.981469  5.946429  3.704974   0.000000  13.000000\n",
       "REW            -0.190551 -0.610675  4.464286  1.990647   0.000000   8.000000\n",
       "HARM            0.533920 -0.006686  3.996429  1.001614   2.000000   6.800000\n",
       "G_SE           -0.290144 -0.457931  3.068750  0.743746   1.200000   4.500000\n",
       "T-CTR           0.560984 -0.082408  2.412500  1.002081   1.000000   5.200000\n",
       "OB_PERF         0.238732 -0.523657  3.373214  1.275831   1.000000   6.600000\n",
       "PS             -0.038523 -0.755104  3.137806  0.876994   1.285714   4.860000\n",
       "AMB             0.345783 -0.308675  4.148839  0.798313   2.500000   6.000000\n",
       "PRED            0.290743 -0.237326  3.607232  0.822479   1.880000   5.630000\n",
       "STAND          -0.183202 -0.233935  4.517798  1.115602   2.000000   7.000000\n",
       "IUS-P           0.094507  0.392694  3.211684  0.706690   1.285714   5.000000\n",
       "IUS-I           0.463743 -0.122766  2.405357  0.913348   1.000000   5.000000\n",
       "SES            -0.025765 -0.452866  2.846429  0.629304   1.400000   4.000000\n",
       "performance     0.039594  0.264725  1.146289  1.197071  -2.616927   3.964060"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = questionnaires_scores_df_transformed.agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72802dd9-ef2b-46cd-8a9d-08ce93c72229",
   "metadata": {},
   "source": [
    "#### Demographical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d953a83d-5539-4f9d-a130-72c1b5d2456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = \"Age\"\n",
    "sex = \"Sex\"\n",
    "handness = \"Handness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f2abf7e5-a77b-443d-a8a2-667a83b5d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [\n",
    "    age,\n",
    "    sex,\n",
    "    handness\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "418ef9d2-28d1-4e2b-8ce9-18ef3adea3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographical_scores_df =  epochs_df[scales].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ba5708a5-ce72-43c3-a0cc-16f29d2638a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.508559</td>\n",
       "      <td>2.313551</td>\n",
       "      <td>23.517857</td>\n",
       "      <td>3.995453</td>\n",
       "      <td>18.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543428</td>\n",
       "      <td>-1.725178</td>\n",
       "      <td>0.370536</td>\n",
       "      <td>0.482792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Handness</th>\n",
       "      <td>-3.664040</td>\n",
       "      <td>11.632627</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.243149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              skew   kurtosis       mean       std   min   max\n",
       "Age       1.508559   2.313551  23.517857  3.995453  18.0  38.0\n",
       "Sex       0.543428  -1.725178   0.370536  0.482792   0.0   1.0\n",
       "Handness -3.664040  11.632627   0.937500  0.243149   0.0   1.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = demographical_scores_df.agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccab4540-8d71-4736-ac33-c50a0428c0cc",
   "metadata": {},
   "source": [
    "Transform skewed age entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "315ad0b9-bc15-47b9-817e-fc466c906f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = demographical_scores_df[['Age']].to_numpy().flatten()\n",
    "age_transformed, lambda_ = boxcox(age)\n",
    "demographical_scores_df[['Age']] = age_transformed.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3626ce17-e5c7-49d6-a790-82c1cd6b271b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.061219</td>\n",
       "      <td>-0.240767</td>\n",
       "      <td>0.394452</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.394338</td>\n",
       "      <td>0.394559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543428</td>\n",
       "      <td>-1.725178</td>\n",
       "      <td>0.370536</td>\n",
       "      <td>0.482792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Handness</th>\n",
       "      <td>-3.664040</td>\n",
       "      <td>11.632627</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.243149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              skew   kurtosis      mean       std       min       max\n",
       "Age       0.061219  -0.240767  0.394452  0.000049  0.394338  0.394559\n",
       "Sex       0.543428  -1.725178  0.370536  0.482792  0.000000  1.000000\n",
       "Handness -3.664040  11.632627  0.937500  0.243149  0.000000  1.000000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = demographical_scores_df.agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf8cbe-77f8-4ff1-94e2-85108eae85cc",
   "metadata": {},
   "source": [
    "#### Concatenate questionnaire and EEG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0417570f-a028-4df8-afe5-f1b27eeee5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_columns_ica = ['e_PCA_1_6', 'e_PCA_2_6']\n",
    "\n",
    "eeg_columns_ern = ['e_ERN']\n",
    "eeg_columns_crn = ['e_CRN']\n",
    "\n",
    "eeg_column_latencies_fal = ['e_LT_F']\n",
    "eeg_column_latencies_peak = ['e_LT_P']\n",
    "\n",
    "eeg_column_ch_type = ['e_LTR']\n",
    "\n",
    "\n",
    "eeg_column_latencies_fal_2_crn = ['e_LT_F2_C']\n",
    "eeg_column_latencies_fal_6_crn = ['e_LT_F6_C']\n",
    "eeg_column_latencies_peak_crn = ['e_LT_P_C']\n",
    "\n",
    "eeg_column_ch_type_crn = ['e_LTR_C']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7bb57d-3781-4238-a702-ae5ce9ea2a88",
   "metadata": {},
   "source": [
    "1. ERN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dd693ecc-18af-47d4-86c8-f743fadc35f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "38a5a406-dad4-4e48-ad07-dafca5789770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_ERN</th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>BAS_NAG</th>\n",
       "      <th>...</th>\n",
       "      <th>G_SE</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.910689e-06</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>2.35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.63</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.682340e-06</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.251852e-07</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.90</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.107933e-06</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.95</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.25</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.880873e-06</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.63</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          e_ERN       RRQ  DASS-21 Stress  DASS-21 Dep  STAI-T  STAI-S Diff  \\\n",
       "0  1.910689e-06  4.250000        1.714286     1.428571    2.35          8.0   \n",
       "1 -1.682340e-06  2.500000        1.714286     2.142857    2.00          9.0   \n",
       "2  3.251852e-07  4.166667        2.285714     3.142857    2.90         14.0   \n",
       "3 -1.107933e-06  2.250000        2.428571     1.857143    1.95          6.0   \n",
       "4 -8.880873e-06  2.416667        1.857143     1.142857    1.75         -1.0   \n",
       "\n",
       "   BIS  BAS_D  BAS_PRZY  BAS_NAG  ...  G_SE  T-CTR  OB_PERF        PS   AMB  \\\n",
       "0  3.4   4.00       3.0      3.8  ...   3.9    3.2      5.2  3.285714  4.00   \n",
       "1  3.1   1.75       2.5      2.8  ...   2.4    3.4      3.4  1.571429  4.50   \n",
       "2  3.1   2.00       3.0      3.6  ...   4.0    3.0      4.0  2.714286  4.50   \n",
       "3  2.7   3.00       2.5      3.4  ...   2.9    3.4      2.2  4.285714  3.67   \n",
       "4  3.0   2.50       2.5      3.0  ...   2.5    1.0      2.0  3.142857  4.00   \n",
       "\n",
       "   PRED     STAND     IUS-P  IUS-I  SES  \n",
       "0  4.63  5.333333  3.428571    2.0  3.0  \n",
       "1  3.63  2.666667  2.857143    2.0  2.5  \n",
       "2  4.00  3.666667  3.000000    3.2  1.6  \n",
       "3  2.25  6.000000  3.571429    1.8  3.4  \n",
       "4  2.63  5.333333  2.571429    1.2  3.5  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ern_df = pd.DataFrame()\n",
    "\n",
    "results_ern_df[eeg_columns_ern] = preprocessed_X_ern # simple mean amp of ERN in 0 -100 m\n",
    "results_ern_df = pd.concat([results_ern_df, questionnaires_scores_df_transformed.drop(columns=['performance'])], axis=1) # add questionnaires\n",
    "\n",
    "results_ern_df.to_pickle(f\"../data/models_pickles_new_dass/ern_models_{dataset}.pkl\")\n",
    "results_ern_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7ea02-ae5e-4f45-89b7-a278b631ad55",
   "metadata": {},
   "source": [
    "1' CRN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8bc00e6d-580a-4eeb-89c9-2b8573976554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_CRN</th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>BIS</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_PRZY</th>\n",
       "      <th>BAS_NAG</th>\n",
       "      <th>...</th>\n",
       "      <th>G_SE</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.215947e-06</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>2.35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.63</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.324835e-06</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.137290e-07</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.90</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.283374e-06</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.95</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.25</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.133535e-06</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.63</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          e_CRN       RRQ  DASS-21 Stress  DASS-21 Dep  STAI-T  STAI-S Diff  \\\n",
       "0  2.215947e-06  4.250000        1.714286     1.428571    2.35          8.0   \n",
       "1  3.324835e-06  2.500000        1.714286     2.142857    2.00          9.0   \n",
       "2  9.137290e-07  4.166667        2.285714     3.142857    2.90         14.0   \n",
       "3 -1.283374e-06  2.250000        2.428571     1.857143    1.95          6.0   \n",
       "4 -5.133535e-06  2.416667        1.857143     1.142857    1.75         -1.0   \n",
       "\n",
       "   BIS  BAS_D  BAS_PRZY  BAS_NAG  ...  G_SE  T-CTR  OB_PERF        PS   AMB  \\\n",
       "0  3.4   4.00       3.0      3.8  ...   3.9    3.2      5.2  3.285714  4.00   \n",
       "1  3.1   1.75       2.5      2.8  ...   2.4    3.4      3.4  1.571429  4.50   \n",
       "2  3.1   2.00       3.0      3.6  ...   4.0    3.0      4.0  2.714286  4.50   \n",
       "3  2.7   3.00       2.5      3.4  ...   2.9    3.4      2.2  4.285714  3.67   \n",
       "4  3.0   2.50       2.5      3.0  ...   2.5    1.0      2.0  3.142857  4.00   \n",
       "\n",
       "   PRED     STAND     IUS-P  IUS-I  SES  \n",
       "0  4.63  5.333333  3.428571    2.0  3.0  \n",
       "1  3.63  2.666667  2.857143    2.0  2.5  \n",
       "2  4.00  3.666667  3.000000    3.2  1.6  \n",
       "3  2.25  6.000000  3.571429    1.8  3.4  \n",
       "4  2.63  5.333333  2.571429    1.2  3.5  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_crn_df = pd.DataFrame()\n",
    "\n",
    "results_crn_df[eeg_columns_crn] = preprocessed_X_crn # simple mean amp of ERN in 0 -100 ms\n",
    "results_crn_df = pd.concat([results_crn_df, questionnaires_scores_df_transformed.drop(columns=['performance'])], axis=1) # add questionnaires\n",
    "\n",
    "results_crn_df.to_pickle(f\"../data/models_pickles_new_dass/crn_models_{dataset}.pkl\")\n",
    "results_crn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9e322-46a5-468a-af1e-0254feeaf3ea",
   "metadata": {},
   "source": [
    "2. ERN, Fractional Area Latency + DEMO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "d2f33769-958e-41e6-a3d6-0270db6d44d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_ERN</th>\n",
       "      <th>e_LT_F</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Handness</th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.622882e-07</td>\n",
       "      <td>0.082812</td>\n",
       "      <td>0.424951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.25</td>\n",
       "      <td>10.298817</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.684569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.121127e-05</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.424985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.376404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.579851e-05</td>\n",
       "      <td>0.063281</td>\n",
       "      <td>0.425040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.40</td>\n",
       "      <td>14.306246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.098470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.217479e-07</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.239223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.456946e-06</td>\n",
       "      <td>0.059375</td>\n",
       "      <td>0.425062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.25</td>\n",
       "      <td>8.915005</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.746350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          e_ERN    e_LT_F       Age  Sex  Handness       RRQ  DASS-21 Stress  \\\n",
       "0 -6.622882e-07  0.082812  0.424951  1.0       1.0  3.416667        1.285714   \n",
       "1 -1.121127e-05  0.106250  0.424985  1.0       1.0  3.750000        1.142857   \n",
       "2 -1.579851e-05  0.063281  0.425040  1.0       1.0  3.833333        1.857143   \n",
       "3 -5.217479e-07  0.004687  0.425113  1.0       1.0  2.250000        3.000000   \n",
       "4 -6.456946e-06  0.059375  0.425062  1.0       1.0  3.916667        2.142857   \n",
       "\n",
       "   DASS-21 Dep  STAI-T  STAI-S Diff  ...  T-CTR  OB_PERF        PS   AMB  \\\n",
       "0     2.142857    2.25    10.298817  ...    4.0      4.0  1.428571  4.83   \n",
       "1     1.285714    2.00     8.185239  ...    1.6      2.6  2.714286  4.17   \n",
       "2     1.571429    2.40    14.306246  ...    1.8      3.2  3.285714  4.00   \n",
       "3     2.571429    2.80     8.185239  ...    1.2      2.0  3.428571  3.33   \n",
       "4     1.571429    2.25     8.915005  ...    2.0      1.8  2.285714  3.67   \n",
       "\n",
       "   PRED     STAND     IUS-P  IUS-I  SES  performance  \n",
       "0  4.25  4.666667  3.142857    2.8  2.4     1.684569  \n",
       "1  3.75  5.000000  2.714286    1.8  3.1     1.376404  \n",
       "2  4.25  4.333333  2.142857    3.0  2.4    -0.098470  \n",
       "3  3.00  4.000000  3.428571    3.2  2.7     1.239223  \n",
       "4  3.25  4.000000  2.857143    1.8  3.0    -0.746350  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ern_lat_df = pd.DataFrame()\n",
    "\n",
    "results_ern_lat_df[eeg_columns_ern] = preprocessed_X_ern # simple mean amp of ERN in 0 -100 ms\n",
    "results_ern_lat_df[eeg_column_latencies_fal] = fractional_latencies_ern # latency of the largest amplitude within channels in ms\n",
    "# results_ern_lat_df[eeg_column_ch_type] = channels_type_ern # the biggest peak on the central || left || right channels \n",
    "results_ern_lat_df = pd.concat([results_ern_lat_df, demographical_scores_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "results_ern_lat_df.to_pickle(f\"../data/models_pickles_new_dass/ern_cov_fal_models_{dataset}.pkl\")\n",
    "results_ern_lat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4b59d-c4f6-4981-8c24-e15469a1a3d0",
   "metadata": {},
   "source": [
    "2' CRN, Fractional Area Latency (2 uV) + DEMO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "90ba4903-e223-45ed-9abf-cdccc5920eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_CRN</th>\n",
       "      <th>e_LT_F2_C</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Handness</th>\n",
       "      <th>RRQ</th>\n",
       "      <th>DASS-21 Stress</th>\n",
       "      <th>DASS-21 Dep</th>\n",
       "      <th>STAI-T</th>\n",
       "      <th>STAI-S Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>T-CTR</th>\n",
       "      <th>OB_PERF</th>\n",
       "      <th>PS</th>\n",
       "      <th>AMB</th>\n",
       "      <th>PRED</th>\n",
       "      <th>STAND</th>\n",
       "      <th>IUS-P</th>\n",
       "      <th>IUS-I</th>\n",
       "      <th>SES</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.337408e-07</td>\n",
       "      <td>0.133594</td>\n",
       "      <td>0.424951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.25</td>\n",
       "      <td>10.298817</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.684569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.552095e-06</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.424985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.376404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.552639e-06</td>\n",
       "      <td>0.098437</td>\n",
       "      <td>0.425040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.40</td>\n",
       "      <td>14.306246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.098470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.879014e-06</td>\n",
       "      <td>-0.007031</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.185239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.239223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.275722e-07</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.425062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.25</td>\n",
       "      <td>8.915005</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.746350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          e_CRN  e_LT_F2_C       Age  Sex  Handness       RRQ  DASS-21 Stress  \\\n",
       "0 -4.337408e-07   0.133594  0.424951  1.0       1.0  3.416667        1.285714   \n",
       "1 -2.552095e-06   0.137500  0.424985  1.0       1.0  3.750000        1.142857   \n",
       "2 -8.552639e-06   0.098437  0.425040  1.0       1.0  3.833333        1.857143   \n",
       "3  4.879014e-06  -0.007031  0.425113  1.0       1.0  2.250000        3.000000   \n",
       "4 -6.275722e-07   0.043750  0.425062  1.0       1.0  3.916667        2.142857   \n",
       "\n",
       "   DASS-21 Dep  STAI-T  STAI-S Diff  ...  T-CTR  OB_PERF        PS   AMB  \\\n",
       "0     2.142857    2.25    10.298817  ...    4.0      4.0  1.428571  4.83   \n",
       "1     1.285714    2.00     8.185239  ...    1.6      2.6  2.714286  4.17   \n",
       "2     1.571429    2.40    14.306246  ...    1.8      3.2  3.285714  4.00   \n",
       "3     2.571429    2.80     8.185239  ...    1.2      2.0  3.428571  3.33   \n",
       "4     1.571429    2.25     8.915005  ...    2.0      1.8  2.285714  3.67   \n",
       "\n",
       "   PRED     STAND     IUS-P  IUS-I  SES  performance  \n",
       "0  4.25  4.666667  3.142857    2.8  2.4     1.684569  \n",
       "1  3.75  5.000000  2.714286    1.8  3.1     1.376404  \n",
       "2  4.25  4.333333  2.142857    3.0  2.4    -0.098470  \n",
       "3  3.00  4.000000  3.428571    3.2  2.7     1.239223  \n",
       "4  3.25  4.000000  2.857143    1.8  3.0    -0.746350  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_crn_lat_demo_df = pd.DataFrame()\n",
    "\n",
    "results_crn_lat_demo_df[eeg_columns_crn] = preprocessed_X_crn # simple mean amp of ERN in 0 -100 ms\n",
    "results_crn_lat_demo_df[eeg_column_latencies_fal_2_crn] = fractional_latencies_crn_2uV # latency of the largest amplitude within channels in ms\n",
    "# results_crn_lat_demo_df[eeg_column_ch_type_crn] = channels_type_crn # the biggest peak on the central || left || right channels \n",
    "results_crn_lat_demo_df = pd.concat([results_crn_lat_demo_df, demographical_scores_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "results_crn_lat_demo_df.to_pickle(f\"../data/models_pickles_new_dass/crn_cov_fal2_models_{dataset}.pkl\")\n",
    "results_crn_lat_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54434d7-37ce-40ff-8264-ddb0c0e470b2",
   "metadata": {},
   "source": [
    "2'' CRN, Fractional Area Latency (6 uV), Lateralization + DEMO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ce2b51-c8cb-4120-ac03-3a9ac13d6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_crn_lat_demo_df = pd.DataFrame()\n",
    "\n",
    "# results_crn_lat_demo_df[eeg_columns_crn] = preprocessed_X_crn # simple mean amp of ERN in 0 -100 ms\n",
    "# results_crn_lat_demo_df[eeg_column_latencies_fal_6_crn] = fractional_latencies_crn_6uV # latency of the largest amplitude within channels in ms\n",
    "# # results_crn_lat_demo_df[eeg_column_ch_type_crn] = channels_type_crn # the biggest peak on the central || left || right channels \n",
    "# results_crn_lat_demo_df = pd.concat([results_crn_lat_demo_df, demographical_scores_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "# results_crn_lat_demo_df.to_pickle(f\"../data/models_pickles_new/crn_cov_fal6_models_{dataset}.pkl\")\n",
    "# results_crn_lat_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ff81e-8fd4-49a6-9fb0-f40d25d9c9e5",
   "metadata": {},
   "source": [
    "3.ERN, Peak Latency, Lateralization + DEMO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a121a0d1-afea-479e-8d39-1133e4bc40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_ern_lat_df = pd.DataFrame()\n",
    "\n",
    "# results_ern_lat_df[eeg_columns_ern] = preprocessed_X_ern # simple mean amp of ERN in 0 -100 ms\n",
    "# results_ern_lat_df[eeg_column_latencies_peak] = peak_latencies_ern # latency of the largest amplitude within channels in ms\n",
    "# # results_ern_lat_df[eeg_column_ch_type] = channels_type_ern # the biggest peak on the central || left || right channels \n",
    "# results_ern_lat_df = pd.concat([results_ern_lat_df, demographical_scores_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "# results_ern_lat_df.to_pickle(f\"../data/models_pickles_new/ern_cov_peak_models_{dataset}.pkl\")\n",
    "# results_ern_lat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20587b64-72f6-4920-b492-f1a5eb44afa8",
   "metadata": {},
   "source": [
    "3'. CRN, Peak Latency, Lateralization + DEMO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6011800d-63dc-4f2b-b7b5-9911b29ede68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_crn_lat_demo_df = pd.DataFrame()\n",
    "\n",
    "# results_crn_lat_demo_df[eeg_columns_crn] = preprocessed_X_crn # simple mean amp of ERN in 0 -100 ms\n",
    "# results_crn_lat_demo_df[eeg_column_latencies_peak_crn] = peak_latencies_crn # latency of the largest amplitude within channels in ms\n",
    "# # results_crn_lat_demo_df[eeg_column_ch_type_crn] = channels_type_crn # the biggest peak on the central || left || right channels \n",
    "# results_crn_lat_demo_df = pd.concat([results_crn_lat_demo_df, demographical_scores_df, questionnaires_scores_df_transformed], axis=1) # add questionnaires\n",
    "\n",
    "# results_crn_lat_demo_df.to_pickle(f\"../data/models_pickles_new/crn_cov_peak_models_{dataset}.pkl\")\n",
    "# results_crn_lat_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e596490-fa93-4c4c-9831-90b84c968bc7",
   "metadata": {},
   "source": [
    "----\n",
    "## Transform non-normal data distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987f3894-aee7-4858-ac6c-5f51a4b38afa",
   "metadata": {},
   "source": [
    "Check skewness and kurtiosis\n",
    "\n",
    "As a general rule of thumb: If skewness is less than -1 or greater than 1, the distribution is highly skewed. If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed. If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n",
    "\n",
    "Analogous to the skewness, the general guideline is that if the kurtosis is greater than +2, the distribution is too peaked. Likewise, a kurtosis of less than −2 indicates a distribution that is too flat. When both skewness and kurtosis are close to zero, the pattern of responses is considered a normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "0f1da5d0-e2f9-45dd-8886-0a757073c362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "a02b2b34-86fd-4319-997e-c23a6eae9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_data_df = pd.read_pickle(f\"../data/models_pickles_new_dass/ern_models_{dataset}.pkl\")\n",
    "ern_cov_fal_data_df = pd.read_pickle(f\"../data/models_pickles_new_dass/ern_cov_fal_models_{dataset}.pkl\")\n",
    "# ern_cov_peak_data_df = pd.read_pickle(f'../data/models_pickles_new/ern_cov_peak_models_{dataset}.pkl')\n",
    "\n",
    "crn_data_df = pd.read_pickle(f\"../data/models_pickles_new_dass/crn_models_{dataset}.pkl\")\n",
    "crn_cov_fal2_data_df = pd.read_pickle(f\"../data/models_pickles_new_dass/crn_cov_fal2_models_{dataset}.pkl\")\n",
    "# crn_cov_fal6_data_df = pd.read_pickle(f\"../data/models_pickles_new/crn_cov_fal6_models_{dataset}.pkl\")\n",
    "# crn_cov_peak_data_df = pd.read_pickle(f'../data/models_pickles_new/crn_cov_peak_models_{dataset}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "cab16a18-c5d3-45c7-9ed3-383588f69404",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ern_data_df, \n",
    "    ern_cov_fal_data_df, \n",
    "    # ern_cov_peak_data_df,\n",
    "    crn_data_df,\n",
    "    crn_cov_fal2_data_df,\n",
    "    # crn_cov_fal6_data_df,\n",
    "    # crn_cov_peak_data_df,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650acd8d-11e7-4e5c-a438-ebb819b81b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_exclude = ['Sex', 'Handness', 'e_LTR_C', 'e_LTR']\n",
    "# datasets_transformed = []\n",
    "\n",
    "# for dataset in datasets:\n",
    "#     columns = dataset.columns\n",
    "#     columns_to_process =  list(set(columns) - set(columns_to_exclude))\n",
    "#     summary = dataset[columns_to_process].agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "#     # display(summary)\n",
    "    \n",
    "#     dataset_transformed = dataset.copy()\n",
    "\n",
    "#     for row in summary.iterrows():\n",
    "#         item_name = row[0]\n",
    "#         skewness_ = row[1]['skew']\n",
    "#         kurtosis_ = row[1]['kurtosis']\n",
    "\n",
    "#         if abs(skewness_) > 1 or abs(kurtosis_) > 2:\n",
    "#             print(f'Transforming: {item_name} scale')\n",
    "#             this_scores = dataset_transformed[[item_name]].to_numpy().flatten()\n",
    "#             this_scores = this_scores - 0.99\n",
    "#             this_scores_transformed, lambda_ = boxcox(this_scores)\n",
    "#             print(f'   Stats before transformation:\\n    Skewness: {skew(this_scores)} \\n    Kurtosis: {scipy.stats.kurtosis(this_scores)}')\n",
    "#             print(f'   Stats after transformation:\\n    Skewness: {skew(this_scores_transformed)} \\n    Kurtosis: {scipy.stats.kurtosis(this_scores_transformed)}')\n",
    "\n",
    "#             dataset_transformed[[item_name]] = this_scores_transformed.reshape(-1,1)\n",
    "#         else:\n",
    "#             # print(f\"Nothing to transform\")\n",
    "#             pass\n",
    "#     summary = dataset_transformed[columns_to_process].agg(['skew', 'kurtosis', 'mean', 'std', 'min', 'max']).transpose()\n",
    "#     # display(summary)   \n",
    "    \n",
    "#     datasets_transformed.append(dataset_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31a9f2e9-1ae3-46d0-9438-8ce44b90fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to transform now, so no write"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net",
   "language": "python",
   "name": "net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
