{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "818009d9-775e-4897-9c28-7547f732f1ca",
   "metadata": {},
   "source": [
    "# Stability estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a44c9-a843-47a6-b63a-b798a03dd097",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc637e3-f121-45d5-898f-ad7de817ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tabulate\n",
    "import time\n",
    "\n",
    "import logging\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "import ast\n",
    "import os.path as op\n",
    "import pickle\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial import distance\n",
    "import scipy.stats as stats\n",
    "\n",
    "import networkx as nx\n",
    "import glob, os\n",
    "from functools import partial\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf86b4-2889-4e78-a124-d154548c7180",
   "metadata": {},
   "source": [
    "Constatnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be40e3-3f4a-42f3-945b-8f5e58b101dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"RRQ\": \"1Q\",\n",
    "    \"DASS-21 Stress\": \"2Q\",\n",
    "    \"DASS-21 Dep\": \"3Q\",\n",
    "    \"STAI-T\": \"4Q\",\n",
    "    \"STAI-S Diff\": '5Q',\n",
    "    \"BIS\": \"6Q\",\n",
    "    \"OBSESS\": \"7Q\",\n",
    "    \"HOARD\": \"8Q\",\n",
    "    \"ORD\": \"9Q\",\n",
    "    \"CHECK\": \"10Q\",\n",
    "    \"WBSI\": \"11Q\",\n",
    "    \"IUS-P\": \"12Q\",\n",
    "    \"IUS-I\": \"13Q\",\n",
    "    \"SES\": \"14Q\",\n",
    "    'BAS_D': \"15Q\",\n",
    "    'BAS_PRZY': \"16Q\",\n",
    "    'BAS_NAG': \"17Q\",\n",
    "    'INDEC_F': \"18Q\",\n",
    "    'PUN': \"19Q\",\n",
    "    'REW': \"20Q\",\n",
    "    'HARM': \"21Q\",\n",
    "    'T-CTR': \"22Q\",\n",
    "    \"OT\": \"23Q\",\n",
    "    'OB_PERF': \"24Q\",\n",
    "    'PS': \"25Q\",\n",
    "    'G_SE': \"26Q\",\n",
    "    'AMB': \"27Q\",\n",
    "    'PRED': \"28Q\",\n",
    "    'STAND': \"29Q\",   \n",
    "    \"Age\": \"1C\",\n",
    "    \"Handness\": \"2C\",\n",
    "    'e_ERN': \"1E\",\n",
    "    'e_LT_F': \"4C\",\n",
    "    'performance': \"3C\",\n",
    "    'e_CRN': \"2E\",\n",
    "    'e_LT_F2_C': \"4C\",\n",
    "    'performance': \"3C\",\n",
    "}\n",
    "\n",
    "ern_order = ['1E', '1Q', '2Q', '3Q', '4Q', '5Q', '6Q', '7Q', '8Q', '9Q', '10Q', '11Q', '12Q', '13Q', '14Q', '15Q', '16Q', '17Q', '18Q', '19Q', '20Q', '21Q', '22Q', '23Q', '24Q', '25Q', '26Q', '27Q', '28Q', '29Q',]\n",
    "ern_cov_order = ['1E', '1Q', '2Q', '3Q', '4Q', '5Q', '6Q', '7Q', '8Q', '9Q', '10Q', '11Q', '12Q', '13Q', '14Q', '15Q', '16Q', '17Q', '18Q', '19Q', '20Q', '21Q', '22Q', '23Q', '24Q', '25Q', '26Q', '27Q', '28Q', '29Q', '1C', '2C', '3C', '4C']\n",
    "crn_order = ['2E', '1Q', '2Q', '3Q', '4Q', '5Q', '6Q', '7Q', '8Q', '9Q', '10Q', '11Q', '12Q', '13Q', '14Q', '15Q', '16Q', '17Q', '18Q', '19Q', '20Q', '21Q', '22Q', '23Q', '24Q', '25Q', '26Q', '27Q', '28Q', '29Q',]\n",
    "crn_cov_order = ['2E', '1Q', '2Q', '3Q', '4Q', '5Q', '6Q', '7Q', '8Q', '9Q', '10Q', '11Q', '12Q', '13Q', '14Q', '15Q', '16Q', '17Q', '18Q', '19Q', '20Q', '21Q', '22Q', '23Q', '24Q', '25Q', '26Q', '27Q', '28Q', '29Q', '1C', '2C', '3C', '4C']\n",
    "\n",
    "orders = [ern_order, ern_cov_order, crn_order, crn_cov_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab7ac13-619a-46e2-9ee6-0c2159d69dbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96963f4b-8d35-4c4f-b5ad-231ab81054c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'train'\n",
    "test = False if dataset == 'train' else False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ba2a4-3953-4a08-be4c-459e6f020b06",
   "metadata": {},
   "source": [
    "Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee1774-3921-4caa-822d-6061181e5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ern_df = pd.read_pickle(f\"../data/models_pickles_new_dass/ern_models_{dataset}.pkl\")\n",
    "results_ern_lat_demo_df = pd.read_pickle(f\"../data/models_pickles_new_dass/ern_cov_fal_models_{dataset}.pkl\")\n",
    "results_crn_df = pd.read_pickle(f\"../data/models_pickles_new_dass/crn_models_{dataset}.pkl\")\n",
    "results_crn_lat_demo_df = pd.read_pickle(f\"../data/models_pickles_new_dass/crn_cov_fal2_models_{dataset}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d91fb5-0dfa-42dd-8bc5-961c8a68b9fd",
   "metadata": {},
   "source": [
    "Loading testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b2f58-1937-40e7-8e21-c1fb3bcb1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ern_test_df = pd.read_pickle(f\"../data/models_pickles_new_dass/ern_models_test.pkl\")\n",
    "results_ern_lat_demo_test_df = pd.read_pickle(f\"../data/models_pickles_new_dass/ern_cov_fal_models_test.pkl\")\n",
    "results_crn_test_df = pd.read_pickle(f\"../data/models_pickles_new_dass/crn_models_test.pkl\")\n",
    "results_crn_lat_demo_test_df = pd.read_pickle(f\"../data/models_pickles_new_dass/crn_cov_fal2_models_test.pkl\")\n",
    "\n",
    "# fill nan\n",
    "results_crn_lat_demo_test_df['e_LT_F2_C'] = results_crn_lat_demo_test_df['e_LT_F2_C'].fillna(results_crn_lat_demo_test_df['e_LT_F2_C'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90281e6d-a1b1-4764-998c-8c085f7bf5e8",
   "metadata": {},
   "source": [
    "Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b716d-79df-4f10-91ff-0a43a9b87768",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_covs = ['WASH', 'NEU', 'Sex']\n",
    "columns_to_drop = ['WASH', 'NEU']\n",
    "\n",
    "# train dataset\n",
    "ern_data_df_ = results_ern_df.drop(columns=columns_to_drop)\n",
    "ern_cov_fal_data_df_ = results_ern_lat_demo_df.drop(columns=columns_to_drop_covs)\n",
    "crn_data_df_ = results_crn_df.drop(columns=columns_to_drop)\n",
    "crn_cov_fal2_data_df_ = results_crn_lat_demo_df.drop(columns=columns_to_drop_covs)\n",
    "\n",
    "# test dataset\n",
    "ern_data_df_test_ = results_ern_test_df.drop(columns=columns_to_drop)\n",
    "ern_cov_fal_data_df_test_ = results_ern_lat_demo_test_df.drop(columns=columns_to_drop_covs)\n",
    "crn_data_df_test_ = results_crn_test_df.drop(columns=columns_to_drop)\n",
    "crn_cov_fal2_data_df_test_ = results_crn_lat_demo_test_df.drop(columns=columns_to_drop_covs)\n",
    "\n",
    "datasets_train = [ern_data_df_, ern_cov_fal_data_df_, crn_data_df_, crn_cov_fal2_data_df_]\n",
    "datasets_test = [ern_data_df_test_, ern_cov_fal_data_df_test_, crn_data_df_test_, crn_cov_fal2_data_df_test_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dad124-e737-49fb-a340-40e3c19ef739",
   "metadata": {},
   "source": [
    "### Read estimated graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f983ed-c895-434a-956b-5a5c27e644cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = f\"../data/graphs/{dataset}/\"\n",
    "\n",
    "graphs = []\n",
    "\n",
    "for file in sorted(glob.glob(dir_ + \"*.gml\")):\n",
    "    print(file)\n",
    "    graph = nx.read_gml(file)\n",
    "    graphs.append(graph)\n",
    "    \n",
    "graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a232d-40f0-4618-9165-fd3105fb99cc",
   "metadata": {},
   "source": [
    "## 1. Stability of network structure as proportion matrices from stability selection procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b887cf26-fdc4-4809-82f7-dcdcc056e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proportion_matrices(\n",
    "    proportion_matrices, \n",
    "    mapping=None, \n",
    "    save=False,\n",
    "):\n",
    "    proportion_matrix_1 = proportion_matrices[0][0]\n",
    "    order_1 = proportion_matrices[0][1]\n",
    "    \n",
    "    ern_df = proportion_matrix_1.rename(columns=mapping, index=mapping)\n",
    "    ern_df = ern_df.reindex(columns=order_1, index=order_1)\n",
    "    ern_mask = np.triu(np.ones_like(ern_df, dtype=bool))\n",
    "\n",
    "    proportion_matrix_2 = proportion_matrices[1][0]\n",
    "    order_2 = proportion_matrices[1][1]\n",
    "    \n",
    "    crn_df = proportion_matrix_2.rename(columns=mapping, index=mapping)\n",
    "    crn_df = crn_df.reindex(columns=order_2, index=order_2)\n",
    "    crn_mask = np.tril(np.ones_like(crn_df, dtype=bool))\n",
    "    \n",
    "\n",
    "    # define plotting parameters\n",
    "    cmap = sns.diverging_palette(100, 7, s=75, l=40, n=5, center=\"light\", as_cmap=True)\n",
    "    cm = 1/2.54\n",
    "    dpi = 500\n",
    "    \n",
    "    sns.set_style(\"white\")\n",
    "    plt.rcParams['figure.dpi'] = dpi\n",
    "    plt.rcParams['figure.figsize'] = [15*cm,15*cm]\n",
    "    plt.rcParams[\"font.size\"] = 4\n",
    "    plt.rcParams['ytick.labelsize'] = 6\n",
    "    plt.rcParams['xtick.labelsize'] = 6\n",
    "    plt.rcParams['axes.labelsize'] = 7\n",
    "    plt.rcParams[\"axes.edgecolor\"] = \".15\"\n",
    "    plt.rcParams[\"axes.linewidth\"]  = 0.5\n",
    "\n",
    "    # create canvas\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "\n",
    "    # draw first proportion matrix\n",
    "    g_1 = sns.heatmap(\n",
    "        data = ern_df,\n",
    "        annot=True,\n",
    "        mask = ern_mask,\n",
    "        center=0.5,\n",
    "        fmt='.2f',\n",
    "        square=True,\n",
    "        cmap=cmap,\n",
    "        cbar=False,\n",
    "        linewidths=1,\n",
    "        ax=axis\n",
    "    )\n",
    "\n",
    "    # draw second proportion matrix\n",
    "    g_2 = sns.heatmap(\n",
    "        data = crn_df,\n",
    "        annot=True,\n",
    "        mask = crn_mask,\n",
    "        center=0.5,\n",
    "        fmt='.2f',\n",
    "        square=True,\n",
    "        cmap=cmap,\n",
    "        cbar=False,\n",
    "        linewidths=1,\n",
    "        ax=axis\n",
    "    )\n",
    "\n",
    "    if save != False:\n",
    "        figure.savefig(f\"data/support_proportion/train/{save}.png\",  bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e11b0b4-2da3-4116-bef3-fafcc1ddafc1",
   "metadata": {},
   "source": [
    "Read proportion matrices from the stability selection procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c7fd6-d29a-4b1a-97c4-f3b0a72959e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = f\"../data/support_proportion/train/\"\n",
    "\n",
    "proportion_matrices = []\n",
    "\n",
    "for file in sorted(glob.glob(dir_ + \"proportion_*.pkl\")):\n",
    "    print(file)\n",
    "    proportion_matrix = pd.read_pickle(file)\n",
    "    proportion_matrices.append(proportion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caec76c1-977b-4b4d-82a4-e3b1571cb2f7",
   "metadata": {},
   "source": [
    "#### Draw proportion matrices for ERN and CRN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d7914-9b07-4964-8de4-10703535cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_matrices_to_plot = [\n",
    "    (proportion_matrices[0], ern_order),\n",
    "    (proportion_matrices[2], crn_order), \n",
    "]\n",
    "\n",
    "fig = plot_proportion_matrices(\n",
    "    proportion_matrices = proportion_matrices_to_plot, \n",
    "    mapping=mapping, \n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d01fd75-c04a-43a5-9b9e-7d84cd6212a9",
   "metadata": {},
   "source": [
    "#### Draw proportion matrices for ERN with covariates and CRN with covariates models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac074f9-5a3b-441c-b753-754a1d758b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_matrices_to_plot = [\n",
    "    (proportion_matrices[1], ern_cov_order),\n",
    "    (proportion_matrices[3], crn_cov_order), \n",
    "]\n",
    "\n",
    "fig = plot_proportion_matrices(\n",
    "    proportion_matrices = proportion_matrices_to_plot, \n",
    "    mapping=mapping, \n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c82ddd-c66e-448a-9c77-5eeae515e870",
   "metadata": {},
   "source": [
    "## 2. Edge-Weight stability using bootstrapping on adaptive average procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1e202-5969-4937-bad5-b5bd57f64bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_pickle(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        precision_matrices = pickle.load(file)\n",
    "    return precision_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc240ea-be3f-4ee0-8184-55c168202c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_matrix(matrix, columns, index, mapping, mapping_order, to_numpy=True):\n",
    "    df = pd.DataFrame(matrix, columns=columns, index=index)\n",
    "    df = df.rename(columns=mapping, index=mapping)\n",
    "    df = df.reindex(columns=mapping_order, index=mapping_order)\n",
    "\n",
    "    result = df.to_numpy() if to_numpy else df\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a69c55-241b-48cd-b53a-49d654b20d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_weights_stability_estimates(\n",
    "    precision_matrices, \n",
    "    df, \n",
    "    mapping, \n",
    "    order, \n",
    "):\n",
    "    precision_matrices_list = [reorder_matrix(matrix, df.columns, df.columns, mapping=mapping, mapping_order=order) for matrix in precision_matrices]\n",
    "    \n",
    "    # Step 1: Calculate the average matrix\n",
    "    average_matrix = np.around(sum(precision_matrices_list) / len(precision_matrices_list), decimals=2)\n",
    "\n",
    "    # Step 2: Calculate the standard error matrix\n",
    "    std_error_matrix = np.std(precision_matrices_list, axis=0) / np.sqrt(len(precision_matrices_list))\n",
    "\n",
    "    # Step 3: Calculate the 95% confidence interval values\n",
    "    z_score = stats.norm.ppf(0.975)  # Z-score for a 95% confidence interval\n",
    "\n",
    "    n = average_matrix.shape[0]\n",
    "    upper_triangle = np.triu(np.ones((n, n), dtype=bool), k=1)\n",
    "    lower_triangle = np.tril(np.ones((n, n), dtype=bool), k=0)\n",
    "\n",
    "    confidence_interval_low = average_matrix.copy()\n",
    "    confidence_interval_low[upper_triangle] -= z_score * std_error_matrix[upper_triangle]\n",
    "\n",
    "    confidence_interval_high = average_matrix.copy()\n",
    "    confidence_interval_high[upper_triangle] += z_score * std_error_matrix[upper_triangle]\n",
    "\n",
    "    # Step 4: Combine the confidence interval ranges into the final_matrix as strings\n",
    "    final_matrix = np.empty_like(average_matrix, dtype=object)\n",
    "    final_matrix[upper_triangle] = [\n",
    "    f\"[{low:.2f},\\n {high:.2f}]\" for low, high in zip(confidence_interval_low[upper_triangle], confidence_interval_high[upper_triangle])\n",
    "    ]\n",
    "    final_matrix[lower_triangle] = average_matrix[lower_triangle]\n",
    "    \n",
    "    df = df.rename(columns=mapping, index=mapping)\n",
    "    df = df.reindex(columns=order, index=order)\n",
    "    \n",
    "    df_ = pd.DataFrame(final_matrix, columns = df.columns, index = df.columns)\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081078d8-7e35-4bbe-861b-c6e432621cef",
   "metadata": {},
   "source": [
    "Read bootstrap results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd0147-3cb3-4f36-b87e-d43c2db41c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = f\"../data/bootstrap_results/\"\n",
    "\n",
    "precision_bootstrap_matrices = []\n",
    "\n",
    "for file in sorted(glob.glob(dir_ + \"*.pkl\")):\n",
    "    print(file)\n",
    "    precision_bootstrap_matrix = read_from_pickle(file)\n",
    "    precision_bootstrap_matrices.append(precision_bootstrap_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe8f32-4774-4f24-a020-a2d07b91ebc7",
   "metadata": {},
   "source": [
    "Estimate edge-weight stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191501b-7d08-4e9d-9e18-74f3222b9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_estimates = []\n",
    "for precisions, dataset, order in zip(precision_bootstrap_matrices, datasets_train, orders):\n",
    "    edge_weights_stability_estimates_df = get_edge_weights_stability_estimates(precisions, dataset, mapping, order)\n",
    "    stability_estimates.append(edge_weights_stability_estimates_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3b232-b3c4-435e-9cd9-9df6e02ce17b",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f9a5d-00cb-49ba-b701-7272c35878cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(stability_estimates):\n",
    "    df.to_pickle(f\"../data/bootstrap_results/edge_weight_stability/edge_weights_stability_train_2-decim_graph_{i}.pkl\")\n",
    "    df.to_csv(f\"../data/bootstrap_results/edge_weight_stability/edge_weights_stability_train_2-decim_graph_{i}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15207fa-e158-4dc9-b91e-3c17b69cac37",
   "metadata": {},
   "source": [
    "#### Visualize results of edge-weights stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d644797-081a-4c79-9e23-a0c1f8ac76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = f\"../data/bootstrap_results/edge_weight_stability/\"\n",
    "\n",
    "stability_estimates = []\n",
    "\n",
    "for file in sorted(glob.glob(dir_ + \"*_2-decim*.pkl\")):\n",
    "    print(file)\n",
    "    df = pd.read_pickle(file)\n",
    "    stability_estimates.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792432dd-5ee2-41ac-af9e-7eb3f35e595d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, stability in enumerate(zip(stability_estimates, orders)):\n",
    "    stability_estimate = stability[0]\n",
    "    order = stability[1]\n",
    "    \n",
    "    df = stability_estimate.copy()\n",
    "\n",
    "    labels = df.copy().to_numpy()\n",
    "    values = df.copy().to_numpy() \n",
    "\n",
    "    n = df.shape[0]\n",
    "    upper_triangle = np.triu(np.ones((n, n), dtype=bool), k=1)\n",
    "    values[upper_triangle] = 0\n",
    "\n",
    "    df_with_values = pd.DataFrame(values, columns=df.columns, index=df.index).astype(float)\n",
    "\n",
    "    cm = 1/2.54\n",
    "    dpi = 500\n",
    "\n",
    "    sns.set_style(\"white\")\n",
    "    plt.rcParams['figure.dpi'] = dpi\n",
    "    plt.rcParams['figure.figsize'] = [15*cm,15*cm]\n",
    "    plt.rcParams[\"font.size\"] = 4\n",
    "    plt.rcParams['ytick.labelsize'] = 6\n",
    "    plt.rcParams['xtick.labelsize'] = 6\n",
    "    plt.rcParams['axes.labelsize'] = 7\n",
    "    plt.rcParams[\"axes.edgecolor\"] = \".15\"\n",
    "    plt.rcParams[\"axes.linewidth\"]  = 0.5\n",
    "\n",
    "    cmap = sns.diverging_palette(100, 7, s=75, l=40,\n",
    "                        n=5, center=\"light\", as_cmap=True)\n",
    "\n",
    "    g = sns.heatmap(\n",
    "    data = df_with_values,\n",
    "    annot=labels,\n",
    "    center=0.0,\n",
    "    fmt = '',\n",
    "    square=True,\n",
    "    cmap=cmap,\n",
    "    cbar=False,\n",
    "    linewidths=0.3,\n",
    "    )\n",
    "    \n",
    "    g.figure.savefig(f\"../data/bootstrap_results/edge_weight_stability/edge_weigh_stability_measures_dpi_{dpi}_graph_{index}.png\",  bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db651f8-3cd1-41dd-a093-a921941796a0",
   "metadata": {},
   "source": [
    "## Test edge-weight differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4bacf-457c-4bbd-bc50-5469d2f9739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract node-node pairs from matrix columns\n",
    "def extract_node_pairs(matrix):\n",
    "    n = matrix.shape[0]\n",
    "    node_pairs = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            node_pairs.append((matrix.columns[i], matrix.columns[j]))\n",
    "    return node_pairs\n",
    "\n",
    "# Extract node-node pairs from the first matrix\n",
    "node_pairs = extract_node_pairs(bootstrap_precisions[0])\n",
    "\n",
    "# Function to calculate pairwise differences in edge weights for each matrix\n",
    "def calculate_links_values(matrices_list):\n",
    "    pairwise_diffs_all_matrices = {}\n",
    "    for matrix in matrices_list:\n",
    "        n = matrix.shape[0]\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                value = matrix[i, j]\n",
    "                pair = (columns[i], columns[j])\n",
    "                if pair not in pairwise_diffs_all_matrices:\n",
    "                    pairwise_diffs_all_matrices[pair] = []\n",
    "                pairwise_diffs_all_matrices[pair].append(value)\n",
    "    return pairwise_diffs_all_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f4deed-222b-4b9c-9bd3-2a3f62d848d3",
   "metadata": {},
   "source": [
    "### 2.1 Pair-wise differences between edge weights within the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeb2273-e93c-4221-bd2c-2cf7576ffe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform statistical tests for each unique pair of differences\n",
    "def perform_statistical_tests(pairwise_diffs_all_matrices):\n",
    "    for i, node_pair1 in enumerate(node_pairs):\n",
    "        for j, node_pair2 in enumerate(node_pairs):\n",
    "            if i >= j:\n",
    "                continue  # We only need to perform tests once for each pair\n",
    "            diffs_pair1 = pairwise_diffs_all_matrices.get(node_pair1, [])\n",
    "            diffs_pair2 = pairwise_diffs_all_matrices.get(node_pair2, [])\n",
    "            _, p_value = ttest_ind(diffs_pair1, diffs_pair2)\n",
    "            p_values_matrix[i, j] = p_value\n",
    "            p_values_matrix[j, i] = p_value  # Symmetric matrix\n",
    "    return p_values_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfbd1d8-103c-4b10-bd79-de9d8c10c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (bootstrap_precisions, order) in enumerate(zip(precision_bootstrap_matrices, orders)):\n",
    "\n",
    "    # reorder and rename nodes\n",
    "    bootstrap_precisions = [reorder_matrix(matrix, matrix.columns, matrix.columns, mapping=mapping, mapping_order=order, to_numpy=False) for matrix in bootstrap_precisions]\n",
    "    matrices_list = [np.array(matrix) for matrix in bootstrap_precisions]\n",
    "    columns = bootstrap_precisions[0].columns\n",
    "    \n",
    "    # Calculate pairwise differences for each matrix\n",
    "    pairwise_diffs_all_matrices = calculate_links_values(matrices_list)\n",
    "    \n",
    "    # Create a matrix to store the p-values for statistical tests\n",
    "    num_nodes = len(node_pairs)\n",
    "    p_values_matrix = np.zeros((num_nodes, num_nodes))\n",
    "  \n",
    "    # Perform statistical tests\n",
    "    p_values_matrix = perform_statistical_tests(pairwise_diffs_all_matrices)\n",
    "    p_values_matrix_df = pd.DataFrame(p_values_matrix, columns =node_pairs, index=node_pairs)\n",
    "    \n",
    "    # save results\n",
    "    p_values_matrix_df.to_pickle(f'../data/bootstrap_results/edge-weight_diff_test_graph_{index}.pkl')\n",
    "    p_values_matrix_df.to_csv(f'../data/bootstrap_results/edge-weight_diff_test_graph_{index}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348c725-84f5-40a9-beee-078e6a523889",
   "metadata": {},
   "source": [
    "### 2.2 Pair-wise differences between edge weights between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76977b-2eda-44ed-a7bc-9ce31f03f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_statistical_tests_between(m1_links, m2_links, node_pairs_1, node_pairs_2):\n",
    "    if len(node_pairs_1) != len(node_pairs_2):\n",
    "        node_pairs = node_pairs_m1 if len(node_pairs_m1) <= len(node_pairs_m2) else node_pairs_m2\n",
    "        num_nodes = len(node_pairs)\n",
    "   \n",
    "        p_values_matrix = np.full((num_nodes, num_nodes), np.nan)\n",
    "\n",
    "        for i, node_pair1 in enumerate(node_pairs):\n",
    "            for j, node_pair2 in enumerate(node_pairs):\n",
    "                if i > j:\n",
    "                    continue \n",
    "                diffs_pair1 = m1_links.get(node_pair1, [])\n",
    "                diffs_pair2 = m2_links.get(node_pair2, [])\n",
    "                _, p_value = ttest_ind(diffs_pair1, diffs_pair2)\n",
    "                p_values_matrix[i, j] = p_value\n",
    "                p_values_matrix[j, i] = p_value\n",
    "                p_values_matrix_df = pd.DataFrame(p_values_matrix, columns=node_pairs, index=node_pairs)\n",
    "    else:\n",
    "        num_nodes = len(node_pairs_1)\n",
    "        \n",
    "        p_values_matrix = np.full((num_nodes, num_nodes), np.nan)\n",
    "\n",
    "        for i, node_pair1 in enumerate(node_pairs_1):\n",
    "            for j, node_pair2 in enumerate(node_pairs_2):\n",
    "                diffs_pair1 = m1_links.get(node_pair1, [])\n",
    "                diffs_pair2 = m2_links.get(node_pair2, [])\n",
    "                _, p_value = ttest_ind(diffs_pair1, diffs_pair2)\n",
    "                p_values_matrix[i, j] = p_value\n",
    "                p_values_matrix_df = pd.DataFrame(p_values_matrix, columns=node_pairs_2, index=node_pairs_1)\n",
    "        \n",
    "    return p_values_matrix_df\n",
    "\n",
    "def compare_edge_weights(\n",
    "    bootstrap_matrices_1,\n",
    "    bootstrap_matrices_2,\n",
    "    save=False\n",
    "):\n",
    "    bootstrap_matrices_1_list = [np.array(matrix) for matrix in bootstrap_matrices_1]\n",
    "    bootstrap_matrices_2_list = [np.array(matrix) for matrix in bootstrap_matrices_2]\n",
    "    \n",
    "    # extract links from precision matrices\n",
    "    m1_links = calculate_links_values(bootstrap_matrices_1_list, bootstrap_matrices_1[0].columns)\n",
    "    m2_links = calculate_links_values(bootstrap_matrices_2_list, bootstrap_matrices_2[0].columns)\n",
    "    \n",
    "    # calculate list of links (node pairs)\n",
    "    node_pairs_m1 = extract_node_pairs(m_1[0])\n",
    "    node_pairs_m2 = extract_node_pairs(m_2[0])\n",
    "    \n",
    "    p_values_matrix_df = perform_statistical_tests_between(m1_links, m2_links, node_pairs_m1, node_pairs_m2)\n",
    "\n",
    "    if save != False:\n",
    "        p_values_matrix_df.to_csv(f'../data/bootstrap_results/models_statistical_diffs/{save}.csv')\n",
    "\n",
    "    return p_values_matrix_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1433be-40ae-4c4a-ad62-84b09a35a312",
   "metadata": {},
   "source": [
    "- Calculate statistical difference between ERN and ERN-COV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524923c-48a4-41eb-8a75-a92b9ac751b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder and change names of the nodes\n",
    "m_1 = [reorder_matrix(\n",
    "        matrix, \n",
    "        precision_bootstrap_matrices[0][0].columns, \n",
    "        precision_bootstrap_matrices[0][0].columns, \n",
    "        mapping=mapping, \n",
    "        mapping_order=ern_order,\n",
    "        to_numpy=False\n",
    "    ) for matrix in precision_bootstrap_matrices[0]\n",
    "]\n",
    "\n",
    "# reorder and change names of the nodes\n",
    "m_2 = [\n",
    "    reorder_matrix(\n",
    "        matrix, \n",
    "        precision_bootstrap_matrices[1][0].columns, \n",
    "        precision_bootstrap_matrices[1][0].columns, \n",
    "        mapping=mapping, \n",
    "        mapping_order=ern_cov_order,\n",
    "        to_numpy=False\n",
    "    ) for matrix in precision_bootstrap_matrices[1]\n",
    "]\n",
    "\n",
    "p_values_matrix = compare_edge_weights(\n",
    "    m_1, \n",
    "    m_2,\n",
    "    save=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0de16c-7ac0-4983-85d7-59cc556a28f2",
   "metadata": {},
   "source": [
    "- Calculate statistical difference between CRN and CRN-COV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fcf238-ee31-4904-93f0-1259b7f89d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder and change names of the nodes\n",
    "m_1 = [reorder_matrix(\n",
    "        matrix, \n",
    "        precision_bootstrap_matrices[2][0].columns, \n",
    "        precision_bootstrap_matrices[2][0].columns, \n",
    "        mapping=mapping, \n",
    "        mapping_order=crn_order,\n",
    "        to_numpy=False\n",
    "    ) for matrix in precision_bootstrap_matrices[2]\n",
    "]\n",
    "\n",
    "# reorder and change names of the nodes\n",
    "m_2 = [\n",
    "    reorder_matrix(\n",
    "        matrix, \n",
    "        precision_bootstrap_matrices[3][0].columns, \n",
    "        precision_bootstrap_matrices[3][0].columns, \n",
    "        mapping=mapping, \n",
    "        mapping_order=crn_cov_order,\n",
    "        to_numpy=False\n",
    "    ) for matrix in precision_bootstrap_matrices[3]\n",
    "]\n",
    "\n",
    "p_values_matrix = compare_edge_weights(\n",
    "    m_1, \n",
    "    m_2,\n",
    "    save=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae0d936-d5d5-4131-9c46-d22b5081cc7e",
   "metadata": {},
   "source": [
    "- Calculate statistical difference between ERN and CRN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909b1cf-a22a-4930-9cc5-b1fcd6c3b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder and change names of the nodes\n",
    "m_1 = [reorder_matrix(\n",
    "        matrix, \n",
    "        precision_bootstrap_matrices[0][0].columns, \n",
    "        precision_bootstrap_matrices[0][0].columns, \n",
    "        mapping=mapping, \n",
    "        mapping_order=ern_order,\n",
    "        to_numpy=False\n",
    "    ) for matrix in precision_bootstrap_matrices[0]\n",
    "]\n",
    "\n",
    "# reorder and change names of the nodes\n",
    "m_2 = [\n",
    "    reorder_matrix(\n",
    "        matrix, \n",
    "        precision_bootstrap_matrices[2][0].columns, \n",
    "        precision_bootstrap_matrices[2][0].columns, \n",
    "        mapping=mapping, \n",
    "        mapping_order=crn_order,\n",
    "        to_numpy=False\n",
    "    ) for matrix in precision_bootstrap_matrices[2]\n",
    "]\n",
    "\n",
    "p_values_matrix = compare_edge_weights(\n",
    "    m_1, \n",
    "    m_2,\n",
    "    save=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e76cc-6d61-4324-bfac-e36817887c75",
   "metadata": {},
   "source": [
    "- Calculate statistical difference between ERN-COV and CRN-COV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7c9d1-a43d-4df8-bec4-0fc329634be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder and change names of the nodes\n",
    "m_1 = [reorder_matrix(\n",
    "        matrix, \n",
    "        precision_bootstrap_matrices[1][0].columns, \n",
    "        precision_bootstrap_matrices[1][0].columns, \n",
    "        mapping=mapping, \n",
    "        mapping_order=ern_cov_order,\n",
    "        to_numpy=False\n",
    "    ) for matrix in precision_bootstrap_matrices[1]\n",
    "]\n",
    "\n",
    "# reorder and change names of the nodes\n",
    "m_2 = [\n",
    "    reorder_matrix(\n",
    "        matrix, \n",
    "        precision_bootstrap_matrices[3][0].columns, \n",
    "        precision_bootstrap_matrices[3][0].columns, \n",
    "        mapping=mapping, \n",
    "        mapping_order=crn_cov_order,\n",
    "        to_numpy=False\n",
    "    ) for matrix in precision_bootstrap_matrices[3]\n",
    "]\n",
    "\n",
    "p_values_matrix = compare_edge_weights(\n",
    "    m_1, \n",
    "    m_2,\n",
    "    save=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e32e2e0-ade0-4e43-9dfc-434bd423092b",
   "metadata": {},
   "source": [
    "## 3. Sensitivity and stability of networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ab5ae-bc06-44e0-af2a-fd29af6bded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_matrix(matrix, threshold=0.02):\n",
    "    return np.where(np.abs(matrix) < threshold, 0, 1)\n",
    "\n",
    "def calculate_specificity_for_element(true_data, estimated_matrices, i, j):\n",
    "    tp = np.sum([1 for matrix in estimated_matrices if matrix[i, j] == 1 and true_data[i, j] == 1])\n",
    "    tn = np.sum([1 for matrix in estimated_matrices if matrix[i, j] == 0 and true_data[i, j] == 0])\n",
    "    fp = np.sum([1 for matrix in estimated_matrices if matrix[i, j] == 1 and true_data[i, j] == 0])\n",
    "    fn = np.sum([1 for matrix in estimated_matrices if matrix[i, j] == 0 and true_data[i, j] == 1])\n",
    "\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0  # Handling division by zero\n",
    "\n",
    "    return specificity\n",
    "\n",
    "def calculate_sensitivity_for_element(true_data, estimated_matrices, i, j):\n",
    "    tp = np.sum([1 for matrix in estimated_matrices if matrix[i, j] == 1 and true_data[i, j] == 1])\n",
    "    tn = np.sum([1 for matrix in estimated_matrices if matrix[i, j] == 0 and true_data[i, j] == 0])\n",
    "    fp = np.sum([1 for matrix in estimated_matrices if matrix[i, j] == 1 and true_data[i, j] == 0])\n",
    "    fn = np.sum([1 for matrix in estimated_matrices if matrix[i, j] == 0 and true_data[i, j] == 1])\n",
    "\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0  # Handling division by zero\n",
    "\n",
    "    return sensitivity\n",
    "\n",
    "def plot_sensitivity_specificity_results(\n",
    "    sensitivity_df, \n",
    "    specificity_df,\n",
    "    save=False\n",
    "):\n",
    "    specificity_df = specificity_df.set_index('Unnamed: 0')\n",
    "    sensitivity_df = sensitivity_df.set_index('Unnamed: 0')\n",
    "    \n",
    "    specificity_mask = np.triu(np.where(specificity_df == 0, False, True), k=1)\n",
    "    sensitivity_mask = np.tril(np.where(sensitivity_df == 0, False, True), k=-1)\n",
    "    \n",
    "    \n",
    "    # plotting parameters\n",
    "    cmap = sns.diverging_palette(100, 7, s=75, l=40,n=5, center=\"light\", as_cmap=True)\n",
    "    cm = 1/2.54\n",
    "    dpi = 500\n",
    "    \n",
    "    sns.set_style(\"white\")\n",
    "    plt.rcParams['figure.dpi'] = dpi\n",
    "    plt.rcParams['figure.figsize'] = [15*cm,15*cm]\n",
    "    plt.rcParams[\"font.size\"] = 4\n",
    "    plt.rcParams['ytick.labelsize'] = 6\n",
    "    plt.rcParams['xtick.labelsize'] = 6\n",
    "    plt.rcParams['axes.labelsize'] = 7\n",
    "    plt.rcParams[\"axes.edgecolor\"] = \".15\"\n",
    "    plt.rcParams[\"axes.linewidth\"]  = 0.5\n",
    "    \n",
    "    # create canvas\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "\n",
    "    # plot sensitivity\n",
    "    g = sns.heatmap(\n",
    "        data = sensitivity_df,\n",
    "        annot=True,\n",
    "        mask = np.invert(sensitivity_mask),\n",
    "        center=0.5,\n",
    "        fmt='.2f',\n",
    "        square=True,\n",
    "        cmap=cmap,\n",
    "        cbar=False,\n",
    "        linewidths=1,\n",
    "        ax=axis\n",
    "    )\n",
    "\n",
    "    # plot specificity\n",
    "    g_2 = sns.heatmap(\n",
    "        data = specificity_df,\n",
    "        annot=True,\n",
    "        mask = np.invert(specificity_mask),\n",
    "        center=0.5,\n",
    "        fmt='.2f',\n",
    "        square=True,\n",
    "        cmap=cmap,\n",
    "        cbar=False,\n",
    "        linewidths=1,\n",
    "        ax=axis\n",
    "    )\n",
    "\n",
    "    if save != False:\n",
    "        figure.savefig(f\"../data/bootstrap_results/specificity_sensitivity/{save}.png\",  bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    return figure    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d1a534-be09-4dbe-b0e3-2eb0770dc096",
   "metadata": {},
   "source": [
    "Read original models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaf1cc7-72a3-4f28-8b04-99a849ddabea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_model_df = pd.read_pickle('../data/precision_matrixes/train/precision_matrix_0_ntrials_1000_sklearn_cv3_th0.65_without_skewd.pkl')\n",
    "ern_cov_model_df = pd.read_pickle('../data/precision_matrixes/train/precision_matrix_1_ntrials_1000_sklearn_cv3_th0.65_without_skewd_no_sex.pkl')\n",
    "crn_model_df = pd.read_pickle('../data/precision_matrixes/train/precision_matrix_2_ntrials_1000_sklearn_cv3_th0.65_without_skewd.pkl')\n",
    "crn_cov_model_df = pd.read_pickle('../data/precision_matrixes/train/precision_matrix_3_ntrials_1000_sklearn_cv3_th0.65_without_skewd_no_sex.pkl')\n",
    "\n",
    "precision_matrixes = [\n",
    "    ern_model_df,\n",
    "    ern_cov_model_df,\n",
    "    crn_model_df,\n",
    "    crn_cov_model_df,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f604d1a-5480-4f8f-8ab5-8e06dcb5f89b",
   "metadata": {},
   "source": [
    "Read bootstrap results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf8b5c-f653-4f41-9acc-67147572fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = f\"data/bootstrap_results/\"\n",
    "\n",
    "precision_bootstrap_matrices = []\n",
    "\n",
    "for file in sorted(glob.glob(dir_ + \"*.pkl\")):\n",
    "    print(file)\n",
    "    precision_bootstrap_matrix = read_from_pickle(file)\n",
    "    precision_bootstrap_matrices.append(precision_bootstrap_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b72cd-03e3-4bc0-aad9-1962937f29bd",
   "metadata": {},
   "source": [
    "Calculate sensitivity ans specificity items for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e787b1-884b-4fb6-823a-93fe2851d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (original_model, bootstrap_precisions, order) in enumerate(zip(precision_matrixes, precision_bootstrap_matrices, orders)):\n",
    "\n",
    "    # reorder and rename nodes\n",
    "    bootstrap_precisions = [reorder_matrix(matrix, bootstrap_precisions[0].columns, bootstrap_precisions[0].columns, mapping=mapping, mapping_order=order) for matrix in bootstrap_precisions]\n",
    "    original_model_df = reorder_matrix(original_model, original_model.columns, original_model.columns, mapping=mapping, mapping_order=order)\n",
    "    \n",
    "    original_model = np.array(binarize_matrix(original_model_df))\n",
    "    matrices_list = [np.array(binarize_matrix(matrix)) for matrix in bootstrap_precisions]\n",
    "\n",
    "    specificity_matrix = np.zeros_like(original_model, dtype=float)\n",
    "    sensitivity_matrix = np.zeros_like(original_model, dtype=float)\n",
    "\n",
    "    for i in range(original_model.shape[0]):\n",
    "        for j in range(original_model.shape[1]):\n",
    "            specificity_matrix[i, j] = calculate_specificity_for_element(original_model, matrices_list, i, j)\n",
    "            sensitivity_matrix[i, j] = calculate_sensitivity_for_element(original_model, matrices_list, i, j)\n",
    "    \n",
    "    specificity_df = pd.DataFrame(specificity_matrix, columns=original_model_df.columns, index=original_model_df.columns)\n",
    "    sensitivity_df = pd.DataFrame(sensitivity_matrix, columns=original_model_df.columns, index=original_model_df.columns)\n",
    "\n",
    "    specificity_df.to_csv(f'../data/bootstrap_results/specificity_sensitivity/specificity_model_{index}.csv')\n",
    "    sensitivity_df.to_csv(f'../data/bootstrap_results/specificity_sensitivity/sensitivity_model_{index}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f7a083-961b-4e9d-b72b-db369f09ab4f",
   "metadata": {},
   "source": [
    "#### Visualize sensitivity and stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d618909-9b69-40a4-8fa8-7fca2acb28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = f\"../data/bootstrap_results/specificity_sensitivity/\"\n",
    "\n",
    "sensitivity_results = []\n",
    "\n",
    "for file in sorted(glob.glob(dir_ + \"sensitivity*.csv\")):\n",
    "    print(file)\n",
    "    result = pd.read_csv(file)\n",
    "    sensitivity_results.append(result)\n",
    "\n",
    "specificity_results = []\n",
    "\n",
    "for file in sorted(glob.glob(dir_ + \"specificity*.csv\")):\n",
    "    print(file)\n",
    "    result = pd.read_csv(file)\n",
    "    specificity_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b940b9b-21a9-41c5-9609-719528ba73ef",
   "metadata": {},
   "source": [
    "- ERN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9146c75-05de-4942-a30d-1b4a80d88f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_specificity_df = specificity_results[0]\n",
    "ern_sensitivity_df = sensitivity_results[0]\n",
    "\n",
    "_ = plot_sensitivity_specificity_results(\n",
    "    sensitivity_df = ern_sensitivity_df,\n",
    "    specificity_df = ern_specificity_df,\n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd35ee-90cf-4471-8d59-74ef54d463f7",
   "metadata": {},
   "source": [
    "- ERN cov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f8e8f-e5bc-4360-8983-cd8a652801d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_specificity_df = specificity_results[1]\n",
    "ern_sensitivity_df = sensitivity_results[1]\n",
    "\n",
    "_ = plot_sensitivity_specificity_results(\n",
    "    sensitivity_df = ern_sensitivity_df,\n",
    "    specificity_df = ern_specificity_df,\n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc37bc-c627-4eea-bb68-72e1918a0a84",
   "metadata": {},
   "source": [
    "- CRN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e4dc0c-df40-4b47-891d-a91954191bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "crn_specificity_df = specificity_results[2]\n",
    "crn_sensitivity_df = sensitivity_results[2]\n",
    "\n",
    "_ = plot_sensitivity_specificity_results(\n",
    "    sensitivity_df = crn_sensitivity_df,\n",
    "    specificity_df = crn_specificity_df,\n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a93975-b8c1-48d6-aa23-c82bd0eaaa65",
   "metadata": {},
   "source": [
    "- CRN cov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f49d6-9cfa-4f15-91dd-678b7c962960",
   "metadata": {},
   "outputs": [],
   "source": [
    "crn_specificity_df = specificity_results[3]\n",
    "crn_sensitivity_df = sensitivity_results[3]\n",
    "\n",
    "_ = plot_sensitivity_specificity_results(\n",
    "    sensitivity_df = crn_sensitivity_df,\n",
    "    specificity_df = crn_specificity_df,\n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27ffd7-5b6e-4d71-bb6d-51bafad92b96",
   "metadata": {},
   "source": [
    "## 3. Network Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550724cc-07fa-47e2-a5a1-35c14ad2d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(precision_matrix_df, threshold=0.02):\n",
    "    precision_matrix_df = precision_matrix_df.where(np.triu(np.ones(precision_matrix_df.shape)).astype(bool))\n",
    "    \n",
    "    links = precision_matrix_df.stack().reset_index()\n",
    "    links.columns = ['var1', 'var2','weight']\n",
    "    links=links.loc[ (abs(links['weight']) > threshold) &  (links['var1'] != links['var2']) ]\n",
    "        \n",
    "    links = links.round(3)\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b346de4-b5c1-4be5-8516-6ce92ffea7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_pickle(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        precision_matrices = pickle.load(file)\n",
    "    return precision_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f0ee2b-1be8-4813-b803-f9640013a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(precision_matrix_df):\n",
    "    this_links = get_links(precision_matrix_df)\n",
    "    this_links['weight'] = this_links['weight'].abs()\n",
    "    G_ = nx.from_pandas_edgelist(this_links,'var1','var2', edge_attr='weight', create_using=nx.Graph())\n",
    "\n",
    "    return G_\n",
    "\n",
    "def get_bootstrap_network_measures(precision_bootstrap_matrices, dataset_train, dataset_test):\n",
    "    network_analysis_results_df = pd.DataFrame()\n",
    "\n",
    "    for bootstrap_precision_matrix in precision_bootstrap_matrices:\n",
    "        bootstrap_graph = get_graph(bootstrap_precision_matrix)\n",
    "        \n",
    "        measures = [\n",
    "                (calculate_nodes_predictability, {'X': dataset_test}), \n",
    "                (nx.degree_centrality, {}),\n",
    "                (nx.closeness_centrality, {}),\n",
    "                (current_flow_closeness_centrality, {'weight': 'weight'}),\n",
    "                (nx.betweenness_centrality, {'weight': 'weight'}),\n",
    "                (nx.current_flow_betweenness_centrality, {'weight': 'weight'}),\n",
    "                (nx.load_centrality, {})\n",
    "        ]\n",
    "        \n",
    "        for measure, measure_parameters in measures:\n",
    "            G = copy.deepcopy(bootstrap_graph)\n",
    "            network_measure = measure(G = G, **measure_parameters)\n",
    "            network_measure = {k: v for k, v in sorted(network_measure.items(), key=lambda item: item[0], reverse=True)}\n",
    "            network_measure_nodes = network_measure.keys()\n",
    "            network_measure_values = network_measure.values()\n",
    "            network_measure_df = pd.DataFrame({\n",
    "                'node': network_measure_nodes,\n",
    "                'value' : network_measure_values,\n",
    "                'measure' : [measure.__name__] * len(network_measure_nodes),\n",
    "            })\n",
    "            \n",
    "            network_analysis_results_df = pd.concat([network_analysis_results_df, network_measure_df], ignore_index = True)\n",
    "\n",
    "    return network_analysis_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32977ef4-deb9-4a6d-9123-521cb8f06909",
   "metadata": {},
   "source": [
    "Define custrom network measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde41e6-f852-4f70-8aa7-3ce5f74e8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nodes_predictability(X, G):\n",
    "    explained_variance = dict()\n",
    "        \n",
    "    for node in G.nodes():\n",
    "        y_ = X[[node]]\n",
    "\n",
    "        neighbors = list(G.neighbors(node))\n",
    "\n",
    "        X_ = X.loc[:, neighbors]\n",
    "\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X_, y_)\n",
    "\n",
    "        score = lm.score(X_,y_)\n",
    "        explained_variance[node] = score\n",
    "\n",
    "    return explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ff255-969b-41a8-8942-a8371e61f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_flow_closeness_centrality(G, weight):\n",
    "    G_ = copy.deepcopy(G.copy())\n",
    "    for u, v, data in G_.edges(data=True):\n",
    "        data['weight'] = abs(data['weight'])\n",
    "        \n",
    "    measure = nx.current_flow_closeness_centrality(G_, weight=weight)\n",
    "    return measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2f349-f9b0-4e07-b904-7b89b3120dd9",
   "metadata": {},
   "source": [
    "### Test if there are differences between network measures based on the bootstrapped samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffec890d-b9e2-48b6-8618-83e761af5d8d",
   "metadata": {},
   "source": [
    "Read bootstrap results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280a041-cba5-4c75-8e26-e747c9040249",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = f\"../data/bootstrap_results/\"\n",
    "\n",
    "precision_bootstrap_matrices = []\n",
    "\n",
    "for file in sorted(glob.glob(dir_ + \"*.pkl\")):\n",
    "    print(file)\n",
    "    precision_bootstrap_matrix = read_from_pickle(file)\n",
    "    precision_bootstrap_matrices.append(precision_bootstrap_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534a9c9-d81c-4a61-bd70-8238901c46ab",
   "metadata": {},
   "source": [
    "Calculate network measures on bootstrapped samples and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d23da-216d-4108-9940-6f8001523a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (bootstrap_precision_matrix, dataset_train, dataset_test) in enumerate(zip(precision_bootstrap_matrices, datasets_train, datasets_test)):\n",
    "    model_network_analysis_results_df = get_bootstrap_network_measures(bootstrap_precision_matrix, dataset_train, dataset_test)\n",
    "    model_network_analysis_results_df.to_pickle(f'../data/bootstrap_results/network_measures_diffs/model_{index}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed2361-d459-49ad-ad70-549bc65eefd7",
   "metadata": {},
   "source": [
    "#### 3.1 Calculate if differences between network measures within one network are significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e697b0-7b57-40a4-884f-0f2251ae508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read network measures estimated on bootstrap samples\n",
    "dir_ = f\"../data/bootstrap_results/network_measures_diffs/\"\n",
    "\n",
    "models_bootstrap_network_measures = []\n",
    "\n",
    "for file in sorted(glob.glob(dir_ + \"model*.pkl\")):\n",
    "    print(file)\n",
    "    bootstrap_network_measures = read_from_pickle(file)\n",
    "    models_bootstrap_network_measures.append(bootstrap_network_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ceee73-f075-4014-a518-9c02a4d07a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define measures to test\n",
    "measures = ['calculate_nodes_predictability', 'degree_centrality', 'current_flow_closeness_centrality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b69e1-bf20-47ed-9bfd-0c7c9d0fd53c",
   "metadata": {},
   "source": [
    "Perform statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f33bf7e-9630-4122-9896-6dea2ce298ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in measures:\n",
    "    for index, (model_bootstrap_results, data, order) in enumerate(zip(models_bootstrap_network_measures, datasets_train, orders)):\n",
    "        nodes_list = data.columns\n",
    "        results_df = pd.DataFrame(np.nan, columns=nodes_list, index=nodes_list)\n",
    "    \n",
    "        for node1 in nodes_list:\n",
    "            for node2 in nodes_list:\n",
    "                if node1 != node2:\n",
    "                    node1_values = model_bootstrap_results[\n",
    "                        (model_bootstrap_results['node'] == node1) & \n",
    "                        (model_bootstrap_results['measure'] == measure)\n",
    "                    ]['value'].to_numpy()\n",
    "        \n",
    "                    node2_values = model_bootstrap_results[\n",
    "                        (model_bootstrap_results['node'] == node2) & \n",
    "                        (model_bootstrap_results['measure'] == measure)\n",
    "                    ]['value'].to_numpy()\n",
    "        \n",
    "                    _, p_value = ttest_rel(node1_values, node2_values)\n",
    "                    results_df.loc[node1, node2] = p_value\n",
    "                \n",
    "                if node1 == node2:\n",
    "                    node_value = model_bootstrap_results[\n",
    "                        (model_bootstrap_results['node'] == node1) & \n",
    "                        (model_bootstrap_results['measure'] == measure)\n",
    "                    ]['value'].to_numpy().mean()\n",
    "        \n",
    "                    results_df.loc[node1, node2] = node_value\n",
    "\n",
    "        results_df = reorder_matrix(\n",
    "            results_df, \n",
    "            results_df.columns, \n",
    "            results_df.columns, \n",
    "            mapping=mapping, \n",
    "            mapping_order=order, \n",
    "            to_numpy=False\n",
    "        )\n",
    "        results_df.to_csv(f'../data/bootstrap_results/network_measures_diffs/{measure}_stats_tests_model_{index}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b88ea-fe7e-4f17-af7f-d87b68b108f5",
   "metadata": {},
   "source": [
    "#### 3.2 Calculate if differences between network measures between networks are significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d1a41a-87c7-4b2c-b048-9d22afc095de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_statistical_tests_network_measures(\n",
    "    model_1_bootstrap_results, \n",
    "    model_2_bootstrap_results, \n",
    "    nodes_list_1, \n",
    "    nodes_list_2, \n",
    "    measure,\n",
    "    mapping, \n",
    "    order_columns,\n",
    "    order_index,\n",
    "):\n",
    "    if len(nodes_list_1) != len(nodes_list_2):\n",
    "        nodes_list = nodes_list_1 if len(nodes_list_1) < len(nodes_list_2) else nodes_list_2\n",
    "        results_df = pd.DataFrame(np.nan, columns=nodes_list, index=nodes_list)\n",
    "\n",
    "        for node1 in nodes_list:\n",
    "            for node2 in nodes_list:\n",
    "                node1_values = model_1_bootstrap_results[\n",
    "                    (model_1_bootstrap_results['node'] == node1) & \n",
    "                    (model_1_bootstrap_results['measure'] == measure)\n",
    "                ]['value'].to_numpy()\n",
    "                \n",
    "                node2_values = model_2_bootstrap_results[\n",
    "                    (model_2_bootstrap_results['node'] == node2) & \n",
    "                    (model_2_bootstrap_results['measure'] == measure)\n",
    "                ]['value'].to_numpy()\n",
    "                \n",
    "                _, p_value = ttest_rel(node1_values, node2_values)\n",
    "                results_df.loc[node1, node2] = p_value\n",
    "\n",
    "    else:\n",
    "        results_df = pd.DataFrame(np.nan, columns=nodes_list_1, index=nodes_list_2)\n",
    "\n",
    "        for node1 in nodes_list_1:\n",
    "            for node2 in nodes_list_2:\n",
    "                node1_values = model_1_bootstrap_results[\n",
    "                    (model_1_bootstrap_results['node'] == node1) & \n",
    "                    (model_1_bootstrap_results['measure'] == measure)\n",
    "                ]['value'].to_numpy()\n",
    "                \n",
    "                node2_values = model_2_bootstrap_results[\n",
    "                    (model_2_bootstrap_results['node'] == node2) & \n",
    "                    (model_2_bootstrap_results['measure'] == measure)\n",
    "                ]['value'].to_numpy()\n",
    "                \n",
    "                _, p_value = ttest_ind(node1_values, node2_values)\n",
    "                results_df.loc[node2, node1] = p_value\n",
    "    \n",
    "    results_df = reorder_matrix(\n",
    "        results_df, \n",
    "        results_df.columns, \n",
    "        results_df.index, \n",
    "        mapping=mapping, \n",
    "        mapping_order_columns=order_columns, \n",
    "        mapping_order_index=order_index,\n",
    "        to_numpy=False\n",
    "    )\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9d270-acf4-4856-8c89-e1bf3ad1477a",
   "metadata": {},
   "source": [
    "- ERN and ERN-COV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bb667-8d7e-4be3-b8cc-7ddf3b38b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_bootstrap_results = models_bootstrap_network_measures[0]\n",
    "model_2_bootstrap_results = models_bootstrap_network_measures[1]\n",
    "\n",
    "nodes_list_1 = datasets_train[0].columns\n",
    "nodes_list_2 = datasets_train[1].columns\n",
    "\n",
    "for measure in measures:\n",
    "    network_measures_diff_results_df = perform_statistical_tests_network_measures(\n",
    "        model_1_bootstrap_results, \n",
    "        model_2_bootstrap_results, \n",
    "        nodes_list_1, \n",
    "        nodes_list_2, \n",
    "        measure,\n",
    "        mapping, \n",
    "        ern_order,\n",
    "        ern_order,\n",
    "    )\n",
    "    \n",
    "    network_measures_diff_results_df.to_csv(f'../data/bootstrap_results/network_measures_diffs/{measure}_stats_tests_ern_ern-cov.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac873de8-3776-478f-b1a5-baf8d31e37a3",
   "metadata": {},
   "source": [
    "- CRN and CRN-COV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5e5c1-0f22-4c15-b3b6-921e28b128b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_bootstrap_results = models_bootstrap_network_measures[2]\n",
    "model_2_bootstrap_results = models_bootstrap_network_measures[3]\n",
    "\n",
    "nodes_list_1 = datasets_train[2].columns\n",
    "nodes_list_2 = datasets_train[3].columns\n",
    "\n",
    "for measure in measures:\n",
    "    network_measures_diff_results_df = perform_statistical_tests_network_measures(\n",
    "        model_1_bootstrap_results, \n",
    "        model_2_bootstrap_results, \n",
    "        nodes_list_1, \n",
    "        nodes_list_2, \n",
    "        measure,\n",
    "        mapping, \n",
    "        crn_order,\n",
    "        crn_order,\n",
    "    )\n",
    "    \n",
    "    network_measures_diff_results_df.to_csv(f'../data/bootstrap_results/network_measures_diffs/{measure}_stats_tests_crn_crn-cov.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca5453c-4e3b-451e-ba70-e29d702f965d",
   "metadata": {},
   "source": [
    "- ERN and CRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb766b-e5f7-46ff-918c-60b4ee0843d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_bootstrap_results = models_bootstrap_network_measures[0]\n",
    "model_2_bootstrap_results = models_bootstrap_network_measures[2]\n",
    "\n",
    "nodes_list_1 = datasets_train[0].columns\n",
    "nodes_list_2 = datasets_train[2].columns\n",
    "\n",
    "for measure in measures:\n",
    "    network_measures_diff_results_df = perform_statistical_tests_network_measures(\n",
    "        model_1_bootstrap_results, \n",
    "        model_2_bootstrap_results, \n",
    "        nodes_list_1, \n",
    "        nodes_list_2, \n",
    "        measure,\n",
    "        mapping, \n",
    "        ern_order,\n",
    "        crn_order,\n",
    "    )\n",
    "    \n",
    "    network_measures_diff_results_df.to_csv(f'../data/bootstrap_results/network_measures_diffs/{measure}_stats_tests_ern_crn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a77b43-5943-44b5-b850-b74532c492ac",
   "metadata": {},
   "source": [
    "- ERN-COV and CRN-COV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd84d3d0-f618-4768-b66d-50505b7511a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_bootstrap_results = models_bootstrap_network_measures[1]\n",
    "model_2_bootstrap_results = models_bootstrap_network_measures[3]\n",
    "\n",
    "nodes_list_1 = datasets_train[1].columns\n",
    "nodes_list_2 = datasets_train[3].columns\n",
    "\n",
    "for measure in measures:\n",
    "    network_measures_diff_results_df = perform_statistical_tests_network_measures(\n",
    "        model_1_bootstrap_results, \n",
    "        model_2_bootstrap_results, \n",
    "        nodes_list_1, \n",
    "        nodes_list_2, \n",
    "        measure,\n",
    "        mapping, \n",
    "        ern_cov_order,\n",
    "        crn_cov_order,\n",
    "    )\n",
    "    \n",
    "    network_measures_diff_results_df.to_csv(f'../data/bootstrap_results/network_measures_diffs/{measure}_stats_tests_ern-cov_crn-cov.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c74453-bb8b-41ef-98df-367133a9dcfa",
   "metadata": {},
   "source": [
    "## 4.Stability of network measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd71e2-6d5d-4fd7-a9b3-962457813562",
   "metadata": {},
   "source": [
    "### Visualize results of network measures stability tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbf010-6872-4723-8fc2-35d34b62e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = f\"data/network_analysis/stability_estimates/\"\n",
    "\n",
    "ranked_stability_estimates = []\n",
    "\n",
    "for file in sorted(glob.glob(dir_ + \"*.pkl\")):\n",
    "    print(file)\n",
    "    stability_estimate = pd.read_pickle(file)\n",
    "    ranked_stability_estimates.append(stability_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52eb680-8bfc-4d81-82b5-d29b69148a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, stability_estimate in enumerate(ranked_stability_estimates):\n",
    "    with pd.option_context('display.max_colwidth', None, 'display.max_columns', None,  'display.max_rows', None,):\n",
    "        print(f'GRAPH:   ------ {index}')\n",
    "        display(stability_estimate.groupby(['measure', 'level']).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1de8ea-e258-49f1-b6f5-3ff72a2429eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_network_measures_stability_estimates(stability_estimates_df, exclude=None):\n",
    "    cm = 1/2.54\n",
    "    dpi = 500\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    plt.rcParams['figure.dpi'] = dpi\n",
    "    plt.rcParams['figure.figsize'] = [10*cm,6*cm]\n",
    "    plt.rcParams['ytick.labelsize'] = 6\n",
    "    plt.rcParams['xtick.labelsize'] = 6\n",
    "    plt.rcParams['axes.labelsize'] = 7\n",
    "    plt.rcParams[\"axes.edgecolor\"] = \".15\"\n",
    "    plt.rcParams[\"axes.linewidth\"]  = 0.5\n",
    "    \n",
    "    stability_estimates_filtered_df = stability_estimates_df[stability_estimates_df['measure'] != exclude]\n",
    "\n",
    "    g = sns.lineplot(\n",
    "        data=stability_estimates_filtered_df, \n",
    "        x='level', \n",
    "        y='similatity', \n",
    "        hue='measure',\n",
    "        palette='colorblind',\n",
    "    )\n",
    "    g.invert_xaxis()\n",
    "    g.set(xlabel='Sampled cases (%)', ylabel='Average correlation with original sample')\n",
    "    g.set(ylim=(-1.1, 1.1))\n",
    "\n",
    "    sns.move_legend(\n",
    "        g, \"lower center\",\n",
    "        bbox_to_anchor=(.5, 1), ncol=3, title=None, frameon=False, fontsize=6,\n",
    "    )\n",
    "\n",
    "    new_labels = labels=['predictability', 'd-centrality', 'closeness', 'c-f-closeness', 'betweenness', 'c-f-betweenness']\n",
    "    for t, l in zip(g.legend_.texts, new_labels):\n",
    "        t.set_text(l)\n",
    "\n",
    "    plt.axhline(y=0.0, color='black', linestyle='-', linewidth=0.3)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# g.figure.savefig(f\"data/n_estimators/network_stability_measures_dpi_{dpi}.png\",  bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6ac57-4e7b-4e00-8017-a7249d667d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stability_estimate in ranked_stability_estimates:\n",
    "    draw_network_measures_stability_estimates(stability_estimate, 'newman_betweenness_centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9ef4a1-4c47-4c52-a52a-8f5e5797f60e",
   "metadata": {},
   "source": [
    "## 5. Test of similarity of networks estimated on train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f15fb9-be5a-481a-830a-2b3b8a5c1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_triu_as_list_adjacency(matrix, threshold = 0.002):\n",
    "    \n",
    "    precision_matrix_df = matrix.where(np.triu(np.ones(matrix.shape)).astype(dtype=bool))\n",
    "    precision_matrix_df = precision_matrix_df.mask(abs(precision_matrix_df) <= threshold, 0.0)\n",
    "    \n",
    "    links = precision_matrix_df.stack().reset_index()\n",
    "    links.columns = ['var1', 'var2','weight']\n",
    "    links=links.loc[(links['var1'] != links['var2']) ]\n",
    "    \n",
    "    links = links['weight'].to_numpy()\n",
    "    \n",
    "    links[abs(links) > 0] = 1.0\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae9ecc-5364-49ef-9310-5f51e5d82742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_triu_as_list(matrix, threshold = 0.002):\n",
    "    \n",
    "    precision_matrix_df = matrix.where(np.triu(np.ones(matrix.shape)).astype(dtype=bool))\n",
    "    precision_matrix_df = precision_matrix_df.mask(abs(precision_matrix_df) <= threshold, 0.0)\n",
    "    \n",
    "    links = precision_matrix_df.stack().reset_index()\n",
    "    links.columns = ['var1', 'var2','weight']\n",
    "    links=links.loc[(links['var1'] != links['var2']) ]\n",
    "    \n",
    "    links = links['weight'].to_numpy()\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3986a3-8d9a-4df1-86b6-236baa7a5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsonr_links_similarity(matrix1, matrix2, adjacency=True):\n",
    "    links1 = get_matrix_triu_as_list_adjacency(matrix1) if adjacency else get_matrix_triu_as_list(matrix1)\n",
    "    links2 = get_matrix_triu_as_list_adjacency(matrix2) if adjacency else get_matrix_triu_as_list(matrix2)\n",
    "        \n",
    "    corr, p_value = pearsonr(links1, links2)\n",
    "    \n",
    "    return corr, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d43aee-d70a-49ec-9d14-ec37332e0962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance_similarity(matrix1, matrix2, adjacency=True):\n",
    "    links1 = get_matrix_triu_as_list_adjacency(matrix1) if adjacency else get_matrix_triu_as_list(matrix1)\n",
    "    links2 = get_matrix_triu_as_list_adjacency(matrix2) if adjacency else get_matrix_triu_as_list(matrix2)\n",
    "        \n",
    "    h_sim = 1 - distance.hamming(links1, links2)\n",
    "    \n",
    "    return h_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3312c-f7cc-400c-a3ab-4efdeec5d1ce",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76a429-03ea-4123-8c69-005834802a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 for ERN, 1 for ERN cov, 2 for CRN, 3 for CRN cov\n",
    "index = 0\n",
    "model_train = pd.read_pickle(f\"data/precision_matrixes/train/precision_matrix_{index}_ntrials_1000_sklearn_cv3_th0.65_without_skewd.pkl\")\n",
    "model_test = pd.read_pickle(f\"data/precision_matrixes/test/precision_matrix_{index}_ntrials_1000_sklearn_cv3_th0.65_without_skewd.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c5b6a1-7917-4bce-9caa-312eac2f52a1",
   "metadata": {},
   "source": [
    "1. similarity between the train ans test nets (as adjencacy matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bc7dd-5afe-42a2-a944-7be4099c4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Pearson\\'s r coef: {pearsonr_links_similarity(model_train, model_test)[0]}, p-value: {pearsonr_links_similarity(model_train, model_test)[1]}')\n",
    "print(f'Hamming distance: {hamming_distance_similarity(model_train, model_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e9e743-13ce-4548-bc88-8d08dace0a85",
   "metadata": {},
   "source": [
    "2. similarity between train and test nets (as weighted matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a274f-a36b-4d94-a3a1-1fc3527ca8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Pearson\\'s r coef: {pearsonr_links_similarity(model_train, model_test, adjacency=False)[0]}, p-value: {pearsonr_links_similarity(model_train, model_test, adjacency=False)[1]}')\n",
    "print(f'Hamming distance: {hamming_distance_similarity(model_train, model_test, adjacency=False)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d942ab-8cb4-43e3-830a-fd287714b308",
   "metadata": {},
   "source": [
    "3. similarity of only ERN associations between train and test sets (weights matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89879974-1518-457f-af9b-95ba457b6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node = 'e_CRN' || 'e_ERN'\n",
    "node = 'e_ERN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5651dc5d-6e2a-4799-8ac3-f73f397ddf72",
   "metadata": {},
   "source": [
    "- adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ad6e6-960c-483d-a8e2-502d84d21c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = model_train[node].to_numpy()\n",
    "test_ = model_test[node].to_numpy()\n",
    "\n",
    "train_ = [0 if abs(item) <= 0.02 else 1 for item in train_]\n",
    "test_ = [0 if abs(item) <= 0.02 else 1 for item in test_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b86f5-edc4-4a9e-aad1-878cff2be4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Pearson\\'s r: {scipy.stats.pearsonr(train_, test_)}')\n",
    "print(f'Hamming distance: {1 - distance.hamming(train_, test_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35d34f-afcc-4782-8b02-37cdc0e404ac",
   "metadata": {},
   "source": [
    "- weighten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f7d7a-5274-40bb-a569-85e951bfdeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = model_train[node].to_numpy()\n",
    "test_ = model_test[node].to_numpy()\n",
    "\n",
    "print(f'Pearson\\'s r: {scipy.stats.pearsonr(train_, test_)}')\n",
    "print(f'Hamming distance: {1 - distance.hamming(train_, test_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71b3a9-5d3e-4a52-98a1-0b2c6b94b83e",
   "metadata": {},
   "source": [
    "## 6. Test wether differences between covariates models and no-covariates models are matter of power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0ef2d-4e54-450f-8230-2c918de6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metric=\"log_likelihood\"\n",
    "n_trials = 1000\n",
    "alphas = np.linspace(0.01, 0.1, 20)\n",
    "cv = 3\n",
    "threshold = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3ec45-279d-4fd1-bf48-e57f6fef68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ern_data_df, \n",
    "    crn_data_df,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c08df6-62ec-42eb-8174-ad6c29ec96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['WASH', 'NEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24332d1b-4396-4fa4-b138-88cb8416c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data_df = pd.DataFrame({\n",
    "    'R1': np.random.rand(datasets_no_skewed_scales[0].shape[0]),\n",
    "    'R2': np.random.rand(datasets_no_skewed_scales[0].shape[0]),\n",
    "    'R3': np.random.rand(datasets_no_skewed_scales[0].shape[0]),\n",
    "    'R4': np.random.rand(datasets_no_skewed_scales[0].shape[0]),\n",
    "})\n",
    "random_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7751dea0-91a7-4451-93c2-2fde7778fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_no_skewed_scales = []\n",
    "for model in datasets:\n",
    "    this_dataset = model.drop(columns=columns_to_drop)\n",
    "    this_dataset = pd.concat([this_dataset, random_data_df], axis=1)\n",
    "    datasets_no_skewed_scales.append(this_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247b8d4-ea3d-4f4a-b441-8f189fa4c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'test':\n",
    "    print(f\"Test dataset\")\n",
    "    precision_matrixes_test = []\n",
    "    covariance_matrixes_test = []\n",
    "    support_matrixes_test = []\n",
    "    proportion_matrixes_test = []\n",
    "    average_estimators_test = []\n",
    "    \n",
    "    for model in datasets_no_skewed_scales:\n",
    "        covariance_matrix_df, precision_matrix_df, support_matrix_df, proportion_matrix_df, estimator = learn_graph_structure_adaptive_average_sklearn(\n",
    "            model, \n",
    "            penalization='random',\n",
    "            n_trials=n_trials,\n",
    "            score_metric=score_metric,\n",
    "            cv=cv,\n",
    "            lam=None,\n",
    "            alphas=alphas,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "        precision_matrixes_test.append(precision_matrix_df) \n",
    "        covariance_matrixes_test.append(covariance_matrix_df)\n",
    "        support_matrixes_test.append(support_matrix_df)\n",
    "        proportion_matrixes_test.append(proportion_matrix_df)\n",
    "        average_estimators_test.append(estimator)\n",
    "\n",
    "else:\n",
    "    print(f\"Train dataset\")\n",
    "    precision_matrixes = []\n",
    "    covariance_matrixes = []\n",
    "    support_matrixes = []\n",
    "    proportion_matrixes = []\n",
    "    average_estimators = []\n",
    "\n",
    "    for model in datasets_no_skewed_scales:\n",
    "        covariance_matrix_df, precision_matrix_df, support_matrix_df, proportion_matrix_df, estimator  = learn_graph_structure_adaptive_average_sklearn(\n",
    "            model, \n",
    "            penalization='random',\n",
    "            n_trials=n_trials,\n",
    "            score_metric=score_metric,\n",
    "            cv=cv,\n",
    "            lam=None,\n",
    "            alphas=alphas,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "        precision_matrixes.append(precision_matrix_df)\n",
    "        covariance_matrixes.append(covariance_matrix_df)\n",
    "        support_matrixes.append(support_matrix_df)\n",
    "        proportion_matrixes.append(proportion_matrix_df)\n",
    "        average_estimators.append(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c466bf5-3cc6-4e81-855a-adb7e279e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_matrixes = []\n",
    "\n",
    "for i in range(0,50):\n",
    "    random_data_df = pd.DataFrame({\n",
    "        'R1': np.random.normal(scale=1,size=datasets_no_skewed_scales[0].shape[0]),\n",
    "        'R2': np.random.normal(scale=1,size=datasets_no_skewed_scales[0].shape[0]),\n",
    "        'R3': np.random.normal(scale=1,size=datasets_no_skewed_scales[0].shape[0]),\n",
    "        'R4': np.random.normal(scale=1,size=datasets_no_skewed_scales[0].shape[0]),\n",
    "    })\n",
    "\n",
    "    datasets_no_skewed_scales = []\n",
    "    for model in datasets:\n",
    "        this_dataset = model.drop(columns=columns_to_drop)\n",
    "        this_dataset = pd.concat([this_dataset, random_data_df], axis=1)\n",
    "        datasets_no_skewed_scales.append(this_dataset)\n",
    "    \n",
    "    print(f\"Train dataset\")\n",
    "\n",
    "    for model in datasets_no_skewed_scales:\n",
    "        covariance_matrix_df, precision_matrix_df, support_matrix_df, proportion_matrix_df, estimator  = learn_graph_structure_adaptive_average_sklearn(\n",
    "            model, \n",
    "            penalization='random',\n",
    "            n_trials=n_trials,\n",
    "            score_metric=score_metric,\n",
    "            cv=cv,\n",
    "            lam=None,\n",
    "            alphas=alphas,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "        precision_matrixes.append(precision_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ccbfc-9237-475a-89a7-60e632f9720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/power_tests/precision_matrices_normal_34.npy', np.array(precision_matrixes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net",
   "language": "python",
   "name": "net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
